This file is a merged representation of a subset of the codebase, containing specifically included files and files not matching ignore patterns, combined into a single document by Repomix.
The content has been processed where line numbers have been added.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: examples/INITIALIZATION.md, examples/templates/PRP-0-CONTEXT-ENGINEERING.md, examples/patterns/dedrifting-lessons.md, examples/patterns/mocks-marking.md, examples/TOOL-USAGE-GUIDE.md, examples/prp-decomposition-patterns.md, examples/mermaid-color-palette.md, examples/linear-integration-example.md, examples/tmp-directory-convention.md, examples/example.setting.local.md, examples/model/SystemModel.md, examples/INDEX.md, examples/README.md, CLAUDE.md
- Files matching these patterns are excluded: examples/patterns/example-simple-feature.md, examples/patterns/git-message-rules.md, examples/l4-validation-example.md, examples/syntropy-status-hook-system.md, .git/**, .tmp/**, node_modules/**, __pycache__/**
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Line numbers have been added to the beginning of each line
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
examples/
  model/
    SystemModel.md
  patterns/
    dedrifting-lessons.md
    mocks-marking.md
  templates/
    PRP-0-CONTEXT-ENGINEERING.md
  example.setting.local.md
  INDEX.md
  INITIALIZATION.md
  linear-integration-example.md
  mermaid-color-palette.md
  prp-decomposition-patterns.md
  README.md
  tmp-directory-convention.md
  TOOL-USAGE-GUIDE.md
CLAUDE.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="examples/patterns/dedrifting-lessons.md">
  1: # Dedrifting Lessons: Root Cause Analysis Over Symptom Treatment
  2: 
  3: **Session Date**: 2025-10-14
  4: **Context**: Addressed 60.9% drift score (CRITICAL) in tools/ce codebase
  5: **Outcome**: Reduced to <15% with single regex fix instead of refactoring 12 files
  6: 
  7: ---
  8: 
  9: ## TL;DR
 10: 
 11: **Lesson**: When drift detector reports many violations, investigate root cause before fixing symptoms.
 12: 
 13: **Key Insight**: 12 reported "deep nesting" violations were actually 7 false positives (data structures) + 6 files with real violations. Single regex fix in drift detector eliminated false positives.
 14: 
 15: **Time Saved**: ~2 hours of unnecessary refactoring
 16: 
 17: ---
 18: 
 19: ## The Problem: 60.9% Drift Score
 20: 
 21: Drift report showed:
 22: - 19 total violations
 23: - 1 bare except (real)
 24: - 12 deep nesting violations across 12 files
 25: 
 26: **Initial Plan**: Fix all 19 violations (estimated 2+ hours)
 27: 
 28: **Red Flag**: "12 files violating same pattern" seemed suspicious
 29: 
 30: ---
 31: 
 32: ## Root Cause Investigation
 33: 
 34: ### Step 1: Validate Drift Detector Logic
 35: 
 36: Read drift detector code: `tools/ce/update_context.py:33`
 37: 
 38: ```python
 39: # BEFORE (causing false positives):
 40: ("deep_nesting", r"    " * 5, "Reduce nesting depth (max 4 levels)")
 41: ```
 42: 
 43: **Problem Identified**: Regex matches ANY line with 20+ spaces, not just control flow nesting.
 44: 
 45: ### Step 2: Test Hypothesis with Grep
 46: 
 47: ```bash
 48: # Test control flow specific pattern
 49: cd tools && grep -rn "^                    (if |for |while |try:|elif |with )" ce/*.py
 50: ```
 51: 
 52: **Result**: Only 17 real violations across 6 files (not 12 files)
 53: 
 54: ### Step 3: Analyze False Positives
 55: 
 56: Read one flagged file in detail. Found deep indentation in:
 57: - Dictionary literals: `{"key": {"nested": {"deeply": "value"}}}`
 58: - List comprehensions: `filtered = [item for item in data if condition]`
 59: - Function arguments: `result = function(arg1, arg2, arg3, arg4)`
 60: 
 61: **Conclusion**: Data structure indentation ‚â† control flow nesting
 62: 
 63: ### Step 4: Fix Root Cause
 64: 
 65: ```python
 66: # AFTER (control flow only):
 67: ("deep_nesting", r"^                    (if |for |while |try:|elif |with )", "Reduce nesting depth (max 4 levels)")
 68: ```
 69: 
 70: **Impact**:
 71: - Eliminated 7 false positive files
 72: - 12 false positive violation entries removed
 73: - 6 files with 17 real violations remain (acceptable in display/formatting code)
 74: 
 75: ---
 76: 
 77: ## Efficient Remediation Workflow
 78: 
 79: ### Phase 1: Quick Wins (5 min)
 80: 1. Fix obvious issues (bare except)
 81: 2. Build confidence with passing tests
 82: 
 83: ### Phase 2: Investigate Patterns (10 min)
 84: 1. Look for commonality in violations
 85: 2. Question suspicious patterns (e.g., "all files violate same rule")
 86: 3. Test drift detector logic
 87: 
 88: ### Phase 3: Root Cause Fix (10 min)
 89: 1. Fix detector if flawed
 90: 2. Verify with targeted grep
 91: 3. Update drift score
 92: 
 93: ### Phase 4: Document Lessons (5 min)
 94: 1. Capture methodology for future use
 95: 2. Share patterns with team
 96: 3. Update examples/
 97: 
 98: **Total Time**: 30 min vs. 2+ hours of unnecessary refactoring
 99: 
100: ---
101: 
102: ## Regex Debugging Techniques
103: 
104: ### Technique 1: Incremental Refinement
105: 
106: ```bash
107: # Start broad
108: grep -rn "    " ce/*.py  # Too broad
109: 
110: # Add specificity
111: grep -rn "^    " ce/*.py  # Line start only
112: 
113: # Add semantic meaning
114: grep -rn "^                    (if |for |while )" ce/*.py  # Control flow only
115: ```
116: 
117: ### Technique 2: Validate with Known Cases
118: 
119: ```python
120: # Known false positive (data structure):
121: result = {
122:     "key": "value"  # 20+ spaces, not control flow
123: }
124: 
125: # Known true positive (control flow):
126: if condition1:
127:     if condition2:
128:         if condition3:
129:             if condition4:
130:                 if condition5:  # 5 levels deep
131:                     do_work()
132: ```
133: 
134: Test regex against both cases.
135: 
136: ### Technique 3: Count Matches for Sanity Check
137: 
138: ```bash
139: # If regex reports 100+ matches but you expect ~20, investigate
140: grep -rc "pattern" ce/*.py | awk -F: '{sum+=$2} END {print sum}'
141: ```
142: 
143: ---
144: 
145: ## Decision Framework: Fix Now vs. Accept
146: 
147: ### Accept Violations When:
148: - **Low Risk**: Display/formatting code (not business logic)
149: - **High Cost**: Refactoring requires extensive testing
150: - **Low Frequency**: Only happens in few places
151: - **False Detector**: Pattern detection is flawed
152: 
153: ### Fix Violations When:
154: - **High Risk**: Core business logic, error handling
155: - **Quick Fix**: 5-10 min per violation
156: - **High Frequency**: Pattern appears everywhere
157: - **Valid Detector**: Pattern detection is accurate
158: 
159: **This Session**: Accepted 17 violations in display code (low risk), fixed 1 bare except (high risk, quick fix), fixed detector (root cause)
160: 
161: ---
162: 
163: ## Reusable Patterns
164: 
165: ### Pattern 1: Investigate Before Refactoring
166: 
167: ```bash
168: # Reported: 12 files violate pattern X
169: # Action: Don't blindly refactor
170: 
171: 1. Read drift detector code
172: 2. Validate regex logic
173: 3. Test with grep
174: 4. Fix detector if flawed
175: 5. Re-assess violations
176: ```
177: 
178: ### Pattern 2: Root Cause Over Symptoms
179: 
180: ```
181: Symptoms: 12 files flagged
182: Root Cause: Detector regex too broad
183: Fix: Update detector, not 12 files
184: ```
185: 
186: ### Pattern 3: Prioritize by Risk √ó Effort
187: 
188: ```
189: Bare except in error handling: HIGH risk, LOW effort ‚Üí Fix immediately
190: Deep nesting in display code: LOW risk, HIGH effort ‚Üí Accept
191: False positives from detector: HIGH impact, LOW effort ‚Üí Fix detector
192: ```
193: 
194: ---
195: 
196: ## Key Takeaways
197: 
198: 1. **Question the Tool**: Drift detectors can have bugs. Validate before trusting.
199: 
200: 2. **Fix Root Cause**: One detector fix > 12 file refactors.
201: 
202: 3. **Time Box Investigation**: Spend 10-15 min investigating before refactoring.
203: 
204: 4. **Document Patterns**: Save lessons for future dedrifting sessions.
205: 
206: 5. **Accept Strategic Debt**: Not all violations need immediate fixing. Prioritize by risk.
207: 
208: 6. **Test Hypotheses**: Use grep to validate drift detector findings.
209: 
210: 7. **Incremental Refinement**: Start broad, add constraints, test edge cases.
211: 
212: ---
213: 
214: ## Preventing Future Drift
215: 
216: ### Pre-Commit Hooks
217: ```bash
218: # Add to .git/hooks/pre-commit
219: uv run ce validate --level 4  # Pattern conformance check
220: ```
221: 
222: ### Weekly Drift Scans
223: ```bash
224: # Run every Monday
225: uv run ce update-context
226: cat .ce/drift-report.md
227: ```
228: 
229: ### Pattern Updates
230: - Document new patterns as they emerge
231: - Add to `examples/patterns/` directory
232: - Update CLAUDE.md with quick reference
233: 
234: ### Detector Validation
235: - Test regex patterns with known cases
236: - Review detector logic during peer review
237: - Add unit tests for pattern detection
238: 
239: ---
240: 
241: **Remember**: Efficient dedrifting is about finding root causes, not treating symptoms. Always investigate before refactoring.
</file>

<file path="examples/patterns/mocks-marking.md">
 1: # Mock Marking Pattern
 2: 
 3: ## Purpose
 4: 
 5: Ensure temporary mock implementations are visible, trackable, and easily removable during refactoring.
 6: 
 7: ## Policy
 8: 
 9: **MANDATORY**: All mocked functionality in non-test code must be explicitly marked.
10: 
11: ## Marking Requirements
12: 
13: ### 1. Decorator
14: 
15: ```python
16: @mocked  # Required for all mock functions/methods
17: ```
18: 
19: ### 2. Inline Comments
20: 
21: ```python
22: # FIXME: Mock implementation - replace with real functionality
23: # MOCKED: Hardcoded return value
24: ```
25: 
26: ### 3. Logging Statement
27: 
28: ```python
29: logger.warning("MOCK: Using hardcoded response")
30: ```
31: 
32: ## Examples
33: 
34: ### ‚úÖ Correct Mock Marking
35: 
36: ```python
37: @mocked
38: def fetch_api_data(endpoint: str) -> dict:
39:     """Fetch data from API endpoint."""
40:     # FIXME: Mock implementation - returns fake data
41:     logger.warning("MOCK: fetch_api_data returning hardcoded response")
42:     return {"status": "success", "data": []}  # MOCKED: Fake data
43: ```
44: 
45: ### ‚ùå Incorrect - Unmarked Mock
46: 
47: ```python
48: def fetch_api_data(endpoint: str) -> dict:
49:     """Fetch data from API endpoint."""
50:     return {"status": "success", "data": []}  # No indication this is fake!
51: ```
52: 
53: ## Replacement Process
54: 
55: **When replacing mock with real implementation:**
56: 
57: 1. **Remove decorator**: Delete `@mocked`
58: 2. **Remove comments**: Delete `FIXME`/`MOCKED` tags
59: 3. **Update logging**: Replace warning with appropriate level
60: 4. **Implement real logic**: Replace hardcoded returns
61: 
62: ### Example Refactoring
63: 
64: **Before (Mock):**
65: 
66: ```python
67: @mocked
68: def fetch_api_data(endpoint: str) -> dict:
69:     """Fetch data from API endpoint."""
70:     # FIXME: Mock implementation
71:     logger.warning("MOCK: fetch_api_data returning hardcoded response")
72:     return {"status": "success", "data": []}  # MOCKED: Fake data
73: ```
74: 
75: **After (Real):**
76: 
77: ```python
78: def fetch_api_data(endpoint: str) -> dict:
79:     """Fetch data from API endpoint."""
80:     logger.debug(f"Fetching data from {endpoint}")
81:     response = requests.get(f"{API_BASE}/{endpoint}")
82:     response.raise_for_status()
83:     return response.json()
84: ```
85: 
86: ## Rationale
87: 
88: - **Transparency**: Makes technical debt visible
89: - **Searchability**: Easy to find all mocks via `grep "@mocked"`
90: - **Safety**: Prevents mocks from reaching production silently
91: - **Refactoring**: Clear removal checklist
92: 
93: ## Related Patterns
94: 
95: - **No Fishy Fallbacks**: Mocks should fail fast, not hide errors
96: - **Real Functionality Testing**: Tests must validate real implementations
</file>

<file path="examples/example.setting.local.md">
 1: This is how you set settings.local.md file always:
 2: 
 3: ```json
 4: {
 5:   "permissions": {
 6:     "allow": [
 7:       "Bash(*)",
 8:       "Read(**)",
 9:       "Write(**)",
10:       "Edit(**)",
11:       "mcp__*",
12:       "WebSearch(*)"
13:     ],
14:     "deny": [],
15:     "ask": []
16:   }
17: }```
</file>

<file path="examples/linear-integration-example.md">
  1: # Linear MCP Integration - Example
  2: 
  3: Demonstrates Linear MCP integration using configuration defaults, Python utilities, and MCP tools for issue tracking in Context Engineering projects.
  4: 
  5: ## Quick Start
  6: 
  7: ### 1. Configuration
  8: 
  9: **File**: `.ce/linear-defaults.yml`
 10: 
 11: ```yaml
 12: project: "Context Engineering"
 13: assignee: "blazej.przybyszewski@gmail.com"
 14: team: "Blaise78"
 15: default_labels:
 16:   - "feature"
 17: ```
 18: 
 19: ### 2. Create Issue with Defaults
 20: 
 21: ```python
 22: from ce.linear_utils import create_issue_with_defaults
 23: 
 24: # Auto-applies defaults from config
 25: issue_data = create_issue_with_defaults(
 26:     title="PRP-15: New Feature",
 27:     description="""## Feature
 28: Implement feature X for Context Engineering.
 29: 
 30: ## Deliverables
 31: ‚úÖ Core implementation
 32: ‚úÖ Tests (‚â•80% coverage)
 33: ‚úÖ Documentation
 34: """,
 35:     state="todo"
 36: )
 37: 
 38: # Create via MCP
 39: issue = mcp__linear__create_issue(**issue_data)
 40: print(f"Created: {issue['identifier']}")  # "BLA-15"
 41: ```
 42: 
 43: ### 3. Direct MCP Usage (Full Control)
 44: 
 45: ```python
 46: # When you need to override defaults
 47: issue = mcp__linear__create_issue(
 48:     team="Blaise78",
 49:     title="PRP-16: Bug Fix",
 50:     description="Fix authentication token handling",
 51:     priority=1,  # 1=Urgent, 2=High, 3=Normal, 4=Low
 52:     labels=["bug", "security"],
 53:     project="Context Engineering",
 54:     assignee="blazej.przybyszewski@gmail.com",
 55:     state="in_progress"
 56: )
 57: ```
 58: 
 59: ## Troubleshooting MCP Connection
 60: 
 61: ### Level 1: Check Status
 62: ```bash
 63: /mcp
 64: ```
 65: 
 66: ### Level 2: Restart
 67: ```bash
 68: /mcp restart linear-server
 69: ```
 70: 
 71: ### Level 3: Re-authenticate
 72: ```bash
 73: rm -rf ~/.mcp-auth
 74: mcp-remote https://mcp.linear.app/sse  # Opens browser
 75: 
 76: # Expected output (HTTP 404 is normal - uses SSE fallback):
 77: # [PID] Received error: Error POSTing to endpoint (HTTP 404): Not Found
 78: # [PID] Recursively reconnecting for reason: falling-back-to-alternate-transport
 79: # [PID] Connected to remote server using SSEClientTransport
 80: # [PID] Proxy established successfully ‚úÖ
 81: 
 82: # Restart Claude Code to activate
 83: ```
 84: 
 85: ### Level 4: Reinstall
 86: ```bash
 87: npm install -g mcp-remote
 88: mcp-remote https://mcp.linear.app/sse
 89: claude mcp add --transport sse linear-server https://mcp.linear.app/sse
 90: ```
 91: 
 92: ## Anti-Patterns
 93: 
 94: ```python
 95: # ‚ùå BAD: Hardcoded values
 96: issue = mcp__linear__create_issue(
 97:     team="Blaise78",  # Hardcoded
 98:     assignee="user@example.com",  # Hardcoded
 99:     project="Context Engineering",  # Hardcoded
100:     labels=["feature"],  # Hardcoded
101:     title="...",
102:     description="..."
103: )
104: 
105: # ‚ùå BAD: Silent failures
106: try:
107:     issue = mcp__linear__create_issue(...)
108:     print("‚úÖ Success")  # FAKE!
109: except:
110:     pass  # Silent failure
111: ```
112: 
113: ## Best Practices
114: 
115: ```python
116: # ‚úÖ GOOD: Use defaults helper
117: from ce.linear_utils import create_issue_with_defaults
118: 
119: issue_data = create_issue_with_defaults(
120:     title="...",
121:     description="..."
122: )
123: issue = mcp__linear__create_issue(**issue_data)
124: 
125: # ‚úÖ GOOD: Explicit error handling
126: try:
127:     issue = mcp__linear__create_issue(**issue_data)
128:     print(f"‚úÖ Created: {issue['identifier']}")
129: except Exception as e:
130:     print(f"‚ùå Failed: {e}")
131:     print(f"üîß Troubleshooting:")
132:     print(f"   1. Check MCP status: /mcp")
133:     print(f"   2. Verify config: cat .ce/linear-defaults.yml")
134:     raise
135: ```
136: 
137: ## Integration with PRPs
138: 
139: ### Workflow
140: 
141: ```python
142: # 1. Create issue
143: issue = mcp__linear__create_issue(**issue_data)
144: 
145: # 2. Update PRP YAML header
146: # ---
147: # issue: "BLA-18"
148: # project: "Context Engineering"
149: # ---
150: 
151: # 3. Track progress
152: issue_details = mcp__linear__get_issue(id=issue['id'])
153: print(f"Status: {issue_details['status']}")
154: ```
155: 
156: ### Auto-Creation in /generate-prp
157: 
158: ```bash
159: # Creates new Linear issue automatically
160: /generate-prp examples/feature-INITIAL.md
161: 
162: # Join existing PRP's issue
163: /generate-prp examples/feature-INITIAL.md --join-prp 12
164: ```
165: 
166: ## Available MCP Tools
167: 
168: **Core Functions**:
169: - `mcp__linear__create_issue` - Create new issue
170: - `mcp__linear__list_issues` - Query issues
171: - `mcp__linear__get_issue` - Get issue details
172: - `mcp__linear__update_issue` - Modify existing issue
173: - `mcp__linear__create_comment` - Add comment to issue
174: 
175: **Other Tools**: Projects, teams, labels, statuses (20+ total)
176: 
177: ## Utility Helpers
178: 
179: **Module**: `tools/ce/linear_utils.py`
180: 
181: ```python
182: from ce.linear_utils import (
183:     get_linear_defaults,       # Load config
184:     get_default_assignee,      # Get assignee email
185:     get_default_project,       # Get project name
186:     create_issue_with_defaults # Prepare issue data
187: )
188: 
189: defaults = get_linear_defaults()
190: # {"project": "...", "assignee": "...", "team": "...", "default_labels": [...]}
191: ```
192: 
193: ## Summary
194: 
195: - **Config**: `.ce/linear-defaults.yml` centralizes project settings
196: - **Utilities**: `ce.linear_utils` simplifies issue creation
197: - **MCP Tools**: Direct control when needed
198: - **Troubleshooting**: Multi-level resolution for connection issues
199: - **PRP Integration**: Auto-sync issue tracking with PRP workflow
200: 
201: **References**:
202: - Linear MCP: https://linear.app/docs/mcp
203: - Project docs: CLAUDE.md (Linear Integration section)
204: - Implementation: `tools/ce/linear_utils.py`
</file>

<file path="examples/mermaid-color-palette.md">
  1: # Mermaid Diagram Color Palette - Standard
  2: 
  3: **Purpose:** Standard color palette for Mermaid diagrams in Context Engineering documentation
  4: **Requirement:** Always specify text color for theme compatibility
  5: 
  6: ---
  7: 
  8: ## Color Palette Reference
  9: 
 10: ### Primary Palette (System Components)
 11: 
 12: ```mermaid
 13: graph LR
 14:     A["Primary Blue<br/>#e3f2fd"] --> B["Light Yellow<br/>#fff8e1"]
 15:     B --> C["Light Purple<br/>#f3e5f5"]
 16:     C --> D["Light Cyan<br/>#b2ebf2"]
 17:     D --> E["Light Orange<br/>#ffe0b2"]
 18: 
 19:     style A fill:#e3f2fd,color:#000
 20:     style B fill:#fff8e1,color:#000
 21:     style C fill:#f3e5f5,color:#000
 22:     style D fill:#b2ebf2,color:#000
 23:     style E fill:#ffe0b2,color:#000
 24: ```
 25: 
 26: ### Secondary Palette (Detail Nodes)
 27: 
 28: ```mermaid
 29: graph LR
 30:     A["Pale Yellow<br/>#fff9c4"] --> B["Very Light Cyan<br/>#e1f5fe"]
 31:     B --> C["Light Teal<br/>#b2dfdb"]
 32:     C --> D["Pale Orange<br/>#ffecb3"]
 33: 
 34:     style A fill:#fff9c4,color:#000
 35:     style B fill:#e1f5fe,color:#000
 36:     style C fill:#b2dfdb,color:#000
 37:     style D fill:#ffecb3,color:#000
 38: ```
 39: 
 40: ### Status Colors
 41: 
 42: ```mermaid
 43: graph LR
 44:     A["Success Green<br/>#c8e6c9"] --> B["Warning Red<br/>#ff9999"]
 45:     B --> C["Error Salmon<br/>#ffccbc"]
 46:     C --> D["Failure Red<br/>#ef9a9a"]
 47: 
 48:     style A fill:#c8e6c9,color:#000
 49:     style B fill:#ff9999,color:#000
 50:     style C fill:#ffccbc,color:#000
 51:     style D fill:#ef9a9a,color:#000
 52: ```
 53: 
 54: ---
 55: 
 56: ## Usage Guidelines
 57: 
 58: ### 1. Always Specify Text Color
 59: 
 60: **MANDATORY:** Include `color:#000` for light backgrounds to ensure readability in both light and dark themes.
 61: 
 62: ```mermaid
 63: graph LR
 64:     A["Node Text"]
 65: 
 66:     style A fill:#e3f2fd,color:#000
 67: ```
 68: 
 69: ### 2. Node Type Color Mapping
 70: 
 71: | Node Type | Color | Hex Code | Usage |
 72: |-----------|-------|----------|-------|
 73: | **Entry Point** | Light Yellow | `#fff8e1` | Start nodes, input documents |
 74: | **Process** | Light Purple | `#f3e5f5` | Processing steps, commands |
 75: | **Data/Document** | Light Cyan | `#b2ebf2` | Documents, data stores |
 76: | **Decision** | Pale Orange | `#fff3e0` | Decision nodes, branches |
 77: | **Action** | Light Orange | `#ffe0b2` | Actions, operations |
 78: | **Critical Checkpoint** | Warning Red | `#ff9999` | Human validation, critical decisions |
 79: | **Success** | Success Green | `#c8e6c9` | Final success states |
 80: | **Error/Manual** | Error Salmon | `#ffccbc` | Error handling, manual intervention |
 81: 
 82: ### 3. Hierarchical Color Scheme
 83: 
 84: **Parent ‚Üí Child relationship:**
 85: 
 86: - Parent node: Primary palette color
 87: - Child nodes: Secondary palette color (lighter shade)
 88: 
 89: ```mermaid
 90: graph TB
 91:     A["Parent Node<br/>Primary Color"]
 92:     A --> B["Child Node<br/>Secondary Color"]
 93:     A --> C["Child Node<br/>Secondary Color"]
 94: 
 95:     style A fill:#f3e5f5,color:#000
 96:     style B fill:#e1f5fe,color:#000
 97:     style C fill:#e1f5fe,color:#000
 98: ```
 99: 
100: ---
101: 
102: ## Standard Templates
103: 
104: ### Template 1: System Architecture
105: 
106: **Use Case:** Component hierarchy, system overview
107: 
108: ```mermaid
109: graph TB
110:     A["System"]
111:     A --> B["Component 1"]
112:     A --> C["Component 2"]
113: 
114:     B --> B1["Sub-component 1.1"]
115:     B --> B2["Sub-component 1.2"]
116: 
117:     C --> C1["Sub-component 2.1"]
118:     C --> C2["Sub-component 2.2"]
119: 
120:     style A fill:#e3f2fd,color:#000
121:     style B fill:#fff8e1,color:#000
122:     style C fill:#f3e5f5,color:#000
123:     style B1 fill:#fff9c4,color:#000
124:     style B2 fill:#fff9c4,color:#000
125:     style C1 fill:#e1f5fe,color:#000
126:     style C2 fill:#e1f5fe,color:#000
127: ```
128: 
129: ### Template 2: Workflow Process
130: 
131: **Use Case:** Step-by-step processes, workflows
132: 
133: ```mermaid
134: graph LR
135:     A["Input"] --> B["Process 1"]
136:     B --> C["Document"]
137:     C --> D{"Decision"}
138:     D -->|"Yes"| E["Action"]
139:     D -->|"No"| F["Alternative"]
140:     E --> G["Success"]
141:     F --> G
142: 
143:     style A fill:#fff8e1,color:#000
144:     style B fill:#f3e5f5,color:#000
145:     style C fill:#b2ebf2,color:#000
146:     style D fill:#fff3e0,color:#000
147:     style E fill:#ffe0b2,color:#000
148:     style F fill:#fff9c4,color:#000
149:     style G fill:#c8e6c9,color:#000
150: ```
151: 
152: ### Template 3: Decision Flow
153: 
154: **Use Case:** Complex decision trees, conditional logic
155: 
156: ```mermaid
157: graph TD
158:     A["Start"] --> B{"Condition 1?"}
159:     B -->|"Yes"| C["Path A"]
160:     B -->|"No"| D["Path B"]
161: 
162:     C --> E{"Condition 2?"}
163:     E -->|"Yes"| F["Success"]
164:     E -->|"No"| G["Retry"]
165: 
166:     D --> H["Manual Action"]
167:     H --> F
168:     G --> B
169: 
170:     style A fill:#fff8e1,color:#000
171:     style B fill:#fff3e0,color:#000
172:     style C fill:#b2ebf2,color:#000
173:     style D fill:#ffe0b2,color:#000
174:     style E fill:#fff3e0,color:#000
175:     style F fill:#c8e6c9,color:#000
176:     style G fill:#ffccbc,color:#000
177:     style H fill:#ff9999,color:#000
178: ```
179: 
180: ### Template 4: Validation Gates
181: 
182: **Use Case:** Testing, validation processes
183: 
184: ```mermaid
185: graph TB
186:     A["Code"] --> B["Level 1: Syntax"]
187:     B --> B1["Auto-fix"]
188:     B1 --> C["Level 2: Unit Tests"]
189:     C --> C1["Analyze & Fix"]
190:     C1 --> D["Level 3: Integration"]
191:     D --> D1["Debug"]
192:     D1 --> E["Production"]
193: 
194:     style A fill:#e3f2fd,color:#000
195:     style B fill:#fff8e1,color:#000
196:     style B1 fill:#fff9c4,color:#000
197:     style C fill:#f3e5f5,color:#000
198:     style C1 fill:#e1f5fe,color:#000
199:     style D fill:#b2ebf2,color:#000
200:     style D1 fill:#b2dfdb,color:#000
201:     style E fill:#c8e6c9,color:#000
202: ```
203: 
204: ---
205: 
206: ## Complete Color Reference Table
207: 
208: | Color Name | Hex Code | RGB | Usage Context |
209: |------------|----------|-----|---------------|
210: | **Primary Blue** | `#e3f2fd` | rgb(227, 242, 253) | Top-level system nodes |
211: | **Light Yellow** | `#fff8e1` | rgb(255, 248, 225) | Entry points, inputs |
212: | **Light Purple** | `#f3e5f5` | rgb(243, 229, 245) | Processing steps |
213: | **Light Cyan** | `#b2ebf2` | rgb(178, 235, 242) | Documents, data |
214: | **Light Orange** | `#ffe0b2` | rgb(255, 224, 178) | Actions, commands |
215: | **Pale Yellow** | `#fff9c4` | rgb(255, 249, 196) | Secondary details |
216: | **Very Light Cyan** | `#e1f5fe` | rgb(225, 245, 254) | Secondary details |
217: | **Light Teal** | `#b2dfdb` | rgb(178, 223, 219) | Secondary details |
218: | **Pale Orange** | `#ffecb3` | rgb(255, 236, 179) | Secondary details |
219: | **Pale Orange 2** | `#fff3e0` | rgb(255, 243, 224) | Decision nodes |
220: | **Success Green** | `#c8e6c9` | rgb(200, 230, 201) | Success states |
221: | **Warning Red** | `#ff9999` | rgb(255, 153, 153) | Critical checkpoints |
222: | **Error Salmon** | `#ffccbc` | rgb(255, 204, 188) | Errors, manual steps |
223: | **Failure Red** | `#ef9a9a` | rgb(239, 154, 154) | Failure states |
224: 
225: ---
226: 
227: ## Anti-Patterns to Avoid
228: 
229: ### ‚ùå BAD: No text color specified
230: 
231: ```mermaid
232: graph LR
233:     A["Node Text"]
234: 
235:     style A fill:#e3f2fd
236: ```
237: 
238: **Problem:** Text may be invisible in dark themes.
239: 
240: ### ‚ùå BAD: Inconsistent color scheme
241: 
242: ```mermaid
243: graph LR
244:     A["Node 1"] --> B["Node 2"]
245:     B --> C["Node 3"]
246: 
247:     style A fill:#ff0000,color:#000
248:     style B fill:#00ff00,color:#000
249:     style C fill:#0000ff,color:#000
250: ```
251: 
252: **Problem:** Random colors break visual hierarchy.
253: 
254: ### ‚úÖ GOOD: Consistent palette with text color
255: 
256: ```mermaid
257: graph LR
258:     A["Node 1"] --> B["Node 2"]
259:     B --> C["Node 3"]
260: 
261:     style A fill:#e3f2fd,color:#000
262:     style B fill:#fff8e1,color:#000
263:     style C fill:#f3e5f5,color:#000
264: ```
265: 
266: **Benefit:** Clear hierarchy, theme-compatible.
267: 
268: ---
269: 
270: ## Quick Copy-Paste Templates
271: 
272: ### Basic Node Styles
273: 
274: ```
275: style A fill:#e3f2fd,color:#000    # Primary Blue
276: style B fill:#fff8e1,color:#000    # Light Yellow
277: style C fill:#f3e5f5,color:#000    # Light Purple
278: style D fill:#b2ebf2,color:#000    # Light Cyan
279: style E fill:#ffe0b2,color:#000    # Light Orange
280: ```
281: 
282: ### Detail Node Styles
283: 
284: ```
285: style A1 fill:#fff9c4,color:#000   # Pale Yellow
286: style A2 fill:#e1f5fe,color:#000   # Very Light Cyan
287: style A3 fill:#b2dfdb,color:#000   # Light Teal
288: style A4 fill:#ffecb3,color:#000   # Pale Orange
289: ```
290: 
291: ### Status Node Styles
292: 
293: ```
294: style SUCCESS fill:#c8e6c9,color:#000   # Success Green
295: style WARNING fill:#ff9999,color:#000   # Warning Red
296: style ERROR fill:#ffccbc,color:#000     # Error Salmon
297: style FAIL fill:#ef9a9a,color:#000      # Failure Red
298: ```
299: 
300: ---
301: 
302: ## Version History
303: 
304: - **v1.0** (2025-10-11): Initial palette extraction from PRPs/Model.md
305: - Based on production diagrams: System Components, PRP Architecture, Validation Gates
306: 
307: ---
308: 
309: ## References
310: 
311: - Source: [PRPs/Model.md](../PRPs/Model.md)
312: - Documentation Standard: [CLAUDE.md](../CLAUDE.md) (Mermaid color requirements)
313: - Mermaid Documentation: <https://mermaid.js.org/syntax/flowchart.html#styling-and-classes>
</file>

<file path="examples/prp-decomposition-patterns.md">
  1: # PRP Decomposition Patterns
  2: 
  3: Practical patterns and examples for breaking down large PRPs into manageable sub-PRPs.
  4: 
  5: ## Pattern 1: Phase-Based Decomposition
  6: 
  7: **When to Use**: PRP has 5+ sequential or semi-independent phases
  8: 
  9: **Structure**:
 10: ```
 11: PRP-X.0: [Feature Name] Framework (Meta-PRP)
 12: ‚îú‚îÄ PRP-X.1: Phase 1 Name
 13: ‚îú‚îÄ PRP-X.2: Phase 2 Name
 14: ‚îú‚îÄ PRP-X.3: Phase 3 Name
 15: ‚îî‚îÄ PRP-X.4: Phase 4 Name
 16: ```
 17: 
 18: ### Example: PRP-4 Decomposition
 19: 
 20: **Before (Monolithic)**:
 21: ```
 22: PRP-4: Execute-PRP Command Orchestration
 23: - 1259 lines, 18 hours, HIGH risk
 24: - 6 phases, 27 functions, 30 criteria
 25: - Complexity Score: 71.45/100 ‚Üí RED
 26: ```
 27: 
 28: **After (Decomposed)**:
 29: ```
 30: PRP-4.0: Execute-PRP Framework (Meta-PRP)
 31: ‚îú‚îÄ PRP-4.1: Blueprint Parser
 32: ‚îÇ   ‚Ä¢ 3 hours, LOW risk
 33: ‚îÇ   ‚Ä¢ Parse PRP markdown ‚Üí structured data
 34: ‚îÇ   ‚Ä¢ Extract phases, validation gates, checkpoints
 35: ‚îÇ
 36: ‚îú‚îÄ PRP-4.2: Execution Orchestration Engine
 37: ‚îÇ   ‚Ä¢ 5 hours, MEDIUM risk
 38: ‚îÇ   ‚Ä¢ Phase-by-phase execution loop
 39: ‚îÇ   ‚Ä¢ Progress tracking, logging
 40: ‚îÇ
 41: ‚îú‚îÄ PRP-4.3: Validation Loop Integration
 42: ‚îÇ   ‚Ä¢ 4 hours, MEDIUM risk
 43: ‚îÇ   ‚Ä¢ Run validation gates after each phase
 44: ‚îÇ   ‚Ä¢ Collect results, determine pass/fail
 45: ‚îÇ
 46: ‚îú‚îÄ PRP-4.4: Self-Healing Implementation
 47: ‚îÇ   ‚Ä¢ 4 hours, HIGH risk (isolated!)
 48: ‚îÇ   ‚Ä¢ Error detection patterns
 49: ‚îÇ   ‚Ä¢ Automatic retry logic with backoff
 50: ‚îÇ
 51: ‚îî‚îÄ PRP-4.5: CLI Integration & Testing
 52:     ‚Ä¢ 2 hours, LOW risk
 53:     ‚Ä¢ Wire up ce prp execute command
 54:     ‚Ä¢ End-to-end integration tests
 55: ```
 56: 
 57: **Benefits**:
 58: - Each sub-PRP is GREEN (‚â§5h, focused scope)
 59: - HIGH risk isolated to PRP-4.4
 60: - Clear dependencies: 4.1 ‚Üí 4.2 ‚Üí 4.3 ‚Üí 4.4 ‚Üí 4.5
 61: - Can execute incrementally, validate each step
 62: 
 63: ## Pattern 2: Feature-Based Decomposition
 64: 
 65: **When to Use**: PRP spans multiple functional areas (parser, validator, executor, formatter, etc.)
 66: 
 67: **Structure**: Split by architectural boundaries
 68: 
 69: ### Example: Data Processing System
 70: 
 71: **Before (Monolithic)**:
 72: ```
 73: PRP-X: Data Processing Pipeline
 74: - 1100 lines, 15 hours, MEDIUM risk
 75: - Ingestion + Validation + Transformation + Export
 76: ```
 77: 
 78: **After (Decomposed)**:
 79: ```
 80: PRP-X.0: Data Processing System (Meta-PRP)
 81: ‚îú‚îÄ PRP-X.1: CSV Input Parser
 82: ‚îÇ   ‚Ä¢ Parse CSV/TSV files
 83: ‚îÇ   ‚Ä¢ Handle encoding issues
 84: ‚îÇ   ‚Ä¢ 3 hours, LOW risk
 85: ‚îÇ
 86: ‚îú‚îÄ PRP-X.2: Data Validator
 87: ‚îÇ   ‚Ä¢ Schema validation
 88: ‚îÇ   ‚Ä¢ Business rule checks
 89: ‚îÇ   ‚Ä¢ 4 hours, MEDIUM risk
 90: ‚îÇ
 91: ‚îú‚îÄ PRP-X.3: Transformation Engine
 92: ‚îÇ   ‚Ä¢ Apply data transformations
 93: ‚îÇ   ‚Ä¢ Aggregations, calculations
 94: ‚îÇ   ‚Ä¢ 5 hours, MEDIUM risk
 95: ‚îÇ
 96: ‚îî‚îÄ PRP-X.4: JSON/XML Exporter
 97:     ‚Ä¢ Format output
 98:     ‚Ä¢ Write to file system
 99:     ‚Ä¢ 3 hours, LOW risk
100: ```
101: 
102: **Benefits**:
103: - Each component independently testable
104: - Clear interfaces between modules
105: - Can swap implementations (e.g., XML parser instead of CSV)
106: 
107: ## Pattern 3: Risk-Based Decomposition
108: 
109: **When to Use**: PRP contains HIGH-risk components mixed with safer features
110: 
111: **Strategy**: Isolate risky parts for focused attention
112: 
113: ### Example: API Client with Authentication
114: 
115: **Before (Monolithic)**:
116: ```
117: PRP-Y: External API Client
118: - 950 lines, 12 hours, HIGH risk
119: - OAuth2 + API calls + Error handling
120: ```
121: 
122: **After (Decomposed)**:
123: ```
124: PRP-Y.0: API Client System (Meta-PRP)
125: ‚îú‚îÄ PRP-Y.1: HTTP Client Core
126: ‚îÇ   ‚Ä¢ Basic request/response handling
127: ‚îÇ   ‚Ä¢ 3 hours, LOW risk
128: ‚îÇ
129: ‚îú‚îÄ PRP-Y.2: OAuth2 Authentication (HIGH RISK)
130: ‚îÇ   ‚Ä¢ Token acquisition flow
131: ‚îÇ   ‚Ä¢ Refresh token logic
132: ‚îÇ   ‚Ä¢ Credential storage
133: ‚îÇ   ‚Ä¢ 5 hours, HIGH risk ‚Üí ISOLATED
134: ‚îÇ
135: ‚îú‚îÄ PRP-Y.3: API Endpoint Methods
136: ‚îÇ   ‚Ä¢ GET/POST/PUT/DELETE wrappers
137: ‚îÇ   ‚Ä¢ 2 hours, LOW risk
138: ‚îÇ
139: ‚îî‚îÄ PRP-Y.4: Error Handling & Retry
140:     ‚Ä¢ Network error detection
141:     ‚Ä¢ Exponential backoff
142:     ‚Ä¢ 2 hours, MEDIUM risk
143: ```
144: 
145: **Benefits**:
146: - HIGH risk (OAuth2) gets dedicated focus
147: - Core functionality (Y.1, Y.3) can proceed independently
148: - Y.2 can be reviewed by security experts
149: 
150: ## Pattern 4: Layer-Based Decomposition
151: 
152: **When to Use**: PRP spans multiple architectural layers (UI, business logic, data access)
153: 
154: ### Example: User Management Feature
155: 
156: **Before (Monolithic)**:
157: ```
158: PRP-Z: User Management System
159: - 1050 lines, 14 hours, MEDIUM risk
160: - UI forms + Business logic + Database
161: ```
162: 
163: **After (Decomposed)**:
164: ```
165: PRP-Z.0: User Management (Meta-PRP)
166: ‚îú‚îÄ PRP-Z.1: Database Schema & Migrations
167: ‚îÇ   ‚Ä¢ Users table, indexes
168: ‚îÇ   ‚Ä¢ 2 hours, LOW risk
169: ‚îÇ
170: ‚îú‚îÄ PRP-Z.2: User Service (Business Logic)
171: ‚îÇ   ‚Ä¢ CRUD operations
172: ‚îÇ   ‚Ä¢ Validation rules
173: ‚îÇ   ‚Ä¢ 5 hours, MEDIUM risk
174: ‚îÇ
175: ‚îú‚îÄ PRP-Z.3: REST API Endpoints
176: ‚îÇ   ‚Ä¢ HTTP routes
177: ‚îÇ   ‚Ä¢ Request/response handling
178: ‚îÇ   ‚Ä¢ 3 hours, LOW risk
179: ‚îÇ
180: ‚îî‚îÄ PRP-Z.4: Admin UI Components
181:     ‚Ä¢ User list, forms
182:     ‚Ä¢ Frontend validation
183:     ‚Ä¢ 4 hours, MEDIUM risk
184: ```
185: 
186: **Benefits**:
187: - Bottom-up implementation (Z.1 ‚Üí Z.2 ‚Üí Z.3 ‚Üí Z.4)
188: - Each layer independently testable
189: - Parallel development possible (Z.3 and Z.4)
190: 
191: ## Pattern 5: Criteria-Based Decomposition
192: 
193: **When to Use**: PRP has >30 success criteria spanning multiple concerns
194: 
195: **Strategy**: Group related criteria into logical sub-features
196: 
197: ### Example: Testing Infrastructure
198: 
199: **Before (Monolithic)**:
200: ```
201: PRP-T: Testing Framework Enhancement
202: - 45 success criteria across unit, integration, E2E, performance
203: ```
204: 
205: **After (Decomposed)**:
206: ```
207: PRP-T.0: Testing Framework (Meta-PRP)
208: ‚îú‚îÄ PRP-T.1: Unit Test Infrastructure (10 criteria)
209: ‚îú‚îÄ PRP-T.2: Integration Test Setup (12 criteria)
210: ‚îú‚îÄ PRP-T.3: E2E Test Framework (15 criteria)
211: ‚îî‚îÄ PRP-T.4: Performance Test Suite (8 criteria)
212: ```
213: 
214: ## Anti-Patterns (What NOT to Do)
215: 
216: ### ‚ùå Anti-Pattern 1: Atomic Splitting
217: 
218: **Don't**: Split every phase into its own PRP when they're tightly coupled
219: 
220: **Problem**:
221: ```
222: PRP-A.1: Define data structure
223: PRP-A.2: Write getter for field 1
224: PRP-A.3: Write getter for field 2
225: PRP-A.4: Write getter for field 3
226: ```
227: 
228: **Better**: Keep tightly coupled code together
229: ```
230: PRP-A.1: Define data structure with all accessors
231: ```
232: 
233: ### ‚ùå Anti-Pattern 2: Artificial Boundaries
234: 
235: **Don't**: Split based on arbitrary criteria (e.g., "files starting with A-M vs N-Z")
236: 
237: **Problem**: No logical cohesion, dependencies span sub-PRPs
238: 
239: **Better**: Split based on functional boundaries or risk
240: 
241: ### ‚ùå Anti-Pattern 3: Over-Decomposition
242: 
243: **Don't**: Create 10 sub-PRPs of 1 hour each
244: 
245: **Problem**: Coordination overhead exceeds benefit
246: 
247: **Better**: 3-4 sub-PRPs of 3-5 hours each
248: 
249: ## Decision Tree
250: 
251: ```
252: Start: Is PRP > 1000 lines OR HIGH risk?
253: ‚îÇ
254: ‚îú‚îÄ No ‚Üí GREEN, proceed as-is
255: ‚îÇ
256: ‚îî‚îÄ Yes ‚Üí Is it ‚â•5 phases?
257:     ‚îÇ
258:     ‚îú‚îÄ Yes ‚Üí Use Phase-Based Decomposition
259:     ‚îÇ
260:     ‚îî‚îÄ No ‚Üí Does it span multiple functional areas?
261:         ‚îÇ
262:         ‚îú‚îÄ Yes ‚Üí Use Feature-Based Decomposition
263:         ‚îÇ
264:         ‚îî‚îÄ No ‚Üí Does it mix HIGH risk with LOW/MEDIUM?
265:             ‚îÇ
266:             ‚îú‚îÄ Yes ‚Üí Use Risk-Based Decomposition
267:             ‚îÇ
268:             ‚îî‚îÄ No ‚Üí Does it have >30 criteria?
269:                 ‚îÇ
270:                 ‚îú‚îÄ Yes ‚Üí Use Criteria-Based Decomposition
271:                 ‚îÇ
272:                 ‚îî‚îÄ No ‚Üí Consider Layer-Based or custom split
273: ```
274: 
275: ## Meta-PRP Template
276: 
277: When decomposing a PRP, create a meta-PRP (PRP-X.0) to track the overall feature:
278: 
279: ```markdown
280: ---
281: prp_id: PRP-X.0
282: feature_name: [Feature Name] Framework
283: status: new
284: type: meta-prp
285: sub_prps:
286:   - PRP-X.1
287:   - PRP-X.2
288:   - PRP-X.3
289: ---
290: 
291: # [Feature Name] Framework (Meta-PRP)
292: 
293: ## Purpose
294: Coordinate implementation of [feature] across multiple sub-PRPs.
295: 
296: ## Sub-PRPs
297: 1. **PRP-X.1**: [Name] (Xh, RISK)
298:    - Description
299:    - Dependencies: None
300: 
301: 2. **PRP-X.2**: [Name] (Xh, RISK)
302:    - Description
303:    - Dependencies: PRP-X.1
304: 
305: 3. **PRP-X.3**: [Name] (Xh, RISK)
306:    - Description
307:    - Dependencies: PRP-X.1, PRP-X.2
308: 
309: ## Execution Order
310: PRP-X.1 ‚Üí PRP-X.2 ‚Üí PRP-X.3
311: 
312: ## Integration Points
313: - Describe how sub-PRPs integrate
314: - Shared interfaces, data structures
315: 
316: ## Overall Success Criteria
317: - [ ] All sub-PRPs executed successfully
318: - [ ] Integration tests pass
319: - [ ] Feature delivers user value
320: ```
321: 
322: ## Real-World Example: PRP-4 Analysis
323: 
324: Run analyzer to see decomposition recommendations:
325: 
326: ```bash
327: cd tools
328: uv run ce prp analyze ../PRPs/executed/PRP-4-execute-prp-orchestration.md
329: ```
330: 
331: Output shows:
332: - Complexity Score: 71.45/100 (RED)
333: - Recommendations: Phase-based decomposition into 6 sub-PRPs
334: - Suggestion: Isolate HIGH-risk self-healing component
335: 
336: ## Tips for Success
337: 
338: 1. **Start with Meta-PRP**: Create PRP-X.0 first to plan decomposition
339: 2. **Document Dependencies**: Make execution order explicit
340: 3. **Keep Interfaces Clear**: Define how sub-PRPs interact
341: 4. **Test Incrementally**: Validate each sub-PRP before next one
342: 5. **Review Collectively**: Ensure all sub-PRPs together deliver feature
343: 
344: ## Validation Checklist
345: 
346: After decomposition, verify:
347: - [ ] Each sub-PRP is GREEN (‚â§700 lines, ‚â§8h)
348: - [ ] HIGH risk components isolated
349: - [ ] Dependencies are minimal and explicit
350: - [ ] Integration points well-defined
351: - [ ] Can execute incrementally with validation gates
352: 
353: ---
354: 
355: **See Also**:
356: - [PRP Sizing Guidelines](../docs/prp-sizing-guidelines.md)
357: - [PRP-8: Sizing Constraint Analysis](../PRPs/feature-requests/PRP-8-prp-sizing-constraint-analysis-and-optimal-breakdown-strategy.md)
</file>

<file path="examples/README.md">
 1: # Code Patterns & Examples
 2: 
 3: This directory contains reusable code patterns for reference during PRP implementation.
 4: 
 5: ## Structure
 6: 
 7: - `patterns/` - Common implementation patterns
 8:   - API patterns
 9:   - Database patterns
10:   - Test patterns
11:   - Error handling patterns
12: 
13: ## Usage
14: 
15: Reference these patterns in PRPs CONTEXT section:
16: 
17: - Similar implementation: `examples/patterns/api-crud.py:15-42`
18: 
19: ## Adding Patterns
20: 
21: When you implement a particularly good solution, extract it as a pattern:
22: 
23: 1. Create a new file in `patterns/` with descriptive name
24: 2. Include clear comments explaining the pattern
25: 3. Add usage notes and gotchas
26: 4. Reference from future PRPs
27: 
28: ## Pattern Categories
29: 
30: ### API Patterns
31: 
32: - RESTful endpoint design
33: - Request validation
34: - Response formatting
35: - Error handling
36: 
37: ### Database Patterns
38: 
39: - Query builders
40: - Transaction handling
41: - Schema migrations
42: - Connection pooling
43: 
44: ### Test Patterns
45: 
46: - Unit test structure
47: - Integration test setup
48: - Mock patterns
49: - Fixture management
50: 
51: ### Error Handling Patterns
52: 
53: - Exception hierarchy
54: - Error logging
55: - User-facing error messages
56: - Recovery strategies
57: 
58: ## Contributing
59: 
60: Keep patterns:
61: 
62: - **Simple**: Single responsibility
63: - **Documented**: Clear comments
64: - **Tested**: Include test examples
65: - **Practical**: Real-world usage
</file>

<file path="examples/tmp-directory-convention.md">
  1: # tmp/ Directory Convention
  2: 
  3: ## Rule: Keep Working Directory Clean
  4: 
  5: **Only final deliverables in tracked directories. All work-in-progress goes to tmp/**
  6: 
  7: ## Directory Structure
  8: 
  9: ```
 10: ctx-eng-plus/
 11: ‚îú‚îÄ‚îÄ PRPs/                    # ONLY final PRP documents
 12: ‚îÇ   ‚îú‚îÄ‚îÄ executed/
 13: ‚îÇ   ‚îî‚îÄ‚îÄ feature-requests/
 14: ‚îú‚îÄ‚îÄ tmp/                     # ALL work-in-progress (gitignored)
 15: ‚îÇ   ‚îú‚îÄ‚îÄ batch-gen/          # Batch generation heartbeat files
 16: ‚îÇ   ‚îú‚îÄ‚îÄ feature-requests/   # INITIAL.md and PLAN.md files
 17: ‚îÇ   ‚îî‚îÄ‚îÄ scratch/            # Any other temporary work
 18: ‚îî‚îÄ‚îÄ examples/               # Documentation and examples
 19: ```
 20: 
 21: ## Rules
 22: 
 23: ### 1. INITIAL.md and PLAN.md
 24: 
 25: **Location**: `tmp/feature-requests/<feature-name>/`
 26: 
 27: **Example**:
 28: ```bash
 29: # ‚úÖ CORRECT
 30: tmp/feature-requests/syntropy-tool-management/INITIAL.md
 31: tmp/feature-requests/syntropy-tool-management/PLAN.md
 32: 
 33: # ‚ùå WRONG
 34: feature-requests/syntropy-tool-management/INITIAL.md
 35: feature-requests/syntropy-tool-management/PLAN.md
 36: ```
 37: 
 38: ### 2. Batch Generation Heartbeat Files
 39: 
 40: **Location**: `tmp/batch-gen/`
 41: 
 42: **Example**:
 43: ```bash
 44: # ‚úÖ CORRECT
 45: tmp/batch-gen/PRP-30.1.1.status
 46: tmp/batch-gen/PRP-30.2.1.status
 47: 
 48: # ‚ùå WRONG
 49: .tmp/batch-gen/PRP-30.1.1.status  # No leading dot
 50: ```
 51: 
 52: ### 3. PRPs (Final Deliverables)
 53: 
 54: **Location**: `PRPs/feature-requests/` or `PRPs/executed/`
 55: 
 56: **Example**:
 57: ```bash
 58: # ‚úÖ CORRECT
 59: PRPs/feature-requests/PRP-30.1.1-syntropy-mcp-tool-management.md
 60: PRPs/executed/PRP-29-haiku-optimized-prp-guidelines.md
 61: 
 62: # ‚ùå WRONG
 63: tmp/PRPs/PRP-30.1.1-syntropy-mcp-tool-management.md
 64: ```
 65: 
 66: ## Workflow Example
 67: 
 68: ### Generate PRP from INITIAL.md
 69: 
 70: ```bash
 71: # Step 1: Create INITIAL.md in tmp/
 72: mkdir -p tmp/feature-requests/my-feature
 73: vim tmp/feature-requests/my-feature/INITIAL.md
 74: 
 75: # Step 2: Generate PRP (output goes to PRPs/)
 76: /generate-prp tmp/feature-requests/my-feature/INITIAL.md
 77: # Output: PRPs/feature-requests/PRP-X-my-feature.md
 78: 
 79: # Step 3: Clean up (optional)
 80: rm -rf tmp/feature-requests/my-feature
 81: ```
 82: 
 83: ### Batch Generation from PLAN.md
 84: 
 85: ```bash
 86: # Step 1: Create PLAN.md in tmp/
 87: mkdir -p tmp/feature-requests/big-feature
 88: vim tmp/feature-requests/big-feature/PLAN.md
 89: 
 90: # Step 2: Generate batch PRPs
 91: /batch-gen-prp tmp/feature-requests/big-feature/PLAN.md
 92: # Heartbeat files: tmp/batch-gen/PRP-X.Y.Z.status
 93: # Output PRPs: PRPs/feature-requests/PRP-X.Y.Z-*.md
 94: 
 95: # Step 3: Clean up (automatic)
 96: # Heartbeat files cleaned up after generation completes
 97: ```
 98: 
 99: ## Git Configuration
100: 
101: **Ensure tmp/ is gitignored**:
102: 
103: ```gitignore
104: # .gitignore
105: tmp/
106: .tmp/
107: *.tmp
108: ```
109: 
110: ## Benefits
111: 
112: 1. **Clean working directory**: Only final deliverables tracked in git
113: 2. **Easy cleanup**: Delete `tmp/` anytime without losing work
114: 3. **Clear separation**: Work-in-progress vs. deliverables
115: 4. **No git noise**: No accidental commits of INITIAL.md or heartbeat files
116: 
117: ## Migration
118: 
119: If you have existing files in wrong locations:
120: 
121: ```bash
122: # Move INITIAL.md files
123: mkdir -p tmp/feature-requests/
124: mv feature-requests/* tmp/feature-requests/
125: 
126: # Move batch-gen files (if any)
127: mkdir -p tmp/batch-gen/
128: mv .tmp/batch-gen/* tmp/batch-gen/ 2>/dev/null || true
129: rmdir .tmp/batch-gen .tmp 2>/dev/null || true
130: ```
</file>

<file path="examples/templates/PRP-0-CONTEXT-ENGINEERING.md">
  1: ---
  2: prp_id: PRP-0
  3: title: Context Engineering Framework Installation
  4: status: executed
  5: created: {TIMESTAMP}
  6: executed: {TIMESTAMP}
  7: batch: 0
  8: phase: 0
  9: order: 0
 10: estimated_hours: {INSTALL_TIME}
 11: complexity: low
 12: risk_level: low
 13: ce_version: {CE_VERSION}
 14: installation_method: {METHOD}
 15: ---
 16: 
 17: # PRP-0: Context Engineering Framework Installation
 18: 
 19: ## üìã TL;DR
 20: 
 21: **What**: Installed Context Engineering (CE) framework version {CE_VERSION} into {PROJECT_NAME}
 22: 
 23: **When**: {TIMESTAMP}
 24: 
 25: **How**: {INSTALLATION_METHOD}
 26: 
 27: **Result**: CE 1.1 framework fully installed with /system/ organization
 28: 
 29: ---
 30: 
 31: ## Installation Details
 32: 
 33: ### CE Version
 34: 
 35: **Version**: {CE_VERSION}
 36: **Release Date**: {CE_RELEASE_DATE}
 37: **Distribution Package**: `ce-infrastructure.xml` ({SIZE}KB)
 38: 
 39: ### Installation Method
 40: 
 41: **Method**: {METHOD}
 42: 
 43: **Options**:
 44: - `greenfield` - New project, no existing CE
 45: - `mature-project` - Existing code, added CE
 46: - `existing-ce` - Upgraded CE 1.0 ‚Üí CE 1.1
 47: - `partial-ce` - Completed incomplete installation
 48: 
 49: ### Installation Date
 50: 
 51: **Started**: {START_TIMESTAMP}
 52: **Completed**: {END_TIMESTAMP}
 53: **Duration**: {DURATION} minutes
 54: 
 55: ---
 56: 
 57: ## Components Installed
 58: 
 59: ### Framework Memories (23 files)
 60: 
 61: **Location**: `.serena/memories/system/`
 62: 
 63: **Critical Memories (6)**:
 64: - code-style-conventions.md
 65: - suggested-commands.md
 66: - task-completion-checklist.md
 67: - testing-standards.md
 68: - tool-usage-syntropy.md
 69: - use-syntropy-tools-not-bash.md
 70: 
 71: **Regular Memories (17)**:
 72: - batch-generation-patterns.md
 73: - ce-tool-patterns.md
 74: - complexity-estimation.md
 75: - context-drift-monitoring.md
 76: - file-structure-best-practices.md
 77: - git-worktree-patterns.md
 78: - prp-execution-checklist.md
 79: - prp-sizing-thresholds.md
 80: - sequential-thinking-usage.md
 81: - syntropy-mcp-architecture.md
 82: - syntropy-tool-management.md
 83: - testing-strategy-pattern.md
 84: - token-optimization-strategies.md
 85: - tool-selection-decision-tree.md
 86: - validation-levels.md
 87: - worktree-conflict-resolution.md
 88: - xml-package-generation.md
 89: 
 90: ### Framework Examples (21 files)
 91: 
 92: **Location**: `.ce/examples/system/`
 93: 
 94: **Files Installed**:
 95: {LIST_OF_EXAMPLE_FILES}
 96: 
 97: ### Framework Commands (11 files)
 98: 
 99: **Location**: `.claude/commands/`
100: 
101: **Commands Installed**:
102: - batch-exe-prp.md
103: - batch-gen-prp.md
104: - denoise.md
105: - execute-prp.md
106: - generate-prp.md
107: - peer-review.md
108: - sync-with-syntropy.md
109: - syntropy-health.md
110: - tools-misuse-scan.md
111: - update-context.md
112: - vacuum.md
113: 
114: ### Tool Source Code (33 files)
115: 
116: **Location**: `tools/`
117: 
118: **Modules Installed**:
119: {LIST_OF_TOOL_MODULES}
120: 
121: ### CLAUDE.md Sections
122: 
123: **Framework Sections Added**:
124: - Communication
125: - Core Principles
126: - UV Package Management
127: - Ad-Hoc Code Policy
128: - Quick Commands
129: - Tool Naming Convention
130: - Allowed Tools Summary
131: - Command Permissions
132: - Quick Tool Selection
133: - Project Structure
134: - Testing Standards
135: - Code Quality
136: 
137: ---
138: 
139: ## Validation Results
140: 
141: ### Component Verification
142: 
143: ```bash
144: # Run validation checklist
145: {VALIDATION_COMMAND_OUTPUT}
146: ```
147: 
148: **Results**:
149: - ‚úÖ 23 system memories installed
150: - ‚úÖ 21 system examples installed
151: - ‚úÖ 11 framework commands installed
152: - ‚úÖ 33 tool files installed
153: - ‚úÖ CLAUDE.md framework sections added
154: - ‚úÖ CE 1.1 /system/ organization verified
155: 
156: ### Token Counts
157: 
158: **Framework Documentation**:
159: - System memories: ~{MEMORY_TOKENS}k tokens
160: - System examples: ~{EXAMPLE_TOKENS}k tokens
161: - Commands: ~{COMMAND_TOKENS}k tokens
162: - **Total**: ~{TOTAL_TOKENS}k tokens
163: 
164: ---
165: 
166: ## Project Integration
167: 
168: ### Existing Project Context
169: 
170: **Project Name**: {PROJECT_NAME}
171: **Project Type**: {PROJECT_TYPE}
172: **Primary Language**: {PRIMARY_LANGUAGE}
173: **Repository**: {REPO_URL}
174: 
175: **Pre-Installation State**:
176: {PRE_INSTALL_STATE}
177: 
178: ### Post-Installation Configuration
179: 
180: **Syntropy MCP**:
181: - Status: {MCP_STATUS}
182: - Servers: {MCP_SERVERS}
183: 
184: **Linear Integration**:
185: - Status: {LINEAR_STATUS}
186: - Project: {LINEAR_PROJECT}
187: - Team: {LINEAR_TEAM}
188: 
189: **UV Tools**:
190: - Status: {UV_STATUS}
191: - Python Version: {PYTHON_VERSION}
192: 
193: ---
194: 
195: ## Next Steps
196: 
197: ### Immediate Actions
198: 
199: 1. **Test framework commands**:
200:    ```bash
201:    /generate-prp
202:    /vacuum --dry-run
203:    /syntropy-health
204:    ```
205: 
206: 2. **Configure project settings**:
207:    - Update `.claude/settings.local.json` with project-specific permissions
208:    - Update `CLAUDE.md` with user sections
209: 
210: 3. **Create first user PRP**:
211:    - Document initial feature or bug fix
212:    - Practice PRP workflow
213: 
214: ### Recommended Reading
215: 
216: **Essential Documentation**:
217: - `.ce/examples/system/TOOL-USAGE-GUIDE.md` - Tool selection reference
218: - `.ce/examples/system/prp-decomposition-patterns.md` - PRP sizing
219: - `.serena/memories/system/task-completion-checklist.md` - Workflow checklist
220: 
221: **Migration Guide**:
222: - `examples/INITIALIZATION.md` - Complete CE 1.1 initialization guide (5-phase workflow, scenario-aware)
223: 
224: ---
225: 
226: ## Troubleshooting
227: 
228: **Issue**: Commands not found
229: 
230: **Solution**:
231: ```bash
232: # Verify commands directory
233: ls .claude/commands/
234: 
235: # Check Claude Code settings
236: cat .claude/settings.local.json | grep commands
237: ```
238: 
239: **Issue**: MCP servers not connected
240: 
241: **Solution**:
242: ```bash
243: # Remove auth cache
244: rm -rf ~/.mcp-auth
245: 
246: # Restart Claude Code
247: /mcp
248: ```
249: 
250: ---
251: 
252: ## Changelog
253: 
254: ### {TIMESTAMP} - Initial Installation
255: 
256: - Installed CE {CE_VERSION} via {INSTALLATION_METHOD}
257: - Added 23 framework memories to `.serena/memories/system/`
258: - Added 21 framework examples to `.ce/examples/system/`
259: - Added 11 framework commands to `.claude/commands/`
260: - Configured CLAUDE.md with framework sections
261: 
262: ---
263: 
264: ## References
265: 
266: - **CE Framework Documentation**: `.ce/examples/system/`
267: - **Migration Guides**: `examples/workflows/migration-*.md`
268: - **Master Initialization Guide**: `examples/INITIALIZATION.md`
269: - **Repomix Packages**: `.ce/ce-infrastructure.xml`, `.ce/ce-workflow-docs.xml`
270: 
271: ---
272: 
273: **Installation Completed**: {TIMESTAMP}
274: **Installed By**: {INSTALLER_NAME}
275: **CE Version**: {CE_VERSION}
</file>

<file path="examples/model/SystemModel.md">
   1: # Context Engineering Management System
   2: 
   3: **Version:** 1.0
   4: **Type:** System Model Documentation
   5: **Purpose:** Formal specification of autonomous AI-driven development framework
   6: 
   7: > **‚ö†Ô∏è Model Document Notice**
   8: >
   9: > This document describes the **target architecture** and **design specification** for the Context Engineering Management system. Features marked with üîú indicate planned capabilities not yet fully implemented. Refer to individual tool documentation ([tools/README.md](../tools/README.md)) for current implementation status.
  10: >
  11: > **Implementation Status:**
  12: >
  13: > - ‚úÖ **Implemented:** Core validation (L1-L3), git operations, context management, run_py tool
  14: > - üîú **Planned:** PRP-aware state management, L4 pattern conformance automation, drift tracking commands
  15: >
  16: > Performance metrics represent a mix of research-backed claims (cited) and internal observations (marked as such). See [Section 8](#8-performance-metrics) for methodology details.
  17: 
  18: ---
  19: 
  20: ## 1. System Overview
  21: 
  22: ### 1.1 Definition
  23: 
  24: **Context Engineering Management** is a systematic framework for autonomous AI-driven software development that achieves 10-100x improvement over prompt engineering through complete context provision (baseline: 10x via structured prompts, up to 100x with full MCP integration and self-healing). The system eliminates hallucinations by treating missing context as compilation errors, enabling AI agents to deliver production-ready code without human intervention during implementation.
  25: 
  26: **Performance Claims:**
  27: 
  28: - **Research-Backed Baseline:** Traditional AI code generation achieves 35-45% success rate (GitHub Copilot evaluation studies)
  29: - **Internal Observations (n=4 case studies):** Context Engineering framework achieves 85-97% success rate and 10-24x productivity improvement for production features
  30: - **Exceptional Cases:** Up to 100x speedup when combining context engineering + Serena MCP + self-healing (documented in Section 8.1 case study)
  31: 
  32: See [Section 8](#8-performance-metrics) for detailed methodology and case studies.
  33: 
  34: ### 1.2 Core Principle: Context-as-Compiler
  35: 
  36: | Traditional Compiler | Context Engineering |
  37: |---------------------|---------------------|
  38: | Source code ‚Üí Executable | Requirements ‚Üí Production code |
  39: | Missing headers ‚Üí Compile error | Missing context ‚Üí Hallucination |
  40: | Type checking | Validation gates |
  41: | Linker errors | Integration failures |
  42: | Build output | Autonomous implementation |
  43: 
  44: **Key Insight:** Complete context provision is necessary and sufficient for reliable AI code generation.
  45: 
  46: ### 1.3 System Components
  47: 
  48: ```mermaid
  49: graph TB
  50:     A["Context Engineering Management"]
  51: 
  52:     A --> B["PRP System"]
  53:     B --> B1["Structured specifications"]
  54:     B --> B2["Self-healing templates"]
  55:     B --> B3["Validation gates"]
  56: 
  57:     A --> C["Four Pillars Architecture"]
  58:     C --> C1["WRITE - Persistence"]
  59:     C --> C2["SELECT - Retrieval"]
  60:     C --> C3["COMPRESS - Efficiency"]
  61:     C --> C4["ISOLATE - Safety"]
  62: 
  63:     A --> D["Tool Ecosystem"]
  64:     D --> D1["run_py - Execution"]
  65:     D --> D2["ce CLI - Operations"]
  66:     D --> D3["MCP Integration"]
  67: 
  68:     A --> E["Quality Framework"]
  69:     E --> E1["4-level validation (L1-L4)"]
  70:     E --> E2["Self-healing loops"]
  71:     E --> E3["Confidence scoring"]
  72: 
  73:     style A fill:#e3f2fd,color:#000
  74:     style B fill:#fff8e1,color:#000
  75:     style C fill:#f3e5f5,color:#000
  76:     style D fill:#b2ebf2,color:#000
  77:     style E fill:#ffe0b2,color:#000
  78:     style B1 fill:#fff9c4,color:#000
  79:     style B2 fill:#fff9c4,color:#000
  80:     style B3 fill:#fff9c4,color:#000
  81:     style C1 fill:#e1f5fe,color:#000
  82:     style C2 fill:#e1f5fe,color:#000
  83:     style C3 fill:#e1f5fe,color:#000
  84:     style C4 fill:#e1f5fe,color:#000
  85:     style D1 fill:#b2dfdb,color:#000
  86:     style D2 fill:#b2dfdb,color:#000
  87:     style D3 fill:#b2dfdb,color:#000
  88:     style E1 fill:#ffecb3,color:#000
  89:     style E2 fill:#ffecb3,color:#000
  90:     style E3 fill:#ffecb3,color:#000
  91: ```
  92: 
  93: ### See Also
  94: 
  95: - [Context Engineering Framework: Complete Documentation Suite](../docs/research/00-index.md) - Overview of all documentation and framework philosophy
  96: - [Context Engineering Foundations](../docs/research/02-context-engineering-foundations.md) - Deep dive into core principles and context-as-compiler mental model
  97: 
  98: ---
  99: 
 100: ## 2. Evolution & Philosophy
 101: 
 102: ### 2.1 Three-Stage Evolution
 103: 
 104: | Stage | Method | Approach | Success Rate | Bottleneck |
 105: |-------|--------|----------|-------------|------------|
 106: | **Stage 1** | Vibe Coding | Trial-and-error prompting | 10-20% | No structure |
 107: | **Stage 2** | Prompt Engineering | Structured prompts with examples | 40-60% | Context scattered |
 108: | **Stage 3** | Context Engineering | Complete context provision | 85-97% | None (systematic) |
 109: 
 110: **Improvement Factor:** 4-9x success rate improvement from Stage 1 to Stage 3 (85-97% vs 10-20%), with corresponding speed improvements through systematic automation.
 111: 
 112: **Methodology Note:** Success rates are based on internal observations from case studies (n=4 PRPs documented). Research-backed baseline (35-45% for traditional AI code generation) from GitHub Copilot evaluation studies. See [References](#references) for peer-reviewed claims vs internal observations.
 113: 
 114: ### 2.2 Context-as-Compiler Mental Model
 115: 
 116: **Traditional Programming:**
 117: 
 118: ```mermaid
 119: graph LR
 120:     A["Source Code + Headers + Libraries"] --> B["Compiler"]
 121:     B --> C["Executable"]
 122:     D["Missing dependency"] -.-> B
 123:     D -.->|"Error"| E["Compilation Fails"]
 124: 
 125:     style A fill:#e3f2fd,color:#000
 126:     style B fill:#fff8e1,color:#000
 127:     style C fill:#c8e6c9,color:#000
 128:     style D fill:#ffccbc,color:#000
 129:     style E fill:#ef9a9a,color:#000
 130: ```
 131: 
 132: **Context Engineering:**
 133: 
 134: ```mermaid
 135: graph LR
 136:     A["Requirements + Context + Patterns"] --> B["AI Agent"]
 137:     B --> C["Production Code"]
 138:     D["Missing context"] -.-> B
 139:     D -.->|"Hallucination"| E["Incorrect Output"]
 140: 
 141:     style A fill:#e3f2fd,color:#000
 142:     style B fill:#fff8e1,color:#000
 143:     style C fill:#c8e6c9,color:#000
 144:     style D fill:#ffccbc,color:#000
 145:     style E fill:#ef9a9a,color:#000
 146: ```
 147: 
 148: **Implication:** Provide complete context upfront, not iteratively.
 149: 
 150: #### 2.2.1 Concrete Mappings
 151: 
 152: | Traditional Compiler | Context Engineering | Consequence |
 153: |---------------------|---------------------|----|
 154: | Missing header file | Missing validation gate | Compilation fails ‚Üí Systematic validation failure |
 155: | Unresolved symbol | Missing MCP context | Linker error ‚Üí Hallucinated implementation |
 156: | Type mismatch | Schema mismatch | Type error ‚Üí Invalid data structure |
 157: | No optimization flags | No quality gates (L1-L4) | Slow build ‚Üí Low confidence code |
 158: | Runtime crash | No self-healing loop | Debug cycle ‚Üí Automatic fixing |
 159: 
 160: **Application:** When designing PRP context, ask: "What information would a compiler need to ensure compilation succeeds?" Then provide it exhaustively.
 161: 
 162: ### 2.3 Philosophical Principles
 163: 
 164: 1. **No Fishy Fallbacks**
 165:    - Fast failure with actionable error messages
 166:    - No silent error masking
 167:    - Exceptions thrown for troubleshooting
 168: 
 169: 2. **KISS (Keep It Simple, Stupid)**
 170:    - Simple solutions over clever code
 171:    - Minimal dependencies
 172:    - Direct implementation
 173: 
 174: 3. **Real Functionality Testing**
 175:    - No mocks in production code
 176:    - No fake results or hardcoded success messages
 177:    - Real values, real validation
 178: 
 179: 4. **Strict Enforcement**
 180:    - 3 LOC limit for ad-hoc code (non-negotiable)
 181:    - UV package management (no manual edits)
 182:    - All validation gates must pass (10/10 confidence required - includes L4 pattern conformance)
 183: 
 184: ### See Also
 185: 
 186: - [Context Engineering Foundations](../docs/research/02-context-engineering-foundations.md) - Detailed explanation of three-stage evolution and context-as-compiler philosophy
 187: - [Best Practices and Anti-Patterns](../docs/research/09-best-practices-antipatterns.md) - Comprehensive coverage of KISS, No Fishy Fallbacks, and Real Functionality Testing principles
 188: 
 189: ---
 190: 
 191: ## 3. Architecture
 192: 
 193: ### 3.1 Four Pillars
 194: 
 195: ```mermaid
 196: graph LR
 197:     A["Context Engineering"] --> B["WRITE"]
 198:     A --> C["SELECT"]
 199:     A --> D["COMPRESS"]
 200:     A --> E["ISOLATE"]
 201: 
 202:     B --> B1["Serena Memories"]
 203:     B --> B2["Git Checkpoints"]
 204:     B --> B3["Validation Results"]
 205: 
 206:     C --> C1["find_symbol"]
 207:     C --> C2["search_for_pattern"]
 208:     C --> C3["Context7 Docs"]
 209: 
 210:     D --> D1["Overview-first"]
 211:     D --> D2["Targeted Reads"]
 212:     D --> D3["Token Efficiency"]
 213: 
 214:     E --> E1["Validation Gates"]
 215:     E --> E2["Checkpoints"]
 216:     E --> E3["Error Boundaries"]
 217: 
 218:     style A fill:#e3f2fd,color:#000
 219:     style B fill:#fff8e1,color:#000
 220:     style C fill:#f3e5f5,color:#000
 221:     style D fill:#b2ebf2,color:#000
 222:     style E fill:#ffe0b2,color:#000
 223:     style B1 fill:#fff9c4,color:#000
 224:     style B2 fill:#fff9c4,color:#000
 225:     style B3 fill:#fff9c4,color:#000
 226:     style C1 fill:#e1f5fe,color:#000
 227:     style C2 fill:#e1f5fe,color:#000
 228:     style C3 fill:#e1f5fe,color:#000
 229:     style D1 fill:#b2dfdb,color:#000
 230:     style D2 fill:#b2dfdb,color:#000
 231:     style D3 fill:#b2dfdb,color:#000
 232:     style E1 fill:#ffccbc,color:#000
 233:     style E2 fill:#ffccbc,color:#000
 234:     style E3 fill:#ffccbc,color:#000
 235: ```
 236: 
 237: #### 3.1.0 Pillar Interaction Patterns
 238: 
 239: The Four Pillars work together in a continuous cycle:
 240: 
 241: ```mermaid
 242: graph TB
 243:     W["WRITE<br/>Persist insights"] -->|"Enables retrieval from"| S["SELECT<br/>Find context"]
 244:     S -->|"Informs optimization of"| C["COMPRESS<br/>Reduce tokens"]
 245:     C -->|"Respects boundaries from"| I["ISOLATE<br/>Safety gates"]
 246:     I -->|"Validates and stores in"| W
 247: 
 248:     W1["Examples: Memories,<br/>Checkpoints, Logs"] -.-> W
 249:     S1["Examples: find_symbol,<br/>search_for_pattern"] -.-> S
 250:     C1["Examples: Overview-first,<br/>Targeted reads"] -.-> C
 251:     I1["Examples: Validation gates,<br/>Error boundaries"] -.-> I
 252: 
 253:     style W fill:#fff8e1,color:#000
 254:     style S fill:#f3e5f5,color:#000
 255:     style C fill:#b2ebf2,color:#000
 256:     style I fill:#ffe0b2,color:#000
 257:     style W1 fill:#fff9c4,color:#000
 258:     style S1 fill:#e1f5fe,color:#000
 259:     style C1 fill:#b2dfdb,color:#000
 260:     style I1 fill:#ffccbc,color:#000
 261: ```
 262: 
 263: **Usage Patterns:**
 264: 
 265: | Scenario | Pillar Sequence | Outcome |
 266: |----------|-----------------|---------|
 267: | Implementing new feature | WRITE context ‚Üí SELECT similar patterns ‚Üí COMPRESS ‚Üí ISOLATE test | Complete implementation with precedents |
 268: | Debugging failure | SELECT error info ‚Üí ISOLATE root cause ‚Üí WRITE findings ‚Üí COMPRESS learnings | Fast diagnosis with documented patterns |
 269: | Refactoring code | SELECT impact analysis ‚Üí WRITE rollback point ‚Üí COMPRESS changes ‚Üí ISOLATE validation | Safe refactoring with checkpoints |
 270: | Context recovery (crashed session) | SELECT from git ‚Üí WRITE to memory ‚Üí COMPRESS overview ‚Üí ISOLATE validation | Resume from last checkpoint |
 271: 
 272: #### 3.1.1 WRITE: Persistence Layer
 273: 
 274: **Purpose:** Maintain state across sessions and context windows
 275: 
 276: **Mechanisms:**
 277: 
 278: - **Serena Memories:** Project knowledge (structure, conventions, patterns)
 279: - **Git Checkpoints:** Code state at validation gates
 280: - **Validation Logs:** Test results, error history
 281: 
 282: **PRP-Scoped State Management:**
 283: 
 284: To prevent information leakage and desynchronization across multiple PRP executions:
 285: 
 286: 1. **Checkpoint Naming Convention:**
 287: 
 288:    ```
 289:    checkpoint-{prp_id}-{phase}-{timestamp}
 290:    Example: checkpoint-PRP-003-implementation-1728934567
 291:    ```
 292: 
 293: 2. **Memory Namespacing:**
 294: 
 295:    ```python
 296:    # PRP-scoped memory operations (prevents state leakage)
 297:    prp_id = "PRP-003"
 298:    write_memory(f"{prp_id}-checkpoint-phase2", "Type definitions complete, 0 errors")
 299:    checkpoint = read_memory(f"{prp_id}-checkpoint-latest")
 300:    write_memory(f"{prp_id}-learnings", "Pattern: Use transaction wrapper...")
 301:    ```
 302: 
 303: 3. **Checkpoint Lifecycle:**
 304:    - **Create:** At each validation gate during PRP execution
 305:    - **Restore:** `git checkout checkpoint-{prp_id}-{phase}`
 306:    - **Cleanup:** Delete temporary checkpoints after PRP completion (retain final checkpoint only)
 307: 
 308: **Operations:**
 309: 
 310: ```python
 311: # Create PRP-scoped checkpoint
 312: write_memory(f"{prp_id}-checkpoint-types", "Type definitions complete, 0 errors")
 313: 
 314: # Restore PRP context
 315: checkpoint = read_memory(f"{prp_id}-checkpoint-latest")
 316: 
 317: # Track PRP-specific learnings
 318: write_memory(f"{prp_id}-learnings-feature-x", "Pattern: Use transaction wrapper for multi-step DB ops")
 319: 
 320: # Cleanup after PRP completion
 321: delete_memory(f"{prp_id}-checkpoint-*")  # Remove ephemeral checkpoints
 322: delete_memory(f"{prp_id}-learnings-*")   # Archive or remove PRP-specific learnings
 323: ```
 324: 
 325: **PRP ID Tracking Across Sessions:**
 326: 
 327: The `prp_id` is injected and persisted through multiple mechanisms:
 328: 
 329: 1. **Session Initialization:**
 330: 
 331:    ```bash
 332:    # User starts PRP execution with explicit ID
 333:    ce prp start PRP-005
 334:    # Creates session state file: .ce/active_prp_session
 335:    ```
 336: 
 337: 2. **Session State Persistence:**
 338: 
 339:    ```python
 340:    # .ce/active_prp_session (JSON)
 341:    {
 342:      "prp_id": "PRP-005",
 343:      "started_at": "2025-10-12T14:30:00Z",
 344:      "phase": "implementation",
 345:      "checkpoint_count": 3
 346:    }
 347:    ```
 348: 
 349: 3. **Automatic Injection:**
 350:    - All `ce prp` commands read from `.ce/active_prp_session`
 351:    - Memory operations automatically namespace using active PRP ID
 352:    - Git checkpoint creation includes PRP ID from session state
 353: 
 354: 4. **Session Cleanup:**
 355: 
 356:    ```bash
 357:    # Explicit completion
 358:    ce prp cleanup PRP-005
 359:    # Removes .ce/active_prp_session
 360:    # Archives memories to project knowledge
 361:    ```
 362: 
 363: **Cross-Session Continuity:** If session is interrupted, `ce prp status` shows active PRP and last checkpoint, enabling seamless resumption.
 364: 
 365: **State Isolation Guarantee:** Each PRP execution maintains isolated state through namespaced memories and scoped checkpoints, preventing context bleed between PRPs.
 366: 
 367: #### 3.1.2 SELECT: Dynamic Retrieval
 368: 
 369: **Purpose:** Retrieve relevant context on-demand
 370: 
 371: **Mechanisms:**
 372: 
 373: - **Symbol Navigation:** `find_symbol("Class/method", include_body=True)`
 374: - **Pattern Search:** `search_for_pattern("async function.*Error")`
 375: - **Documentation:** Context7 MCP for library-specific docs
 376: 
 377: **Strategy:**
 378: 
 379: 1. Overview first: `get_symbols_overview(file)`
 380: 2. Targeted search: `find_symbol` for specific symbols
 381: 3. Context expansion: `find_referencing_symbols` for relationships
 382: 
 383: #### 3.1.3 COMPRESS: Efficiency Management
 384: 
 385: **Purpose:** Minimize token consumption while maintaining completeness
 386: 
 387: **Techniques:**
 388: 
 389: - **Overview-first:** Structure before implementation details
 390: - **Symbolic editing:** Edit by symbol path, not full file reads
 391: - **Targeted reads:** Read specific lines/symbols, not entire files
 392: - **Batch operations:** Group related changes
 393: 
 394: **Example:**
 395: 
 396: ```
 397: ‚ùå Wasteful: Read(file) ‚Üí Edit(file)  # 10k tokens
 398: ‚úÖ Efficient: Edit(file, old, new)    # 100 tokens
 399: ```
 400: 
 401: #### 3.1.4 ISOLATE: Safety Boundaries
 402: 
 403: **Purpose:** Prevent context interference and ensure reproducibility
 404: 
 405: **Mechanisms:**
 406: 
 407: - **Validation gates:** Checkpoint after each phase
 408: - **Error boundaries:** Self-healing loops with iteration limits
 409: - **Strict rules:** 3 LOC limit, tmp/ folder for scripts
 410: - **Security scans:** Detect sensitive data patterns
 411: 
 412: ### See Also
 413: 
 414: - [Context Engineering Foundations](../docs/research/02-context-engineering-foundations.md) - Four Pillars architecture (WRITE, SELECT, COMPRESS, ISOLATE) in depth
 415: - [Persistence Layers](../docs/research/05-persistence-layers.md) - Ground truth management and persistence strategies
 416: - [MCP Orchestration](../docs/research/03-mcp-orchestration.md) - Strategic MCP integration architecture
 417: 
 418: ---
 419: 
 420: ### 3.2 PRP System Architecture
 421: 
 422: ```mermaid
 423: graph TB
 424:     A["INITIAL.md or PLAN.md"] --> B["PRP Generation<br/>(Manual or /batch-gen-prp)"]
 425:     B --> C["PRP Document(s)"]
 426:     C --> D{"Human Validation"}
 427:     D -->|"Approved"| E["/execute-prp"]
 428:     D -->|"Rejected"| F["Revise PRP"]
 429:     F --> C
 430:     E --> G["Implementation"]
 431:     G --> H["Validation Gate"]
 432:     H --> I{"Pass?"}
 433:     I -->|"Yes"| J["Next Phase"]
 434:     I -->|"No"| K["Self-Heal"]
 435:     K --> G
 436:     J --> L{"More Phases?"}
 437:     L -->|"Yes"| G
 438:     L -->|"No"| M["Production Code"]
 439: 
 440:     style A fill:#fff8e1,color:#000
 441:     style B fill:#f3e5f5,color:#000
 442:     style C fill:#b2ebf2,color:#000
 443:     style D fill:#ff9999,color:#000
 444:     style E fill:#ffe0b2,color:#000
 445:     style F fill:#fff9c4,color:#000
 446:     style G fill:#e1bee7,color:#000
 447:     style H fill:#ffecb3,color:#000
 448:     style I fill:#fff3e0,color:#000
 449:     style J fill:#e1f5fe,color:#000
 450:     style K fill:#ffccbc,color:#000
 451:     style L fill:#f3e5f5,color:#000
 452:     style M fill:#c8e6c9,color:#000
 453: ```
 454: 
 455: #### 3.2.1 PRP Structure
 456: 
 457: **Six Primary Sections:**
 458: 
 459: 1. **GOAL** - Single, clear objective
 460: 2. **WHY** - Business value and user impact
 461: 3. **WHAT** - Measurable success criteria
 462: 4. **CONTEXT** - Complete implementation context
 463:    - Project structure
 464:    - Existing patterns
 465:    - Library documentation
 466:    - Validation commands
 467:    - Gotchas and warnings
 468: 5. **IMPLEMENTATION BLUEPRINT** - Step-by-step pseudocode
 469: 6. **VALIDATION LOOPS** - Four-level testing gates (L1-L4)
 470: 
 471: **Optional Sections:**
 472: 
 473: - SERENA PRE-FLIGHT CHECKS
 474: - SELF-HEALING GATES
 475: - CONFIDENCE SCORING
 476: - COMPLETION CHECKLIST
 477: - **DRIFT_JUSTIFICATION** (Required if pattern drift > 30% accepted)
 478: 
 479: **DRIFT_JUSTIFICATION Section Format:**
 480: 
 481: Required when Level 4 validation detects >30% pattern drift and user accepts it.
 482: 
 483: ```yaml
 484: DRIFT_JUSTIFICATION:
 485:   drift_score: "<percentage>%"
 486:   decision: "accept | reject | update_examples"
 487:   reason: |
 488:     <Multi-line explanation of why drift is justified>
 489:     <Trade-offs considered>
 490:     <Business/technical rationale>
 491:   alternatives_considered:
 492:     - "<Alternative approach>: <Why rejected>"
 493:     - "<Alternative approach>: <Why rejected>"
 494:   approved_by: "user | team_lead | architect"
 495:   date: "YYYY-MM-DD"
 496:   references:
 497:     - "PRP-XXX: <Related drift decision>"
 498:     - "INITIAL.md: <Relevant EXAMPLES section>"
 499: ```
 500: 
 501: **Example:**
 502: 
 503: ```yaml
 504: DRIFT_JUSTIFICATION:
 505:   drift_score: 60%
 506:   decision: accept
 507:   reason: |
 508:     Payment gateway API (Stripe) requires synchronous webhooks.
 509:     Converting to async would break webhook signature validation.
 510:     This is isolated to payment module only.
 511:   alternatives_considered:
 512:     - "Async wrapper with sync bridge: Adds complexity, no performance gain"
 513:     - "Switch to async payment API: Not available from Stripe"
 514:     - "Background job processing: Breaks real-time payment flow"
 515:   approved_by: user
 516:   date: 2025-01-15
 517:   references:
 518:     - "PRP-004: Similar decision for legacy callback API"
 519:     - "INITIAL.md lines 42-56: Async pattern documented"
 520: ```
 521: 
 522: **Purpose:** Creates audit trail of architectural decisions, enables future PRPs to understand why patterns diverged.
 523: 
 524: #### 3.2.2 Information Density Requirements
 525: 
 526: | Anti-Pattern | Best Practice |
 527: |--------------|---------------|
 528: | "Use modern practices" | "Use Next.js 14.2.3 app router (see docs/routing.md:42)" |
 529: | "Handle errors properly" | "Wrap in try-catch, log to Winston, return {error: string}" |
 530: | "Store data efficiently" | "PostgreSQL with pg-pool, max 10 connections" |
 531: 
 532: **Principle:** Provide exactly what's needed‚Äîno more, no less.
 533: 
 534: ---
 535: 
 536: ### 3.3 Validation Framework
 537: 
 538: #### 3.3.1 Four-Level Gate System
 539: 
 540: ```mermaid
 541: graph TB
 542:     A["Code Implementation"] --> B["Level 1: Syntax & Style<br/>10 seconds"]
 543:     B --> B1["‚Ä¢ Linters, formatters, type checkers<br/>‚Ä¢ Auto-fix: Yes<br/>‚Ä¢ Action: Fix and re-run"]
 544:     B1 --> C["Level 2: Unit Tests<br/>30-60 seconds"]
 545:     C --> C1["‚Ä¢ Function-level validation<br/>‚Ä¢ Auto-fix: Conditional<br/>‚Ä¢ Action: Analyze, fix, re-test"]
 546:     C1 --> D["Level 3: Integration<br/>1-2 minutes"]
 547:     D --> D1["‚Ä¢ API endpoints, database, E2E<br/>‚Ä¢ Auto-fix: Manual<br/>‚Ä¢ Action: Debug systematically"]
 548:     D1 --> D2["Level 4: Pattern Conformance<br/>30-60 seconds"]
 549:     D2 --> D3["‚Ä¢ Compare vs EXAMPLES from INITIAL.md<br/>‚Ä¢ Check architectural consistency<br/>‚Ä¢ Detect drift from specification<br/>‚Ä¢ Action: Refactor if drift detected"]
 550:     D3 --> E["Production Ready"]
 551: 
 552:     style A fill:#e3f2fd,color:#000
 553:     style B fill:#fff8e1,color:#000
 554:     style B1 fill:#fff9c4,color:#000
 555:     style C fill:#f3e5f5,color:#000
 556:     style C1 fill:#e1f5fe,color:#000
 557:     style D fill:#b2ebf2,color:#000
 558:     style D1 fill:#b2dfdb,color:#000
 559:     style D2 fill:#e8f5e9,color:#000
 560:     style D3 fill:#c5e1a5,color:#000
 561:     style E fill:#c8e6c9,color:#000
 562: ```
 563: 
 564: #### 3.3.2 Self-Healing Protocol
 565: 
 566: **Standard Loop:**
 567: 
 568: 1. Run validation command
 569: 2. Capture output
 570: 3. If failure:
 571:    - Parse error message
 572:    - Identify root cause
 573:    - Use MCP tools to locate code
 574:    - Apply targeted fix
 575:    - Re-run validation
 576: 4. Repeat until pass OR escalate after 3 attempts
 577: 
 578: **Escalation Triggers:**
 579: 
 580: - Same error after 3 fix attempts
 581: - Ambiguous error messages
 582: - Architectural changes required
 583: - External dependency issues
 584: 
 585: #### 3.3.3 Level 4: Pattern Conformance Validation
 586: 
 587: **Purpose:** Ensure implementation matches architectural patterns defined in INITIAL.md EXAMPLES
 588: 
 589: **Validation Steps:**
 590: 
 591: 1. **Extract patterns from EXAMPLES:**
 592:    - Code structure (async/await vs callbacks)
 593:    - Error handling approach (try-catch, error boundaries)
 594:    - Data flow patterns (props, state, context)
 595:    - Naming conventions (camelCase, PascalCase, snake_case)
 596: 
 597: 2. **Compare implementation:**
 598:    - Use `find_symbol` to analyze new code structure
 599:    - Pattern match against EXAMPLES
 600:    - Calculate drift score (0-100%)
 601: 
 602: 3. **Drift detection thresholds:**
 603:    - **0-10%:** Minor style differences ‚Üí Auto-accept, continue
 604:    - **10-30%:** Moderate drift ‚Üí Auto-fix if possible, log warning
 605:    - **30%+:** Major architectural divergence ‚Üí **HALT & ESCALATE TO USER**
 606: 
 607: 4. **Human Decision Required (30%+ drift):**
 608: 
 609:    When major drift is detected, execution **PAUSES** and presents user with:
 610: 
 611:    ```
 612:    üö® PATTERN DRIFT DETECTED (60% divergence)
 613: 
 614:    üìã EXAMPLES Pattern (from INITIAL.md):
 615:    async def fetch_data():
 616:        try:
 617:            result = await api.get()
 618:            return {"data": result}
 619:        except Exception as e:
 620:            logger.error(f"Fetch failed: {e}")
 621:            raise
 622: 
 623:    üîß Current Implementation:
 624:    def fetch_data():
 625:        result = api.get()
 626:        return result
 627: 
 628:    ‚ùå Differences:
 629:    ‚Ä¢ Missing async/await (architectural)
 630:    ‚Ä¢ No try-catch error handling
 631:    ‚Ä¢ Wrong return format (missing wrapper)
 632: 
 633:    üìö Recent Drift History (last 3 PRPs):
 634:    ‚Ä¢ PRP-004: Accepted 25% drift (added callbacks for legacy API)
 635:    ‚Ä¢ PRP-003: Rejected 45% drift (maintained async consistency)
 636:    ‚Ä¢ PRP-002: Accepted 15% drift (simplified error messages)
 637: 
 638:    ü§î Choose Action:
 639:    [1] Accept drift + document justification in PRP
 640:    [2] Reject drift + refactor to match EXAMPLES
 641:    [3] Update EXAMPLES + accept new pattern
 642: 
 643:    If [1], provide justification:
 644:    > _______________________________________
 645:    ```
 646: 
 647: 5. **User Decision Handling:**
 648: 
 649:    **Option 1: Accept Drift**
 650:    - User provides written justification
 651:    - Justification saved to PRP under `DRIFT_JUSTIFICATION` section
 652:    - Pattern recorded in Serena memory: `drift-{prp_id}-justification`
 653:    - Future PRPs can reference this decision
 654:    - Example: "Legacy callback API requires synchronous interface"
 655: 
 656:    **Option 2: Reject Drift**
 657:    - AI refactors code to match EXAMPLES
 658:    - Re-run L1-L4 validation
 659:    - Continue to Step 6.5 if all gates pass
 660: 
 661:    **Option 3: Update EXAMPLES**
 662:    - User edits INITIAL.md EXAMPLES with new pattern
 663:    - New pattern becomes baseline for future validations
 664:    - Document pattern evolution in INITIAL.md
 665:    - Re-validate current implementation (should now pass)
 666: 
 667: 6. **Drift Justification Format (in PRP):**
 668: 
 669:    ```yaml
 670:    DRIFT_JUSTIFICATION:
 671:      drift_score: 60%
 672:      decision: accept
 673:      reason: |
 674:        Legacy payment API requires synchronous callback interface.
 675:        Async conversion would require major API refactor (out of scope).
 676:        Trade-off: Maintain sync pattern for payment, keep async for data fetching.
 677:      alternatives_considered:
 678:        - Async wrapper: Rejected (adds complexity, no benefit)
 679:        - API upgrade: Rejected (3rd party, no control)
 680:      approved_by: user
 681:      date: 2025-01-15
 682:    ```
 683: 
 684: **Example Check:**
 685: 
 686: ```python
 687: # INITIAL.md EXAMPLES shows:
 688: async def fetch_data():
 689:     try:
 690:         result = await api.get()
 691:         return {"data": result}
 692:     except Exception as e:
 693:         logger.error(f"Fetch failed: {e}")
 694:         raise
 695: 
 696: # Implementation:
 697: def fetch_data():  # ‚ùå Not async
 698:     result = api.get()  # ‚ùå No try-catch
 699:     return result  # ‚ùå Wrong return format
 700: 
 701: # Pattern Conformance: 60% drift ‚Üí Refactor required
 702: ```
 703: 
 704: **Integration:** Runs after Level 3 (Integration tests), before declaring production-ready.
 705: 
 706: **Drift Decision Workflow:**
 707: 
 708: ```mermaid
 709: graph TB
 710:     A["Level 4: Pattern Conformance<br/>Calculate Drift Score"] --> B{Drift Score?}
 711:     B -->|0-10%| C["‚úÖ Accept<br/>Continue to Production"]
 712:     B -->|10-30%| D["‚ö†Ô∏è Auto-fix<br/>Log Warning"]
 713:     D --> E["Re-run L4 Validation"]
 714:     E --> C
 715:     B -->|30%+| F["üö® HALT<br/>Escalate to User"]
 716: 
 717:     F --> G["Display:<br/>‚Ä¢ EXAMPLES pattern<br/>‚Ä¢ Current implementation<br/>‚Ä¢ Differences list<br/>‚Ä¢ Recent drift history"]
 718: 
 719:     G --> H{User Decision}
 720: 
 721:     H -->|1. Accept Drift| I["User provides justification"]
 722:     I --> J["Save DRIFT_JUSTIFICATION to PRP<br/>Record in Serena memory"]
 723:     J --> K["Update drift history<br/>drift-{prp_id}-justification"]
 724:     K --> C
 725: 
 726:     H -->|2. Reject Drift| L["AI refactors code<br/>to match EXAMPLES"]
 727:     L --> M["Re-run L1-L4 validation"]
 728:     M --> N{All gates pass?}
 729:     N -->|Yes| C
 730:     N -->|No| L
 731: 
 732:     H -->|3. Update EXAMPLES| O["User edits INITIAL.md<br/>New pattern becomes baseline"]
 733:     O --> P["Document pattern evolution<br/>in INITIAL.md"]
 734:     P --> E
 735: 
 736:     style A fill:#e3f2fd,color:#000
 737:     style B fill:#fff8e1,color:#000
 738:     style C fill:#c8e6c9,color:#000
 739:     style D fill:#ffe0b2,color:#000
 740:     style F fill:#ffccbc,color:#000
 741:     style G fill:#f3e5f5,color:#000
 742:     style H fill:#ff9999,color:#000
 743:     style I fill:#e1f5fe,color:#000
 744:     style J fill:#e1f5fe,color:#000
 745:     style K fill:#e1f5fe,color:#000
 746:     style L fill:#b2ebf2,color:#000
 747:     style M fill:#b2dfdb,color:#000
 748:     style N fill:#fff8e1,color:#000
 749:     style O fill:#f3e5f5,color:#000
 750:     style P fill:#e8f5e9,color:#000
 751: ```
 752: 
 753: #### 3.3.4 Confidence Scoring
 754: 
 755: | Score | Meaning | Criteria |
 756: |-------|---------|----------|
 757: | 1-3 | Unvalidated | No tests run |
 758: | 4-6 | Partially validated | Syntax checks pass |
 759: | 7-8 | Core validated | Unit tests pass |
 760: | 9 | Integration validated | L1-L3 pass, but pattern drift detected |
 761: | 10 | Production-ready | All 4 gates pass, zero drift from EXAMPLES |
 762: 
 763: **Threshold:** 10/10 required for production deployment (previously 9/10, upgraded to include L4).
 764: 
 765: ---
 766: 
 767: ## 4. Components
 768: 
 769: ### 4.1 Tool Ecosystem
 770: 
 771: **Implementation Status Overview:**
 772: 
 773: Context Engineering framework is **production-ready** with 31+ core PRPs executed (93%+ completion). All critical features implemented, tested, and security-verified.
 774: 
 775: **Core Features Implemented:** ‚úÖ
 776: 
 777: - ‚úÖ 4-level validation gates (L1-L4: syntax, unit tests, integration, pattern conformance + drift)
 778: - ‚úÖ PRP generation & execution (research + synthesis workflow with checkpoint tracking)
 779: - ‚úÖ Batch PRP generation & execution (parallel subagents, git worktrees, dependency analysis)
 780: - ‚úÖ Git operations (status, diff, checkpoints, drift tracking, worktree management)
 781: - ‚úÖ Context management (health monitoring, drift detection, sync, auto-remediation)
 782: - ‚úÖ Error recovery (retry with backoff, circuit breaker, resilience patterns)
 783: - ‚úÖ Metrics & profiling (success rate tracking, performance monitoring)
 784: - ‚úÖ Serena MCP integration (symbol search, pattern analysis, reference tracking)
 785: - ‚úÖ Linear integration (automated issue creation, defaults management)
 786: - ‚úÖ Syntropy MCP aggregation (unified server layer, connection pooling)
 787: - ‚úÖ Security hardening (CWE-78 elimination, command injection prevention)
 788: - ‚úÖ Tool ecosystem optimization (55 MCP tools denied, 96% token reduction)
 789: - ‚úÖ Project maintenance tools (vacuum, denoise, tools-misuse-scan)
 790: - ‚úÖ 9 slash commands for interactive workflows
 791: 
 792: **Post-1.0 Enhancements:** üîú
 793: 
 794: - üîú CLI wrappers for state commands (functions exist, rarely used)
 795: - üîú Alternative CI/CD executors (GitLab CI, Jenkins support)
 796: 
 797: **Architecture:**
 798: 
 799: - **Location:** `tools/ce/` (Python package)
 800: - **Management:** UV package manager
 801: - **CLI:** Single `ce` command with subcommands
 802: - **Testing:** `tools/tests/` with real functionality tests
 803: 
 804: #### 4.1.1 run_py Tool
 805: 
 806: **Purpose:** Execute Python code with strict 3 LOC limit
 807: 
 808: **Rules:**
 809: 
 810: - Ad-hoc code: Max 3 LOC (lines with actual code)
 811: - Longer scripts: Must be in `tmp/` folder
 812: - Auto-detect mode: Smart file vs code detection
 813: 
 814: **Usage:**
 815: 
 816: ```bash
 817: # Ad-hoc (max 3 LOC)
 818: cd tools && uv run ce run_py "import sys; print(sys.version)"
 819: 
 820: # File-based
 821: cd tools && uv run ce run_py tmp/analysis.py
 822: 
 823: # Auto-detect
 824: cd tools && uv run ce run_py "print('hello')"  # Detects code
 825: cd tools && uv run ce run_py tmp/script.py      # Detects file
 826: ```
 827: 
 828: **Implementation:**
 829: 
 830: ```python
 831: def run_py(code: Optional[str] = None,
 832:            file: Optional[str] = None,
 833:            auto: Optional[str] = None) -> Dict[str, Any]:
 834:     # Auto-detect file vs code
 835:     if auto is not None:
 836:         if "/" in auto or auto.endswith(".py"):
 837:             file = auto
 838:         else:
 839:             code = auto
 840: 
 841:     # Enforce 3 LOC limit
 842:     if code is not None:
 843:         lines = [line for line in code.split('\n') if line.strip()]
 844:         if len(lines) > 3:
 845:             raise ValueError(f"Ad-hoc code exceeds 3 LOC limit (found {len(lines)} lines)")
 846: 
 847:     # Execute with uv
 848:     cmd = f"uv run python -c {shlex.quote(code)}" if code else f"uv run python {file}"
 849:     return run_cmd(cmd, timeout=120 if code else 300)
 850: ```
 851: 
 852: #### 4.1.2 ce CLI
 853: 
 854: **Purpose:** Context Engineering operations
 855: 
 856: **Core Commands (Implemented):**
 857: 
 858: - `ce validate --level [1|2|3|all]` - Run validation gates (L1-L4)
 859: - `ce git status` - Git repository status
 860: - `ce git diff [options]` - View git changes
 861: - `ce git checkpoint "message"` - Create git tag checkpoint
 862: - `ce context health` - Context drift analysis
 863: - `ce context sync` - Sync context with codebase changes
 864: - `ce context prune` - Remove stale context entries
 865: - `ce run_py` - Execute Python code (3 LOC limit)
 866: - `ce vacuum [--execute|--auto|--nuclear]` - Clean up project noise (temp files, obsolete docs, unreferenced code)
 867: - `ce drift` - Drift history tracking and analysis
 868: - `ce analyze-context` / `ce analyse-context` - Fast drift check without metadata sync (2-3s vs 10-15s)
 869: 
 870: **PRP Management Commands (Implemented):**
 871: 
 872: - `ce prp validate <prp-file>` - Validate PRP structure and sections
 873: - `ce prp analyze <prp-file>` - Analyze PRP for complexity, sizing, patterns
 874: - `ce update-context [--prp file]` - Sync context, generate drift reports, create remediation PRPs
 875: - `ce metrics [options]` - Collect and display system metrics and success rates
 876: 
 877: **PRP State Management (Functions Implemented, CLI Pending):**
 878: 
 879: - `ce prp start <prp-id>` - ‚úÖ Function exists, CLI wrapper pending
 880: - `ce prp checkpoint <phase>` - ‚úÖ Function exists, CLI wrapper pending
 881: - `ce prp cleanup` - ‚úÖ Function exists, CLI wrapper pending
 882: - `ce prp restore <prp-id> [phase]` - ‚úÖ Function exists, CLI wrapper pending
 883: - `ce prp status` - ‚úÖ Function exists, CLI wrapper pending
 884: - `ce prp list` - ‚úÖ Function exists, CLI wrapper pending
 885: 
 886: **Drift History Commands (Functions Implemented, CLI Pending):**
 887: 
 888: - `ce drift history [--last N]` - ‚úÖ Function exists, CLI wrapper pending
 889: - `ce drift show <prp-id>` - ‚úÖ Function exists, CLI wrapper pending
 890: - `ce drift summary` - ‚úÖ Function exists, CLI wrapper pending
 891: - `ce drift compare <prp-id-1> <prp-id-2>` - ‚úÖ Function exists, CLI wrapper pending
 892: 
 893: **Pipeline Commands (Implemented):**
 894: 
 895: - `ce pipeline validate <yaml>` - Validate abstract pipeline YAML schema
 896: - `ce pipeline render <yaml>` - Render pipeline to concrete format (GitHub Actions, etc.)
 897: 
 898: **Implementation Status:**
 899: 
 900: ```python
 901: # Core operations (fully implemented)
 902: ‚úÖ core.py: run_cmd, git_status, git_diff, git_checkpoint, run_py (CWE-78 secure)
 903: ‚úÖ validate.py: validate_level_1-4 (all 4 levels with L4 drift detection)
 904: ‚úÖ context.py: sync, health, prune (with üîß troubleshooting guidance)
 905: ‚úÖ update_context.py: drift remediation workflow automation (30+ bugs fixed)
 906: 
 907: # Drift analysis (fully implemented)
 908: ‚úÖ drift.py: fast analyze-context command (2-3s vs 10-15s)
 909: ‚úÖ drift_analyzer.py: automated pattern detection + smart caching
 910: 
 911: # PRP system (functions implemented, most CLI exposed)
 912: ‚úÖ prp.py: start_prp, checkpoint, cleanup, restore, status, list (functions)
 913: ‚úÖ generate.py: research + synthesize (via /batch-gen-prp for parallel generation)
 914: ‚úÖ execute.py: phase execution + validation loops (via /execute-prp and /batch-exe-prp)
 915: ‚úÖ prp_analyzer.py: complexity analysis (ce prp analyze)
 916: 
 917: # Tool optimization (fully implemented)
 918: ‚úÖ mcp_adapter.py: MCP tool configuration mapping
 919: ‚úÖ shell_utils.py: Python bash replacements (30-50% context reduction)
 920: ‚úÖ pattern_detectors.py: Tool misuse prevention (6 anti-patterns)
 921: 
 922: # Pipeline & infrastructure (partial)
 923: ‚ö†Ô∏è pipeline.py: schema validation + abstract definition only
 924: ‚úÖ metrics.py: collection and reporting
 925: ‚úÖ linear_utils.py: issue creation + defaults
 926: ‚úÖ testing/: strategy pattern + builder (for PRP validation)
 927: 
 928: # Security (fully verified)
 929: ‚úÖ CWE-78 Command Injection: Eliminated (CVSS 8.1‚Üí0)
 930: ‚úÖ shlex.split() + shell=False: 6 critical locations fixed
 931: ‚úÖ Security Tests: 38/38 pass, 631 regression tests pass
 932: ```
 933: 
 934: **Architecture Note:** Execution driven by slash commands (`/batch-gen-prp`, `/batch-exe-prp`, `/execute-prp`) with state managed internally. CLI commands provide validation, analysis, and utility functions. This differs from model's planned interactive CLI state management but achieves same functionality through delegation.
 935: 
 936: **PRP Context Command Examples:**
 937: 
 938: ```bash
 939: # Start new PRP execution with isolated state
 940: ce prp start PRP-005
 941: 
 942: # Create phase checkpoint (PRP-scoped)
 943: ce prp checkpoint implementation
 944: # Creates: checkpoint-PRP-005-implementation-{timestamp}
 945: 
 946: # Cleanup after PRP completion
 947: ce prp cleanup PRP-005
 948: # - Deletes intermediate checkpoints (keeps final)
 949: # - Archives PRP memories to project knowledge
 950: # - Resets validation state counters
 951: 
 952: # Restore to specific PRP checkpoint
 953: ce prp restore PRP-005 implementation
 954: ```
 955: 
 956: **Drift History Command Examples:**
 957: 
 958: ```bash
 959: # Show last 3 drift decisions
 960: ce drift history --last 3
 961: # Output:
 962: # PRP-005: 45% drift REJECTED (refactored to match async pattern)
 963: # PRP-004: 25% drift ACCEPTED (legacy callback API requirement)
 964: # PRP-003: 15% drift AUTO-FIXED (minor style inconsistency)
 965: 
 966: # Show specific drift justification
 967: ce drift show PRP-004
 968: # Displays full DRIFT_JUSTIFICATION section from PRP-004
 969: 
 970: # Summary of all drift decisions
 971: ce drift summary
 972: # Output:
 973: # Total PRPs analyzed: 10
 974: # Drift decisions:
 975: #   - Accepted: 3 (30%)
 976: #   - Rejected: 5 (50%)
 977: #   - Auto-fixed: 2 (20%)
 978: # Average drift score: 22%
 979: # Common justifications:
 980: #   - Legacy API compatibility: 2 cases
 981: #   - Third-party library constraints: 1 case
 982: 
 983: # Compare drift between two PRPs
 984: ce drift compare PRP-003 PRP-005
 985: # Shows side-by-side drift decisions and reasoning
 986: ```
 987: 
 988: **Design:** Single CLI tool, modular subcommands, UV-managed. PRP state management ensures isolation between executions. Drift tracking creates architectural decision audit trail.
 989: 
 990: ##### 4.1.2.4 Update-Context Reliability Improvements (PRP-21)
 991: 
 992: **Comprehensive Fix** (30+ critical bugs eliminated):
 993: 
 994: **Drift Score Accuracy**:
 995: - ‚ùå **Before**: Used file count (1 file with 30 violations = 3.3% drift - misleading!)
 996: - ‚úÖ **After**: Uses violation count (30 violations / total checks = accurate percentage)
 997: - **Impact**: Drift scores now reflect actual codebase health
 998: 
 999: **Implementation Verification**:
1000: - ‚ùå **Before**: Serena MCP disabled (always False), ce_verified only checked if functions mentioned
1001: - ‚úÖ **After**: AST-based verification (actually checks if functions/classes exist in codebase)
1002: - **Impact**: PRPs auto-transition to executed/ only when implementations verified
1003: 
1004: **Pattern Matching Robustness**:
1005: - ‚ùå **Before**: Regex with `$` anchor missed multiline raises
1006: - ‚úÖ **After**: AST parsing for accurate pattern detection
1007: - **Impact**: Zero false positives/negatives in violation detection
1008: 
1009: **File Operation Safety**:
1010: - ‚ùå **Before**: No atomic writes (corruption risk on mid-write failure)
1011: - ‚úÖ **After**: Temp file + atomic rename pattern
1012: - **Impact**: PRP YAML headers never corrupted
1013: 
1014: **Error Handling**:
1015: - ‚ùå **Before**: Generic exceptions, no troubleshooting guidance
1016: - ‚úÖ **After**: Specific exceptions with üîß troubleshooting steps
1017: - **Impact**: Users can self-resolve issues without escalation
1018: 
1019: **Graceful Degradation**:
1020: - ‚ùå **Before**: Hard failures if Serena MCP unavailable
1021: - ‚úÖ **After**: Works without Serena (sets serena_updated=false with warning)
1022: - **Impact**: System usable even with partial MCP availability
1023: 
1024: **Remediation Workflow**:
1025: - ‚ùå **Before**: --remediate only generated PRP (half-baked)
1026: - ‚úÖ **After**: Full workflow (transform ‚Üí blueprint ‚Üí automated execution)
1027: - **Impact**: PRP-15 drift remediation pipeline complete
1028: 
1029: **Verification** (PRP-21 execution):
1030: - ‚úÖ 30+ bugs fixed across tools/ce/update_context.py
1031: - ‚úÖ Design flaws resolved (state management, error handling)
1032: - ‚úÖ All tests passing post-refactor
1033: - ‚úÖ Drift detection now accurate and reliable
1034: 
1035: **Files Modified**:
1036: - `tools/ce/update_context.py` - Main reliability fixes
1037: - `tools/ce/drift_analyzer.py` - Pattern detection improvements
1038: - `tools/ce/context.py` - Integration updates
1039: 
1040: **Reference**: [PRP-21: update-context Comprehensive Fix](../../PRPs/executed/PRP-21-update-context-comprehensive-fix.md)
1041: 
1042: #### 4.1.3 MCP Integration
1043: 
1044: **Serena MCP** (Codebase Navigation)
1045: 
1046: - `find_symbol(name_path)` - Locate code symbols
1047: - `find_referencing_symbols(name_path, file)` - Find usages
1048: - `search_for_pattern(pattern)` - Regex search
1049: - `get_symbols_overview(file)` - File structure
1050: - `write_memory(name, content)` - Persist knowledge
1051: - `read_memory(name)` - Restore knowledge
1052: 
1053: **Context7 MCP** (Documentation)
1054: 
1055: - `resolve-library-id(name)` - Find library ID
1056: - `get-library-docs(id, topic)` - Fetch docs
1057: 
1058: **Sequential Thinking MCP** (Reasoning)
1059: 
1060: - `sequentialthinking(thought, thought_number, total_thoughts)` - Step-by-step analysis
1061: 
1062: #### 4.1.4 Linear Integration
1063: 
1064: **Purpose:** Automated issue tracking for PRP lifecycle management
1065: 
1066: **Status:** ‚úÖ **IMPLEMENTED** (PRP-24 integration, not in prior model)
1067: 
1068: **Functionality:**
1069: 
1070: - **Auto-issue creation**: `/batch-gen-prp` creates Linear issues automatically during batch generation
1071: - **Default configuration**: `.ce/linear-defaults.yml` stores project, assignee, labels
1072: - **PRP metadata**: YAML header stores `issue: {LINEAR-ISSUE-ID}` for tracking
1073: - **Multi-PRP join**: `--join-prp` flag links multiple PRPs to same issue
1074: - **Status tracking**: Update issue as PRP progresses through phases
1075: 
1076: **Configuration:**
1077: 
1078: ```yaml
1079: # .ce/linear-defaults.yml
1080: project: "Context Engineering"
1081: assignee: "user@example.com"
1082: team: "TeamID"
1083: default_labels:
1084:   - "feature"
1085: ```
1086: 
1087: **Usage:**
1088: 
1089: ```bash
1090: # Auto-create Linear issues during batch PRP generation
1091: /batch-gen-prp BIG-FEATURE-PLAN.md
1092: # ‚Üí Creates PRP-43.1.1, PRP-43.2.1, ... + Linear issues for each
1093: # ‚Üí Updates each PRP YAML with issue ID
1094: 
1095: # Manual issue creation (if needed)
1096: cd tools && uv run python -c "from ce.linear_utils import create_issue; create_issue('PRP-44', 'Feature Name')"
1097: ```
1098: 
1099: #### 4.1.5 Metrics & Performance Monitoring
1100: 
1101: **Purpose:** Collect, analyze, and report execution metrics
1102: 
1103: **Status:** ‚úÖ **IMPLEMENTED** (not in prior model)
1104: 
1105: **Components:**
1106: 
1107: - **metrics.py**: Collection framework (execution time, success rate, quality scores)
1108: - **profiling.py**: Performance profiling (memory, CPU, timing analysis)
1109: - **Linear integration**: Track metrics per issue for productivity analysis
1110: 
1111: **CLI:**
1112: 
1113: ```bash
1114: ce metrics --type prp          # PRP execution metrics
1115: ce metrics --type validation   # Validation gate performance
1116: ce metrics --format json       # JSON output for CI/CD
1117: ```
1118: 
1119: #### 4.1.6 Syntropy MCP Aggregation Layer
1120: 
1121: **Purpose:** Unified interface for all MCP tools via single server
1122: 
1123: **Status:** ‚úÖ **IMPLEMENTED** (PRP-24, transforms tool ecosystem)
1124: 
1125: **Architecture:**
1126: 
1127: - **Single MCP Server**: `syntropy-mcp/` wraps 7 underlying servers
1128: - **Unified namespace**: `mcp__syntropy__<server>__<tool>` format
1129: - **Connection pooling**: Lazy initialization + automatic cleanup
1130: - **Zero breaking changes**: Existing tools preserved, just aggregated
1131: 
1132: **Servers Managed:**
1133: 
1134: 1. Serena (code navigation)
1135: 2. Filesystem (file operations)
1136: 3. Git (version control)
1137: 4. Context7 (documentation)
1138: 5. Sequential Thinking (reasoning)
1139: 6. Linear (issue tracking)
1140: 7. Repomix (codebase packaging)
1141: 
1142: **Benefits:**
1143: 
1144: - Single connection point instead of 8 servers
1145: - Structured logging with timing
1146: - Consistent error handling
1147: - Easy extensibility (new servers via servers.json)
1148: 
1149: **Configuration:**
1150: 
1151: ```json
1152: // syntropy-mcp/servers.json
1153: {
1154:   "servers": {
1155:     "syn-serena": {
1156:       "command": "uvx",
1157:       "args": ["--from", "git+https://...", "serena"]
1158:     },
1159:     // ... other servers
1160:   }
1161: }
1162: ```
1163: 
1164: #### 4.1.7 Quality & Validation Utilities
1165: 
1166: **Purpose:** Markdown linting, Mermaid validation, code quality checks
1167: 
1168: **Status:** ‚úÖ **IMPLEMENTED** (not in prior model)
1169: 
1170: **Components:**
1171: 
1172: - **markdown_lint.py**: Style enforcement for markdown docs
1173: - **mermaid_validator.py**: Diagram validation and color compatibility
1174: - **code_analyzer.py**: Pattern analysis for drift detection
1175: - **pattern_extractor.py**: Example extraction for EXAMPLES sections
1176: 
1177: **Integration:**
1178: 
1179: - **L1 validation**: Linter + formatter auto-fix
1180: - **Pre-commit**: Markdown linting via git hooks
1181: - **PRP validation**: Mermaid color specs in diagrams
1182: 
1183: #### 4.1.8 Security & Command Injection Prevention
1184: 
1185: **Purpose:** CWE-78 vulnerability elimination and command execution safety
1186: 
1187: **Status:** ‚úÖ **IMPLEMENTED & VERIFIED** (PRP-22 executed)
1188: 
1189: **Security Profile:**
1190: 
1191: - **Vulnerability**: CWE-78 (OS Command Injection via `shell=True`)
1192: - **Mitigation**: Replaced `subprocess.run(shell=True)` with `shlex.split() + shell=False`
1193: - **Locations Fixed**: 6 critical locations in core.py and context.py
1194: - **CVSS Score**: 8.1 (HIGH) ‚Üí 0 (Vulnerability eliminated)
1195: 
1196: **Verification:**
1197: 
1198: - ‚úÖ **Security Tests**: 38/38 passed (comprehensive injection prevention)
1199: - ‚úÖ **Regression Tests**: 631 tests passed (no functionality loss)
1200: - ‚úÖ **Validation**: Zero `shell=True` usage in codebase
1201: - ‚úÖ **Backward Compatibility**: All existing callers work unchanged
1202: 
1203: **Implementation Details:**
1204: 
1205: ```python
1206: # BEFORE (VULNERABLE)
1207: result = subprocess.run(cmd, shell=True, ...)  # ‚ùå CWE-78
1208: 
1209: # AFTER (SAFE)
1210: if isinstance(cmd, str):
1211:     cmd_list = shlex.split(cmd)  # Safe parsing
1212: else:
1213:     cmd_list = cmd
1214: 
1215: result = subprocess.run(cmd_list, shell=False, ...)  # ‚úÖ SAFE
1216: ```
1217: 
1218: **Features:**
1219: 
1220: - **Accepts both strings and lists** - Backward compatible
1221: - **Uses shlex.split()** - Properly handles quoted arguments
1222: - **Shell interpretation disabled** - No metacharacter expansion
1223: - **Error handling** - Clear troubleshooting for invalid commands
1224: 
1225: **References:**
1226: 
1227: - [CWE-78: OS Command Injection](https://cwe.mitre.org/data/definitions/78.html) - MITRE/NIST
1228: - [Bandit B602 Security Check](https://bandit.readthedocs.io/en/latest/plugins/b602_subprocess_popen_with_shell_equals_true.html) - Static analysis tool
1229: - [CISA Secure Design Alert](https://www.cisa.gov/resources-tools/resources/secure-design-alert-eliminating-os-command-injection-vulnerabilities) - Federal guidance
1230: 
1231: #### 4.1.9 Slash Commands
1232: 
1233: **Purpose:** High-level workflow commands for interactive Claude Code sessions
1234: 
1235: **Status:** ‚úÖ **IMPLEMENTED** (9 commands active)
1236: 
1237: **Command Overview:**
1238: 
1239: | Command | Purpose | Typical Use Case |
1240: |---------|---------|------------------|
1241: | `/execute-prp` | Execute single PRP | Implement specific feature |
1242: | `/batch-exe-prp` | Execute batch PRPs in parallel | Multi-PRP staged implementation |
1243: | `/batch-gen-prp` | Generate batch PRPs from plan | Decompose large features |
1244: | `/update-context` | Sync context with codebase | After major changes or drift |
1245: | `/vacuum` | Clean up project noise | Remove temp files, obsolete docs |
1246: | `/denoise` | Compress verbose documents | Token optimization for docs |
1247: | `/tools-misuse-scan` | Detect tool anti-patterns | Debug session issues |
1248: | `/syntropy-health` | MCP server health check | Troubleshoot MCP connections |
1249: | `/sync-with-syntropy` | Sync tool permissions | Update settings after tool changes |
1250: 
1251: **Implementation Details:**
1252: 
1253: ```bash
1254: # Location: .claude/commands/*.md
1255: # Format: Markdown files with command documentation
1256: # Invocation: /command-name [args]
1257: # Example: /vacuum --execute
1258: ```
1259: 
1260: **Key Features:**
1261: 
1262: - **Interactive workflow**: Designed for Claude Code conversation flow
1263: - **Context-aware**: Access to full project state and conversation history
1264: - **Integrated with ce CLI**: Many commands wrap ce CLI operations
1265: - **Documentation-driven**: Command behavior defined in markdown files
1266: 
1267: **Command Descriptions:**
1268: 
1269: **1. /execute-prp** - Execute single PRP implementation
1270: - Reads PRP file, executes implementation steps
1271: - Runs validation gates (L1-L4)
1272: - Creates git checkpoints
1273: - Updates PRP metadata (executed timestamp, commit hash)
1274: 
1275: **2. /batch-exe-prp** - Execute batch PRPs with parallel execution
1276: - Parses batch ID from PRP filenames (PRP-X.Y.Z format)
1277: - Groups by stage, executes stages sequentially
1278: - Parallel execution within stage (git worktrees)
1279: - Health monitoring via git commit timestamps
1280: - Automatic merge with conflict detection
1281: 
1282: **3. /batch-gen-prp** - Generate batch PRPs from plan document
1283: - Parses plan markdown ‚Üí extracts phases
1284: - Builds dependency graph (explicit + file conflicts)
1285: - Assigns stages for parallel generation
1286: - Spawns parallel subagents for generation
1287: - Creates Linear issues for each PRP
1288: - Health monitoring via heartbeat files
1289: 
1290: **4. /update-context** - Sync context metadata with codebase
1291: - Updates PRP execution status
1292: - Generates drift reports
1293: - Syncs with Serena memories
1294: - Creates remediation PRPs for high drift
1295: 
1296: **5. /vacuum** - Clean up project noise
1297: - Strategies: temp-files, backup-files, obsolete-docs, unreferenced-code, orphan-tests, commented-code
1298: - Modes: dry-run (report only), --execute (HIGH confidence), --auto (MEDIUM+), --nuclear (ALL)
1299: - Confidence scoring: 30-100%
1300: - Protected paths: .ce/, .claude/, PRPs/, pyproject.toml, etc.
1301: - Report output: .ce/vacuum-report.md
1302: 
1303: **6. /denoise** - Boil out document noise
1304: - Removes verbosity while preserving essential information
1305: - Target: 60-75% reduction in lines
1306: - Preserves: commands, references, warnings, key facts
1307: - Compresses: long explanations, redundant examples, verbose text
1308: - Validation: ensures zero information loss
1309: 
1310: **7. /tools-misuse-scan** - Detect tool anti-patterns
1311: - Scans conversation for denied tool errors
1312: - Categories: Bash anti-patterns, denied tools
1313: - Remediation suggestions with alternatives
1314: - Report format: structured markdown
1315: 
1316: **8. /syntropy-health** - MCP server health diagnostics
1317: - Checks all Syntropy MCP servers (serena, filesystem, git, etc.)
1318: - Connection status, response time, error counts
1319: - Tool availability check
1320: - Detailed diagnostics with `--detailed` flag
1321: 
1322: **9. /sync-with-syntropy** - Sync tool permissions with Syntropy state
1323: - Calls `mcp__syntropy__list_all_tools` for current state
1324: - Updates `.claude/settings.local.json` to match
1325: - Backs up original settings
1326: - Outputs summary of changes
1327: 
1328: **Workflow Integration:**
1329: 
1330: ```bash
1331: # Typical workflow
1332: /syntropy-health              # Check MCP health
1333: /batch-gen-prp PLAN.md        # Generate PRPs from plan
1334: /batch-exe-prp --batch 43     # Execute batch 43
1335: /update-context               # Sync context after execution
1336: /vacuum --execute             # Clean up temp files
1337: ```
1338: 
1339: #### 4.1.10 Batch PRP Generation & Execution
1340: 
1341: **Purpose:** Parallel PRP generation and execution for large features
1342: 
1343: **Status:** ‚úÖ **IMPLEMENTED** (PRP-27-31 era)
1344: 
1345: **Architecture:**
1346: 
1347: ```mermaid
1348: graph TB
1349:     A[Plan Document] --> B[/batch-gen-prp]
1350:     B --> C[Parse Phases]
1351:     C --> D[Build Dependency Graph]
1352:     D --> E[Assign Stages]
1353:     E --> F[Spawn Parallel Subagents]
1354:     F --> G[Monitor via Heartbeats]
1355:     G --> H[Generated PRPs]
1356: 
1357:     H --> I[/batch-exe-prp]
1358:     I --> J[Parse Batch ID]
1359:     J --> K[Group by Stage]
1360:     K --> L[Create Git Worktrees]
1361:     L --> M[Execute Stage in Parallel]
1362:     M --> N[Monitor via Git Commits]
1363:     N --> O[Merge in Order]
1364:     O --> P[Cleanup Worktrees]
1365: 
1366:     style A fill:#e3f2fd,color:#000
1367:     style B fill:#fff8e1,color:#000
1368:     style F fill:#c8e6c9,color:#000
1369:     style H fill:#f3e5f5,color:#000
1370:     style I fill:#fff8e1,color:#000
1371:     style M fill:#c8e6c9,color:#000
1372:     style P fill:#b2ebf2,color:#000
1373: ```
1374: 
1375: **Generation Process:**
1376: 
1377: 1. **Parse Plan**: Extract phases with metadata (goal, hours, complexity, files, dependencies)
1378: 2. **Dependency Analysis**: Build graph with explicit + implicit (file conflict) dependencies
1379: 3. **Stage Assignment**: Topological sort ‚Üí group independent PRPs
1380: 4. **Parallel Generation**: Spawn Sonnet subagents per stage
1381: 5. **Health Monitoring**: 30s polling, heartbeat files, 2-poll kill timeout
1382: 6. **Linear Integration**: Create issue per PRP with defaults
1383: 
1384: **Execution Process:**
1385: 
1386: 1. **Parse Batch**: Extract PRP-X.Y.Z format ‚Üí batch ID, stage, order
1387: 2. **Stage Grouping**: Group PRPs by stage number
1388: 3. **Worktree Creation**: `git worktree add ../ctx-eng-plus-prp-X-Y-Z -b branch-name`
1389: 4. **Parallel Execution**: Execute PRPs in parallel within stage
1390: 5. **Health Monitoring**: 30s polling, git log timestamps, 10min timeout
1391: 6. **Sequential Merge**: Merge branches in order, handle conflicts
1392: 7. **Cleanup**: Remove worktrees, prune references
1393: 
1394: **PRP Naming Convention:**
1395: 
1396: - **Format**: `PRP-X.Y.Z-feature-name.md`
1397: - **X**: Batch ID (next free PRP number)
1398: - **Y**: Stage number (1, 2, 3...)
1399: - **Z**: Order within stage (1, 2, 3...)
1400: - **Example**: `PRP-43.2.3-doc-updates.md` (Batch 43, Stage 2, 3rd PRP in stage)
1401: 
1402: **Metadata in PRP Headers:**
1403: 
1404: ```yaml
1405: stage: stage-2-parallel
1406: execution_order: 4
1407: merge_order: 4
1408: worktree_path: ../ctx-eng-plus-prp-43-2-3
1409: branch_name: prp-43-2-3-doc-updates
1410: conflict_potential: LOW
1411: dependencies: [PRP-43.1.1]
1412: ```
1413: 
1414: **Performance:**
1415: 
1416: - **Generation**: 8 PRPs sequential (30 min) ‚Üí parallel (10-12 min) = **60% faster**
1417: - **Execution**: 3 PRPs sequential (45 min) ‚Üí parallel (20 min) = **55% faster**
1418: - **Monitoring**: 30s polling interval, low overhead
1419: 
1420: **Safety Mechanisms:**
1421: 
1422: - **Dependency validation**: Circular dependency detection
1423: - **File conflict detection**: Implicit dependencies from file overlaps
1424: - **Health monitoring**: Kill stalled agents/executors
1425: - **Merge order**: Enforced sequential merge to handle conflicts
1426: - **Worktree isolation**: No cross-contamination between PRPs
1427: 
1428: **Example Workflow:**
1429: 
1430: ```bash
1431: # 1. Create plan document
1432: vim BIG-FEATURE-PLAN.md
1433: 
1434: # 2. Generate batch PRPs (parallel)
1435: /batch-gen-prp BIG-FEATURE-PLAN.md
1436: # Output: PRPs/feature-requests/PRP-43.*.md (8 PRPs)
1437: #   Stage 1: PRP-43.1.1
1438: #   Stage 2: PRP-43.2.1, PRP-43.2.2, PRP-43.2.3 (parallel)
1439: #   Stage 3: PRP-43.3.1, PRP-43.3.2
1440: 
1441: # 3. Execute batch (parallel within stages)
1442: /batch-exe-prp --batch 43
1443: # Executes Stage 1 ‚Üí Stage 2 (parallel) ‚Üí Stage 3
1444: # Time: ~20 min vs 45 min sequential
1445: 
1446: # 4. Sync context
1447: /update-context
1448: ```
1449: 
1450: **Implementation Status:**
1451: 
1452: - ‚úÖ Batch generation with parallel subagents
1453: - ‚úÖ Batch execution with git worktrees
1454: - ‚úÖ Dependency graph analysis (explicit + file conflicts)
1455: - ‚úÖ Health monitoring (heartbeats for gen, git commits for exe)
1456: - ‚úÖ Linear integration (issue creation per PRP)
1457: - ‚úÖ Conflict detection and merge order enforcement
1458: - ‚úÖ Circular dependency detection with path reporting
1459: - ‚úÖ Worktree creation and cleanup automation
1460: 
1461: ### See Also
1462: 
1463: - [Product Requirements Prompt (PRP) System](../docs/research/01-prp-system.md) - Complete PRP templates, validation gates, and self-healing patterns
1464: - [MCP Orchestration](../docs/research/03-mcp-orchestration.md) - Strategic integration of Serena, Context7, and Sequential Thinking MCPs
1465: - [Command Reference](../docs/research/07-commands-reference.md) - Complete CLI tool documentation and command workflows
1466: - [Tooling and Configuration](../docs/research/10-tooling-configuration.md) - Setup guides for UV, git, validation commands, and MCP servers
1467: - [Syntropy Examples](../tools/ce/examples/syntropy/README.md) - Complete pattern library for Syntropy MCP servers
1468: 
1469: ---
1470: 
1471: ### 4.2 Templates
1472: 
1473: #### 4.2.1 Self-Healing Template
1474: 
1475: **Use Case:** Complex features with extensive validation
1476: 
1477: **Key Sections:**
1478: 
1479: - SERENA PRE-FLIGHT CHECKS
1480: - SELF-HEALING GATES with checkpoint creation
1481: - CONTEXT SYNCHRONIZATION PROTOCOL
1482: - CONFIDENCE SCORING
1483: 
1484: **Characteristics:**
1485: 
1486: - Multiple checkpoints per phase
1487: - Detailed pseudocode
1488: - Comprehensive error handling
1489: - Integration with Serena MCP
1490: 
1491: #### 4.2.2 KISS Template
1492: 
1493: **Use Case:** Simple features, quick implementations
1494: 
1495: **Key Sections:**
1496: 
1497: - Minimal CONTEXT (files, patterns, gotchas)
1498: - Streamlined IMPLEMENTATION (3-4 steps)
1499: - VALIDATION with automatic self-healing note
1500: 
1501: **Characteristics:**
1502: 
1503: - Single checkpoint at end
1504: - High-level pseudocode
1505: - Essential error handling only
1506: - Standard validation commands
1507: 
1508: #### 4.2.3 Template Selection
1509: 
1510: | Factor | Self-Healing | KISS |
1511: |--------|--------------|------|
1512: | Feature complexity | High (multi-component) | Low (single component) |
1513: | Integration points | 3+ systems | 1-2 systems |
1514: | Risk level | Production-critical | Non-critical |
1515: | Team experience | Junior developers | Senior developers |
1516: | Time available | Ample | Limited |
1517: 
1518: ---
1519: 
1520: ### 4.3 Infrastructure
1521: 
1522: ```mermaid
1523: graph LR
1524:     A["project/"]
1525: 
1526:     A --> B[".claude/"]
1527:     B --> B1["commands/<br/>9 Slash commands"]
1528:     B1 --> B1a["batch-gen-prp.md"]
1529:     B1 --> B1b["batch-exe-prp.md"]
1530:     B1 --> B1c["execute-prp.md"]
1531:     B1 --> B1d["vacuum.md, denoise.md, etc."]
1532:     B --> B2["CLAUDE.md<br/>Global rules"]
1533: 
1534:     A --> C["PRPs/"]
1535:     C --> C1["templates/"]
1536:     C1 --> C1a["self-healing.md"]
1537:     C1 --> C1b["kiss.md"]
1538:     C --> C2["ai_docs/<br/>Cached docs"]
1539:     C --> C3["feature-requests/<br/>INITIAL.md files"]
1540:     C --> C4["PRP-*.md<br/>Generated PRPs"]
1541: 
1542:     A --> D["examples/"]
1543:     D --> D1["patterns/<br/>Reusable code"]
1544: 
1545:     A --> E["tools/"]
1546:     E --> E1["ce/<br/>CLI source"]
1547: 
1548:     A --> F["Project source code"]
1549: 
1550:     style A fill:#e3f2fd,color:#000
1551:     style B fill:#fff8e1,color:#000
1552:     style C fill:#f3e5f5,color:#000
1553:     style D fill:#b2ebf2,color:#000
1554:     style E fill:#ffe0b2,color:#000
1555:     style F fill:#ffecb3,color:#000
1556:     style B1 fill:#fff9c4,color:#000
1557:     style B2 fill:#fff9c4,color:#000
1558:     style C1 fill:#e1f5fe,color:#000
1559:     style C2 fill:#e1f5fe,color:#000
1560:     style C3 fill:#e1f5fe,color:#000
1561:     style C4 fill:#e1f5fe,color:#000
1562:     style D1 fill:#b2dfdb,color:#000
1563:     style E1 fill:#ffccbc,color:#000
1564: ```
1565: 
1566: **Purpose:**
1567: 
1568: - `.claude/` - Claude Code configuration
1569: - `PRPs/` - Specification documents
1570: - `examples/` - Reference implementations
1571: - `tools/` - Development utilities
1572: 
1573: ---
1574: 
1575: ## 5. Workflow
1576: 
1577: ### 5.1 Six-Step Process
1578: 
1579: ```mermaid
1580: graph TB
1581:     A["Step 1: CLAUDE.md<br/>Global Rules"] --> B["Step 2: INITIAL.md<br/>Feature Request"]
1582:     B --> B5["Step 2.5: Context Sync<br/>Health Check 1-2 min"]
1583:     B5 --> C["Step 3: PRP Generation<br/>10-15 min Research"]
1584:     C --> D["Step 4: Human Validation<br/>CRITICAL CHECKPOINT"]
1585:     D --> E["Step 5: /execute-prp<br/>20-90 min Implementation"]
1586:     E --> F["Step 6: Validation Loop<br/>L1-L4 + Self-Healing"]
1587:     F --> F5["Step 6.5: State Cleanup<br/>Context Sync 2-3 min"]
1588:     F5 --> G["Production Code<br/>10/10 Confidence"]
1589:     G -.->|Next PRP| B
1590: 
1591:     style A fill:#e3f2fd,color:#000
1592:     style B fill:#fff8e1,color:#000
1593:     style B5 fill:#e1f5fe,color:#000
1594:     style C fill:#f3e5f5,color:#000
1595:     style D fill:#ff9999,color:#000
1596:     style E fill:#b2ebf2,color:#000
1597:     style F fill:#ffe0b2,color:#000
1598:     style F5 fill:#e1f5fe,color:#000
1599:     style G fill:#c8e6c9,color:#000
1600: ```
1601: 
1602: ### 5.2 Step Breakdown
1603: 
1604: **Step 1: CLAUDE.md** (One-time setup)
1605: 
1606: - Establish project-wide rules
1607: - Define code structure limits
1608: - Specify testing requirements
1609: - Document style conventions
1610: 
1611: **Step 2: INITIAL.md** (2-5 minutes)
1612: 
1613: - Write FEATURE section (what to build)
1614: - Add EXAMPLES (similar code)
1615: - Link DOCUMENTATION (library docs)
1616: - List OTHER CONSIDERATIONS (gotchas)
1617: 
1618: **Step 2.5: Context Sync & Health Check** (1-2 minutes)
1619: 
1620: - Run `ce context sync` to refresh context with recent codebase changes
1621: - Run `ce context health` to verify context quality
1622: - Check drift score (abort if > 30% - indicates stale context)
1623: - Verify git clean state (warn if uncommitted changes)
1624: - **Purpose:** Ensure PRP generation uses fresh, accurate context
1625: - **Abort conditions:** High drift, failed sync, context corruption
1626: 
1627: **Step 3: PRP Generation** (10-15 minutes)
1628: 
1629: - **For single PRPs**: Manual PRP writing using templates (.ce/examples/prp-template.md)
1630: - **For batch PRPs**: `/batch-gen-prp PLAN.md` with parallel subagents
1631: - Automated research: codebase patterns, documentation, architecture
1632: - Generate complete PRP with all sections
1633: - Include validation commands and pseudocode
1634: 
1635: **Step 4: Human Validation** (5-10 minutes)
1636: 
1637: - Architecture review
1638: - Security audit
1639: - Requirement coverage check
1640: - Implementation sanity check
1641: 
1642: **Step 5: /execute-prp** (20-90 minutes)
1643: 
1644: - Parse PRP into tasks
1645: - Implement following blueprint
1646: - Run validation gates after each phase
1647: - Self-heal on failures
1648: 
1649: **Step 6: Validation Loop** (Continuous)
1650: 
1651: - Level 1: Syntax checks
1652: - Level 2: Unit tests
1653: - Level 3: Integration tests
1654: - Level 4: Pattern conformance (NEW)
1655:   - Compare implementation vs EXAMPLES from INITIAL.md
1656:   - Verify code follows documented patterns
1657:   - Detect architectural drift from specification
1658: - Self-correct until 10/10 confidence (all 4 gates pass)
1659: 
1660: **Step 6.5: State Cleanup & Context Sync** (2-3 minutes)
1661: 
1662: - Execute cleanup protocol (Section 5.6):
1663:   - Delete intermediate git checkpoints (keep final only)
1664:   - Archive PRP-scoped Serena memories to project knowledge
1665:   - Reset validation state counters
1666: - Run `ce context sync` to index new code
1667: - Run `ce context health` to verify clean state
1668: - Create final checkpoint: `checkpoint-{prp_id}-final`
1669: - **Purpose:** Prevent state leakage into next PRP, maintain context quality
1670: - **Verification:** Clean git tags, drift score stable, no orphaned memories
1671: 
1672: ### 5.3 Time Distribution
1673: 
1674: | Feature Complexity | Context Sync | PRP Gen | Execution | Cleanup | Total | Manual Equiv |
1675: |-------------------|--------------|---------|-----------|---------|-------|--------------|
1676: | Simple | 1-2 min | 5-8 min | 8-15 min | 2-3 min | 16-28 min | 3-5 hrs |
1677: | Medium | 1-2 min | 10-15 min | 20-40 min | 2-3 min | 33-60 min | 8-15 hrs |
1678: | Complex | 1-2 min | 15-25 min | 45-90 min | 2-3 min | 63-120 min | 20-40 hrs |
1679: 
1680: **Notes:**
1681: 
1682: - **Context Sync (Step 2.5):** Health check + drift detection before PRP generation
1683: - **Execution:** Includes L1-L4 validation gates and self-healing
1684: - **Cleanup (Step 6.5):** State cleanup, memory archival, context sync after completion
1685: - **Total:** End-to-end per PRP, including quality gates
1686: 
1687: **Speed Improvement:** 10-40x faster than manual development (typically 10-24x, exceptional cases up to 40x).
1688: 
1689: **Context overhead:** Steps 2.5 and 6.5 add 3-5 min total but prevent state leakage and ensure quality.
1690: 
1691: ### 5.4 Autonomy Levels
1692: 
1693: | Step | Human Involvement | AI Autonomy |
1694: |------|------------------|-------------|
1695: | 1. CLAUDE.md | Manual (one-time) | 0% |
1696: | 2. INITIAL.md | Manual | 0% |
1697: | 2.5. Context Sync | None | 100% |
1698: | 3. PRP Generation | Manual or /batch-gen-prp | 0-100% |
1699: | 4. Validation | Manual (required) | 0% |
1700: | 5. /execute-prp | None | 100% |
1701: | 6. Validation loop (L1-L4) | None | 100% |
1702: | 6.5. State Cleanup | None | 100% |
1703: 
1704: **Key Insight:** Human intervention only at specification (Steps 1-2) and critical checkpoint (Step 4). Context sync and cleanup are fully automated.
1705: 
1706: ### 5.5 Escalation Triggers
1707: 
1708: **When to Intervene During Autonomous Execution (Steps 5-6):**
1709: 
1710: 1. **Persistent Failures**
1711:    - Same error after 3 self-healing attempts
1712:    - Validation failures without clear resolution path
1713:    - Circular dependency or conflicting requirements detected
1714: 
1715: 2. **Architectural Decisions Required**
1716:    - Major refactoring needed beyond PRP scope
1717:    - Design patterns need human judgment
1718:    - Performance trade-offs require business context
1719: 
1720: 3. **External Dependencies**
1721:    - Third-party API failures or breaking changes
1722:    - Database schema conflicts
1723:    - Environment configuration issues
1724: 
1725: 4. **Security Concerns**
1726:    - Potential vulnerability detected during implementation
1727:    - Secret exposure risk identified
1728:    - Permission escalation patterns found
1729: 
1730: 5. **Ambiguous Requirements**
1731:    - PRP specification conflicts with existing code
1732:    - Edge cases not covered in acceptance criteria
1733:    - Business logic interpretation unclear
1734: 
1735: **Escalation Process:**
1736: 
1737: - System logs issue to `PRPs/ISSUES.md`
1738: - Execution pauses at safe checkpoint
1739: - Human reviews context and provides guidance
1740: - Execution resumes with clarified direction
1741: 
1742: ### 5.6 PRP State Cleanup Protocol
1743: 
1744: **Purpose:** Prevent state leakage and desynchronization between PRP executions
1745: 
1746: **When to Execute:** After Step 6 (Validation Loop) completion, before starting next PRP
1747: 
1748: **Cleanup Operations:**
1749: 
1750: 1. **Git Checkpoint Cleanup**
1751: 
1752:    ```bash
1753:    # Keep only final checkpoint for historical reference
1754:    git tag -d checkpoint-{prp_id}-phase1
1755:    git tag -d checkpoint-{prp_id}-phase2
1756:    # Retain: checkpoint-{prp_id}-final
1757:    ```
1758: 
1759: 2. **Serena Memory Archival**
1760: 
1761:    ```python
1762:    # Archive ephemeral PRP memories
1763:    prp_learnings = read_memory(f"{prp_id}-learnings")
1764:    write_memory("project-patterns", prp_learnings)  # Merge to project knowledge
1765:    delete_memory(f"{prp_id}-checkpoint-*")          # Remove ephemeral checkpoints
1766:    delete_memory(f"{prp_id}-temp-*")                # Remove temporary state
1767:    ```
1768: 
1769: 3. **Validation State Reset**
1770:    - Clear self-healing attempt counters
1771:    - Reset error history for next PRP
1772:    - Archive test results to `PRPs/{prp_id}/validation-log.md`
1773: 
1774: 4. **Context Health Check**
1775: 
1776:    ```bash
1777:    ce context health           # Verify clean state
1778:    ce context prune           # Remove stale context entries
1779:    ```
1780: 
1781: **State Boundaries:**
1782: 
1783: | State Type | Scope | Cleanup Strategy |
1784: |------------|-------|------------------|
1785: | Git Checkpoints | Per-PRP | Delete intermediate, keep final |
1786: | Serena Memories | Per-PRP | Archive learnings, delete ephemeral |
1787: | Validation Logs | Per-PRP | Archive to PRP directory |
1788: | Self-healing State | Per-PRP | Reset counters to zero |
1789: | Project Knowledge | Global | Merge PRP learnings, persist patterns |
1790: 
1791: **Verification:**
1792: 
1793: ```bash
1794: # After cleanup, verify no state leakage
1795: git tag | grep checkpoint-{prp_id}  # Should show only *-final tag
1796: ce context health                   # Should report clean state
1797: ```
1798: 
1799: **Critical Rule:** No PRP state should persist into the next PRP execution except:
1800: 
1801: - Final checkpoint (for rollback capability)
1802: - Generalized learnings (merged into project knowledge)
1803: - Persistent project structure knowledge
1804: 
1805: ### See Also
1806: 
1807: - [Workflow Patterns](../docs/research/06-workflow-patterns.md) - Detailed six-step process, timing data, and workflow best practices
1808: - [Product Requirements Prompt (PRP) System](../docs/research/01-prp-system.md) - PRP generation and execution workflows
1809: - [Command Reference](../docs/research/07-commands-reference.md) - Command sequences for workflow automation
1810: 
1811: ---
1812: 
1813: ## 6. Implementation Patterns
1814: 
1815: ### 6.1 No Fishy Fallbacks
1816: 
1817: **Principle:** Fast failure with actionable errors
1818: 
1819: **Anti-Pattern:**
1820: 
1821: ```python
1822: def process_data(params):
1823:     try:
1824:         result = complex_operation(params)
1825:         return result
1826:     except Exception:
1827:         return {"success": True}  # FISHY FALLBACK!
1828: ```
1829: 
1830: **Best Practice:**
1831: 
1832: ```python
1833: def process_data(params):
1834:     try:
1835:         result = complex_operation(params)
1836:         return result
1837:     except ValueError as e:
1838:         raise ValueError(
1839:             f"Invalid parameters: {e}\n"
1840:             f"üîß Troubleshooting: Check param format and ranges"
1841:         ) from e
1842: ```
1843: 
1844: ### 6.2 3 LOC Rule
1845: 
1846: **Principle:** Strict enforcement for ad-hoc code
1847: 
1848: **Rationale:**
1849: 
1850: - Forces code organization
1851: - Prevents unmaintainable inline scripts
1852: - Encourages file-based development
1853: 
1854: **Enforcement:**
1855: 
1856: ```python
1857: # Validate LOC count
1858: lines = [line for line in code.split('\n') if line.strip()]
1859: if len(lines) > 3:
1860:     raise ValueError(
1861:         f"Ad-hoc code exceeds 3 LOC limit (found {len(lines)} lines)\n"
1862:         f"üîß Troubleshooting: Move code to tmp/ file"
1863:     )
1864: ```
1865: 
1866: **Examples:**
1867: 
1868: ```bash
1869: # ‚úÖ ALLOWED (3 LOC)
1870: run_py --code "x = [1,2,3]; y = sum(x); print(y)"
1871: 
1872: # ‚ùå FORBIDDEN (4 LOC)
1873: run_py --code "x = 1
1874: y = 2
1875: z = 3
1876: w = 4
1877: print(x+y+z+w)"
1878: 
1879: # ‚úÖ REQUIRED (use file)
1880: run_py --file tmp/calculation.py
1881: ```
1882: 
1883: ### 6.3 Real Functionality Testing
1884: 
1885: **Principle:** No mocks in production, no fake results
1886: 
1887: **Anti-Pattern:**
1888: 
1889: ```python
1890: def test_processor():
1891:     result = {"success": True}  # FAKE RESULT!
1892:     assert result["success"]
1893:     print("‚úÖ Test passed")  # FAKE SUCCESS!
1894: ```
1895: 
1896: **Best Practice:**
1897: 
1898: ```python
1899: def test_processor():
1900:     result = process_data(test_params)  # REAL CALL
1901:     assert result["success"] is True
1902:     assert "processed" in result["data"]
1903:     print(f"‚úÖ Real result: {result}")
1904: ```
1905: 
1906: ### 6.4 Auto-Detect Mode
1907: 
1908: **Principle:** Smart detection reduces cognitive load
1909: 
1910: **Implementation:**
1911: 
1912: ```python
1913: # Detect file path vs code
1914: if "/" in auto or auto.endswith(".py"):
1915:     file = auto  # Path detected
1916: else:
1917:     code = auto  # Code detected
1918: ```
1919: 
1920: **Usage:**
1921: 
1922: ```bash
1923: # No explicit flags needed
1924: run_py "print('hello')"     # Auto: code
1925: run_py "tmp/script.py"      # Auto: file path
1926: run_py "../data/analyze.py" # Auto: file path
1927: ```
1928: 
1929: ### 6.5 UV Package Management
1930: 
1931: **Principle:** Never edit pyproject.toml manually
1932: 
1933: **Rationale - Why Manual Edits Fail:**
1934: 
1935: - **Broken dependency resolution:** Manual version specs bypass UV's constraint solver, causing incompatible version combinations
1936: - **Missing lock file updates:** Changes to pyproject.toml don't auto-update uv.lock, leading to non-reproducible builds across environments
1937: - **Skipped transitive dependencies:** Direct edits miss cascading dependency updates, resulting in runtime import errors
1938: - **Build system conflicts:** Incorrect build-system specifications break installation on different platforms
1939: 
1940: **Operations:**
1941: 
1942: ```bash
1943: # ‚úÖ REQUIRED
1944: uv add requests              # Add production dependency
1945: uv add --dev pytest          # Add dev dependency
1946: uv sync                      # Install dependencies
1947: 
1948: # ‚ùå FORBIDDEN
1949: # Manually editing pyproject.toml
1950: # Using pip directly
1951: ```
1952: 
1953: ### See Also
1954: 
1955: - [Best Practices and Anti-Patterns](../docs/research/09-best-practices-antipatterns.md) - Comprehensive implementation patterns, anti-patterns, and code quality guidelines
1956: - [Tooling and Configuration](../docs/research/10-tooling-configuration.md) - UV package management setup and best practices
1957: 
1958: ---
1959: 
1960: ## 7. Quality Assurance
1961: 
1962: ### 7.1 Validation Gate Implementation
1963: 
1964: #### 7.1.1 Level 1: Syntax & Style
1965: 
1966: **Speed:** 10 seconds
1967: **Tools:** Linters, formatters, type checkers
1968: **Auto-fix:** Yes
1969: 
1970: ```bash
1971: # Python
1972: black . && mypy . && pylint src/
1973: 
1974: # TypeScript
1975: npm run type-check && npm run lint && npm run format:check
1976: 
1977: # Python (UV-managed)
1978: cd tools && uv run pytest --collect-only  # Syntax validation
1979: ```
1980: 
1981: **Failure Action:** Auto-fix formatting, resolve type errors, re-run.
1982: 
1983: #### 7.1.2 Level 2: Unit Tests
1984: 
1985: **Speed:** 30-60 seconds
1986: **Tools:** Test frameworks (pytest, jest)
1987: **Auto-fix:** Conditional
1988: 
1989: ```bash
1990: # Python
1991: uv run pytest tests/ --coverage --verbose
1992: 
1993: # TypeScript
1994: npm test -- --coverage --verbose
1995: ```
1996: 
1997: **Failure Action:**
1998: 
1999: 1. Analyze test failure message
2000: 2. Identify root cause (logic bug, edge case)
2001: 3. Apply fix to implementation
2002: 4. Re-run tests
2003: 5. Repeat until pass
2004: 
2005: #### 7.1.3 Level 3: Integration Tests
2006: 
2007: **Speed:** 1-2 minutes
2008: **Tools:** API clients, E2E frameworks
2009: **Auto-fix:** Manual (systematic debugging)
2010: 
2011: ```bash
2012: # Start services
2013: npm run dev:test &
2014: sleep 5
2015: 
2016: # Run integration tests
2017: npm run test:integration
2018: 
2019: # Manual verification
2020: curl -X POST http://localhost:3000/api/endpoint \
2021:   -H "Content-Type: application/json" \
2022:   -d '{"test": "data"}'
2023: ```
2024: 
2025: **Failure Action:**
2026: 
2027: 1. Check server logs
2028: 2. Verify environment configuration
2029: 3. Debug with MCP tools
2030: 4. Fix issues systematically
2031: 5. Re-validate
2032: 
2033: ---
2034: 
2035: ### 7.2 Self-Healing Mechanism
2036: 
2037: #### 7.2.1 Standard Loop
2038: 
2039: ```python
2040: def self_healing_loop(validation_cmd: str, max_attempts: int = 3) -> bool:
2041:     """Self-healing validation loop."""
2042:     for attempt in range(max_attempts):
2043:         result = run_cmd(validation_cmd)
2044: 
2045:         if result["success"]:
2046:             return True
2047: 
2048:         # Parse error
2049:         error = parse_error(result["stderr"])
2050: 
2051:         # Locate code
2052:         location = find_error_location(error)
2053: 
2054:         # Apply fix
2055:         apply_fix(location, error)
2056: 
2057:         # Log attempt
2058:         print(f"Attempt {attempt + 1}/{max_attempts}: Applied fix for {error.type}")
2059: 
2060:     # Escalate after max attempts
2061:     raise ValidationError(f"Failed after {max_attempts} attempts: {error}")
2062: ```
2063: 
2064: #### 7.2.2 Error Categories
2065: 
2066: *Note: Percentages represent proportion of all validation failures, not probability of occurrence*
2067: 
2068: | Error Type | Frequency | Auto-Fix Success | Typical Fix |
2069: |------------|-----------|------------------|-------------|
2070: | Type errors | 15% | 95% | Add type annotations |
2071: | Unit test failures | 25% | 85% | Fix logic bugs |
2072: | Integration failures | 10% | 70% | Fix configuration |
2073: | Style violations | 30% | 100% | Auto-format |
2074: | Coverage gaps | 20% | 90% | Add test cases |
2075: 
2076: **Interpretation:** When validation fails, style violations are the most common issue (30% of failures), followed by unit test failures (25%). A single execution may trigger multiple error categories simultaneously.
2077: 
2078: ---
2079: 
2080: ### 7.3 Confidence Scoring System
2081: 
2082: #### 7.3.1 Score Calculation
2083: 
2084: ```python
2085: def calculate_confidence(results: ValidationResults) -> int:
2086:     """Calculate confidence score (1-10).
2087: 
2088:     Scoring breakdown:
2089:     - Baseline: 6 (untested code)
2090:     - Level 1 (Syntax): +1
2091:     - Level 2 (Unit tests): +2
2092:     - Level 3 (Integration): +1
2093:     - Level 4 (Pattern conformance): +1 (NEW)
2094:     - Max: 10/10 (production-ready)
2095:     """
2096:     score = 6  # Baseline for untested code
2097: 
2098:     # Level 1: Syntax & Style (+1)
2099:     if results.syntax_pass:
2100:         score += 1
2101: 
2102:     # Level 2: Unit Tests (+2)
2103:     if results.unit_tests_pass and results.coverage > 0.8:
2104:         score += 2
2105: 
2106:     # Level 3: Integration (+1)
2107:     if results.integration_pass:
2108:         score += 1
2109: 
2110:     # Level 4: Pattern Conformance (+1)
2111:     if results.pattern_conformance_pass and results.drift_score < 0.10:
2112:         score += 1
2113: 
2114:     return min(score, 10)
2115: ```
2116: 
2117: **L4 Validation Requirements:**
2118: 
2119: - `pattern_conformance_pass`: Implementation matches EXAMPLES from INITIAL.md
2120: - `drift_score < 0.10`: Less than 10% architectural divergence (auto-accept threshold)
2121: - Scores 9/10: L1-L3 pass but pattern drift detected (10-30% range)
2122: - Score 10/10: All gates pass including pattern conformance
2123: 
2124: **Scoring Limitations:**
2125: This confidence scoring focuses on **code correctness and test coverage** but does not account for:
2126: 
2127: - Security vulnerability scanning (SAST/DAST)
2128: - Edge case coverage beyond unit tests
2129: - Performance benchmarks
2130: - Documentation completeness
2131: - Accessibility compliance (for UI code)
2132: 
2133: For production-critical systems, supplement with additional validation (security scans, performance testing, manual security review).
2134: 
2135: ### 7.4 Pipeline Architecture & Testing Strategy
2136: 
2137: #### 7.4.1 Design Principles
2138: 
2139: **Core Philosophy:**
2140: 
2141: - **Single source of truth:** Production logic = Test logic
2142: - **Composable:** Test individual nodes, subgraphs, or full pipeline
2143: - **Observable:** Mocked nodes visible in logs with clear indicators
2144: - **Strategy pattern:** Pluggable mock implementations
2145: - **CI/CD agnostic:** Abstract pipeline definition, concrete execution
2146: 
2147: **Key Requirements:**
2148: 
2149: 1. Same builder function constructs both production and test pipelines
2150: 2. Mock strategy interface allows clean substitution
2151: 3. E2E tests run full pipeline with mocked external dependencies
2152: 4. Integration tests run subgraphs with real components
2153: 5. Unit tests run individual nodes in isolation
2154: 
2155: #### 7.4.2 Pipeline Builder Pattern
2156: 
2157: **Architecture Diagram:**
2158: 
2159: ```mermaid
2160: graph TB
2161:     subgraph "Pipeline Builder"
2162:         PB["PipelineBuilder<br/>(mode: production | integration | e2e)"]
2163:         PB --> N1["Node: parse_initial"]
2164:         PB --> N2["Node: research_codebase"]
2165:         PB --> N3["Node: fetch_docs"]
2166:         PB --> N4["Node: generate_prp"]
2167:         PB --> N5["Node: validate_prp"]
2168:     end
2169: 
2170:     subgraph "Strategy Pattern"
2171:         N1 --> S1["RealParserStrategy"]
2172:         N2 --> S2A{"Mode?"}
2173:         S2A -->|production| S2R["RealSerenaStrategy"]
2174:         S2A -->|e2e/integration| S2M["MockSerenaStrategy üé≠"]
2175:         N3 --> S3A{"Mode?"}
2176:         S3A -->|production| S3R["RealContext7Strategy"]
2177:         S3A -->|e2e/integration| S3M["MockContext7Strategy üé≠"]
2178:         N4 --> S4A{"Mode?"}
2179:         S4A -->|production| S4R["RealLLMStrategy"]
2180:         S4A -->|e2e/integration| S4M["MockLLMStrategy üé≠"]
2181:         N5 --> S5["RealValidatorStrategy"]
2182:     end
2183: 
2184:     subgraph "Test Modes"
2185:         TU["Unit Test<br/>Single node"]
2186:         TI["Integration Test<br/>Subgraph with real nodes"]
2187:         TE["E2E Test<br/>Full pipeline, mocked externals"]
2188:     end
2189: 
2190:     TU -.-> N1
2191:     TI -.-> N4
2192:     TI -.-> N5
2193:     TE -.-> PB
2194: 
2195:     style PB fill:#e3f2fd,color:#000
2196:     style N1 fill:#fff8e1,color:#000
2197:     style N2 fill:#fff8e1,color:#000
2198:     style N3 fill:#fff8e1,color:#000
2199:     style N4 fill:#fff8e1,color:#000
2200:     style N5 fill:#fff8e1,color:#000
2201:     style S1 fill:#c8e6c9,color:#000
2202:     style S2R fill:#c8e6c9,color:#000
2203:     style S2M fill:#ffccbc,color:#000
2204:     style S3R fill:#c8e6c9,color:#000
2205:     style S3M fill:#ffccbc,color:#000
2206:     style S4R fill:#c8e6c9,color:#000
2207:     style S4M fill:#ffccbc,color:#000
2208:     style S5 fill:#c8e6c9,color:#000
2209:     style S2A fill:#fff9c4,color:#000
2210:     style S3A fill:#fff9c4,color:#000
2211:     style S4A fill:#fff9c4,color:#000
2212:     style TU fill:#e1f5fe,color:#000
2213:     style TI fill:#b2ebf2,color:#000
2214:     style TE fill:#b2dfdb,color:#000
2215: ```
2216: 
2217: **Code Architecture:**
2218: 
2219: ```python
2220: from typing import Protocol, TypeVar, Generic
2221: from dataclasses import dataclass
2222: 
2223: # Strategy interface for mocks
2224: class NodeStrategy(Protocol):
2225:     """Strategy for node execution (real or mock)."""
2226:     def execute(self, input_data: dict) -> dict:
2227:         """Execute node logic."""
2228:         ...
2229: 
2230:     def is_mocked(self) -> bool:
2231:         """Return True if this is a mock implementation."""
2232:         ...
2233: 
2234: # Builder pattern for pipeline construction
2235: class PipelineBuilder:
2236:     """Builds pipelines with pluggable node strategies."""
2237: 
2238:     def __init__(self, mode: str = "production"):
2239:         """
2240:         Args:
2241:             mode: "production", "integration", or "e2e"
2242:         """
2243:         self.mode = mode
2244:         self.nodes = {}
2245:         self.edges = []
2246: 
2247:     def add_node(
2248:         self,
2249:         name: str,
2250:         strategy: NodeStrategy,
2251:         description: str = ""
2252:     ) -> "PipelineBuilder":
2253:         """Add node with execution strategy."""
2254:         self.nodes[name] = {
2255:             "strategy": strategy,
2256:             "description": description,
2257:             "mocked": strategy.is_mocked()
2258:         }
2259:         return self
2260: 
2261:     def add_edge(self, from_node: str, to_node: str) -> "PipelineBuilder":
2262:         """Add edge between nodes."""
2263:         self.edges.append((from_node, to_node))
2264:         return self
2265: 
2266:     def build(self) -> "Pipeline":
2267:         """Construct executable pipeline."""
2268:         # Log mocked nodes
2269:         mocked = [n for n, data in self.nodes.items() if data["mocked"]]
2270:         if mocked:
2271:             logger.info(f"üé≠ MOCKED NODES: {', '.join(mocked)}")
2272: 
2273:         return Pipeline(self.nodes, self.edges)
2274: 
2275: 
2276: # Example: LangGraph integration (optional, for convenience)
2277: from langgraph.graph import StateGraph
2278: 
2279: def to_langgraph(pipeline: Pipeline) -> StateGraph:
2280:     """Convert pipeline to LangGraph for visualization/execution."""
2281:     graph = StateGraph()
2282: 
2283:     for node_name, node_data in pipeline.nodes.items():
2284:         mock_indicator = "üé≠ " if node_data["mocked"] else ""
2285:         graph.add_node(
2286:             f"{mock_indicator}{node_name}",
2287:             node_data["strategy"].execute
2288:         )
2289: 
2290:     for from_node, to_node in pipeline.edges:
2291:         graph.add_edge(from_node, to_node)
2292: 
2293:     return graph.compile()
2294: ```
2295: 
2296: #### 7.4.3 Mock Strategy Interface
2297: 
2298: **Clean optionality - strategy determines behavior:**
2299: 
2300: ```python
2301: # Real implementation
2302: class OpenAINodeStrategy:
2303:     def execute(self, input_data: dict) -> dict:
2304:         response = openai.ChatCompletion.create(
2305:             model="gpt-4",
2306:             messages=input_data["messages"]
2307:         )
2308:         return {"response": response.choices[0].message.content}
2309: 
2310:     def is_mocked(self) -> bool:
2311:         return False
2312: 
2313: 
2314: # Mock implementation (same interface)
2315: class MockOpenAINodeStrategy:
2316:     def __init__(self, canned_response: str = "Mock response"):
2317:         self.canned_response = canned_response
2318: 
2319:     def execute(self, input_data: dict) -> dict:
2320:         logger.info(f"üé≠ MOCK: OpenAI called with {len(input_data['messages'])} messages")
2321:         return {"response": self.canned_response}
2322: 
2323:     def is_mocked(self) -> bool:
2324:         return True
2325: 
2326: 
2327: # Factory for test convenience
2328: def create_node_strategy(
2329:     node_type: str,
2330:     mode: str = "production",
2331:     **mock_params
2332: ) -> NodeStrategy:
2333:     """Factory creates real or mock strategy based on mode."""
2334:     if mode == "production":
2335:         return REAL_STRATEGIES[node_type]()
2336:     else:
2337:         return MOCK_STRATEGIES[node_type](**mock_params)
2338: ```
2339: 
2340: #### 7.4.4 Test Composition Patterns
2341: 
2342: **E2E Test (Full Pipeline, Mocked External Dependencies):**
2343: 
2344: ```python
2345: def test_prp_execution_e2e():
2346:     """E2E: Full pipeline with mocked external APIs."""
2347: 
2348:     # Build pipeline in E2E mode
2349:     pipeline = (
2350:         PipelineBuilder(mode="e2e")
2351:         .add_node("parse_initial", create_node_strategy("parser", "e2e"))
2352:         .add_node("research_codebase", create_node_strategy("serena", "e2e"))
2353:         .add_node("fetch_docs", create_node_strategy("context7", "e2e"))
2354:         .add_node("generate_prp", create_node_strategy("llm", "e2e",
2355:                                                        canned_response=MOCK_PRP))
2356:         .add_node("validate_prp", create_node_strategy("validator", "production"))
2357:         .add_edge("parse_initial", "research_codebase")
2358:         .add_edge("research_codebase", "fetch_docs")
2359:         .add_edge("fetch_docs", "generate_prp")
2360:         .add_edge("generate_prp", "validate_prp")
2361:         .build()
2362:     )
2363: 
2364:     # Execute
2365:     result = pipeline.run({"initial_md": SAMPLE_INITIAL})
2366: 
2367:     # Assertions
2368:     assert result["validate_prp"]["success"]
2369:     assert "GOAL" in result["generate_prp"]["response"]
2370: 
2371:     # Log shows: üé≠ MOCKED NODES: research_codebase, fetch_docs, generate_prp
2372: 
2373: 
2374: **Integration Test (Subgraph, Real Components):**
2375: 
2376: ```python
2377: def test_validation_subgraph_integration():
2378:     """Integration: Real validation nodes, mocked generation."""
2379: 
2380:     pipeline = (
2381:         PipelineBuilder(mode="integration")
2382:         .add_node("generate_prp", create_node_strategy("llm", "integration",
2383:                                                        canned_response=VALID_PRP))
2384:         .add_node("validate_syntax", create_node_strategy("validator_l1", "production"))
2385:         .add_node("validate_tests", create_node_strategy("validator_l2", "production"))
2386:         .add_node("validate_integration", create_node_strategy("validator_l3", "production"))
2387:         .add_edge("generate_prp", "validate_syntax")
2388:         .add_edge("validate_syntax", "validate_tests")
2389:         .add_edge("validate_tests", "validate_integration")
2390:         .build()
2391:     )
2392: 
2393:     result = pipeline.run({})
2394: 
2395:     # Real L1-L3 validation runs
2396:     assert result["validate_integration"]["all_passed"]
2397: 
2398:     # Log shows: üé≠ MOCKED NODES: generate_prp
2399: 
2400: 
2401: **Unit Test (Single Node):**
2402: 
2403: ```python
2404: def test_parser_node_unit():
2405:     """Unit: Single node in isolation."""
2406: 
2407:     strategy = create_node_strategy("parser", "production")
2408:     result = strategy.execute({"initial_md": SAMPLE_INITIAL})
2409: 
2410:     assert result["feature_name"]
2411:     assert result["examples"]
2412: ```
2413: 
2414: #### 7.4.5 CI/CD Pipeline Abstraction
2415: 
2416: **Design Goals:**
2417: 
2418: - Unbound from concrete CI/CD implementation (GitHub Actions, GitLab CI, Jenkins)
2419: - Readable, manipulable signatures
2420: - Easy to test pipeline definition itself
2421: 
2422: **Abstract Pipeline Definition:**
2423: 
2424: ```yaml
2425: # ci_pipeline.yml - Abstract pipeline definition
2426: name: context-engineering-validation
2427: 
2428: stages:
2429:   - stage: lint
2430:     nodes:
2431:       - name: python_lint
2432:         command: "uv run ruff check ."
2433:         strategy: real
2434:       - name: type_check
2435:         command: "uv run mypy ."
2436:         strategy: real
2437:     parallel: true
2438: 
2439:   - stage: test
2440:     nodes:
2441:       - name: unit_tests
2442:         command: "uv run pytest tests/unit/ -v"
2443:         strategy: real
2444:       - name: integration_tests
2445:         command: "uv run pytest tests/integration/ -v"
2446:         strategy: real
2447:     parallel: true
2448:     depends_on: [lint]
2449: 
2450:   - stage: e2e
2451:     nodes:
2452:       - name: e2e_prp_generation
2453:         command: "uv run pytest tests/e2e/test_prp_gen.py -v"
2454:         strategy: real
2455:       - name: e2e_prp_execution
2456:         command: "uv run pytest tests/e2e/test_prp_exec.py -v"
2457:         strategy: real
2458:     parallel: false
2459:     depends_on: [test]
2460: 
2461:   - stage: deploy
2462:     nodes:
2463:       - name: build_docs
2464:         command: "uv run mkdocs build"
2465:         strategy: real
2466:       - name: publish
2467:         command: "uv run publish.py"
2468:         strategy: conditional  # Only on main branch
2469:     depends_on: [e2e]
2470: 
2471: mock_strategies:
2472:   # Override for testing CI/CD pipeline itself
2473:   python_lint:
2474:     mode: mock
2475:     return_code: 0
2476:   e2e_prp_generation:
2477:     mode: mock
2478:     return_code: 0
2479:     output: "‚úÖ E2E tests passed (mocked)"
2480: ```
2481: 
2482: **Concrete Executor (GitHub Actions example):**
2483: 
2484: ```python
2485: # ci/executors/github_actions.py
2486: def render_github_actions(abstract_pipeline: dict) -> str:
2487:     """Convert abstract pipeline to GitHub Actions YAML."""
2488: 
2489:     jobs = {}
2490:     for stage in abstract_pipeline["stages"]:
2491:         job_name = stage["stage"]
2492:         jobs[job_name] = {
2493:             "runs-on": "ubuntu-latest",
2494:             "steps": [
2495:                 {"uses": "actions/checkout@v3"},
2496:                 {"name": "Setup Python", "uses": "actions/setup-python@v4"}
2497:             ]
2498:         }
2499: 
2500:         for node in stage["nodes"]:
2501:             jobs[job_name]["steps"].append({
2502:                 "name": node["name"],
2503:                 "run": node["command"]
2504:             })
2505: 
2506:         if stage.get("depends_on"):
2507:             jobs[job_name]["needs"] = stage["depends_on"]
2508: 
2509:     return yaml.dump({"jobs": jobs})
2510: ```
2511: 
2512: **Testing the CI/CD Pipeline Itself:**
2513: 
2514: ```python
2515: def test_ci_pipeline_structure():
2516:     """Test pipeline definition is valid."""
2517: 
2518:     pipeline = load_ci_pipeline("ci_pipeline.yml")
2519: 
2520:     # Test stage dependencies
2521:     assert pipeline.get_stage("test").depends_on == ["lint"]
2522:     assert pipeline.get_stage("e2e").depends_on == ["test"]
2523: 
2524:     # Test mocked execution
2525:     result = pipeline.run(mode="mock", mock_strategies=pipeline["mock_strategies"])
2526: 
2527:     assert result["lint"]["python_lint"]["return_code"] == 0
2528:     assert result["e2e"]["e2e_prp_generation"]["mocked"]
2529: ```
2530: 
2531: #### 7.4.6 Observable Mocking - Log Output Example
2532: 
2533: ```
2534: üöÄ Starting pipeline: prp-generation-e2e
2535: üìä Pipeline mode: e2e
2536: üé≠ MOCKED NODES: research_codebase, fetch_docs, generate_prp
2537: 
2538: [parse_initial] ‚úÖ Parsed INITIAL.md (23 lines, 3 examples)
2539: [research_codebase] üé≠ MOCK: Serena search returned 5 canned symbols
2540: [fetch_docs] üé≠ MOCK: Context7 returned React 18.2 docs (cached)
2541: [generate_prp] üé≠ MOCK: LLM generated PRP (using mock_prp_template.md)
2542: [validate_prp] ‚úÖ REAL: PRP validation passed (all sections present)
2543: 
2544: ‚úÖ Pipeline completed: 5 nodes, 3 mocked, 0 failures
2545: ‚è±Ô∏è  Duration: 1.2s (vs ~45s with real LLM calls)
2546: ```
2547: 
2548: ### See Also
2549: 
2550: - [Validation and Testing Framework](../docs/research/08-validation-testing.md) - Complete 4-level validation gates (L1-L4), self-healing implementation, and testing strategies
2551: - [Self-Healing Framework](../docs/research/04-self-healing-framework.md) - Detailed self-healing loops, error recovery, and auto-fix mechanisms
2552: 
2553: #### 7.3.2 Production Readiness Criteria
2554: 
2555: | Criterion | Requirement |
2556: |-----------|-------------|
2557: | Confidence score | 10/10 (all 4 gates pass) |
2558: | Test coverage | ‚â• 80% |
2559: | All validation gates | Pass (L1-L4 including pattern conformance) |
2560: | Error handling | Comprehensive |
2561: | Security scan | No issues |
2562: 
2563: ### 7.5 Security
2564: 
2565: **Vulnerability Mitigation**: Production-grade security through systematic vulnerability elimination
2566: 
2567: #### 7.5.1 CWE-78 Command Injection - ELIMINATED (PRP-22)
2568: 
2569: **Vulnerability Details**:
2570: - **Issue**: Improper Neutralization of Special Elements in OS Command (CWE-78)
2571: - **Location**: `tools/ce/core.py:35` - `subprocess.run(cmd, shell=True)`
2572: - **CVSS Score**: 8.1 (HIGH) ‚Üí 0 (vulnerability eliminated)
2573: - **Attack Vector**: `run_cmd(f"cat {user_input}")` with malicious input (`file.md; rm -rf /`)
2574: - **Impact**: Arbitrary command execution with application privileges
2575: 
2576: **Mitigation Strategy**:
2577: - ‚úÖ Replaced `shell=True` with `shell=False` + `shlex.split()`
2578: - ‚úÖ Eliminated shell interpretation of metacharacters (`;`, `|`, `>`, `<`, `$`, etc.)
2579: - ‚úÖ Maintained backward compatibility (accepts both strings and lists)
2580: - ‚úÖ Added Python helper functions to replace shell pipelines
2581: 
2582: **Verification** (PRP-22):
2583: - ‚úÖ **Security Tests**: 38/38 tests pass (injection prevention verified)
2584: - ‚úÖ **Regression Tests**: 631/631 tests pass (no functional impact)
2585: - ‚úÖ **shell=True usage**: 0 occurrences in production code
2586: - ‚úÖ **CVSS Reduction**: 8.1 ‚Üí 0 (vulnerability completely eliminated)
2587: 
2588: **Affected Files** (6 locations):
2589: 1. `tools/ce/core.py:35` - Core `run_cmd()` function
2590: 2. `tools/ce/context.py:32` - Git file count
2591: 3. `tools/ce/context.py:552` - Drift score calculation
2592: 4. `tools/ce/context.py:573-574` - Dependency change detection
2593: 5. `tools/ce/context.py:637` - Context health check
2594: 6. `tools/ce/context.py:662-663` - Dependency changes (health)
2595: 
2596: **Security Posture**:
2597: - ‚úÖ Zero known vulnerabilities in production code
2598: - ‚úÖ Comprehensive injection prevention (shell, SQL, path traversal)
2599: - ‚úÖ Industry best practices (CISA, MITRE, Bandit compliance)
2600: - ‚úÖ Continuous security validation via pytest security suite
2601: 
2602: **References**:
2603: - [CWE-78 Definition](https://cwe.mitre.org/data/definitions/78.html) - MITRE/NIST
2604: - [CISA Secure Design Alert - OS Command Injection](https://www.cisa.gov/resources-tools/resources/secure-design-alert-eliminating-os-command-injection-vulnerabilities)
2605: - [Bandit B602 Security Check](https://bandit.readthedocs.io/en/latest/plugins/b602_subprocess_popen_with_shell_equals_true.html)
2606: - [PRP-22: Command Injection Vulnerability Fix](../../PRPs/executed/PRP-22-command-injection-vulnerability-fix.md)
2607: 
2608: #### 7.5.2 Security Testing Framework
2609: 
2610: **Test Coverage**:
2611: - **38 security-specific tests** - Injection prevention, input validation, path traversal
2612: - **631 regression tests** - Ensure security fixes don't break functionality
2613: - **CI/CD integration** - Automated security validation on every commit
2614: 
2615: **Security Patterns**:
2616: - Input validation before command execution
2617: - Path sanitization for file operations
2618: - Error messages without sensitive data leakage
2619: - Principle of least privilege (no unnecessary permissions)
2620: 
2621: ---
2622: 
2623: ## 8. Performance Metrics
2624: 
2625: ### 8.1 Real Case Study: PRP Taskmaster
2626: 
2627: **Project:** MCP server for task management with LLM parsing
2628: 
2629: | Metric | Value |
2630: |--------|-------|
2631: | Total execution time | 25 minutes |
2632: | Tools built | 18 fully functional |
2633: | Lines of code | ~1,200 |
2634: | Test coverage | 87% |
2635: | Validation failures | 2 (auto-fixed) |
2636: | Human intervention | 0 during implementation |
2637: | First-pass success | Yes |
2638: 
2639: **Manual Equivalent:**
2640: 
2641: - Architecture design: 2 hrs
2642: - Implementation: 8 hrs
2643: - Testing: 3 hrs
2644: - Debugging: 2 hrs
2645: - **Total: 15 hours** (36x speedup)
2646: 
2647: **‚ö†Ô∏è Case Study Context:**
2648: 
2649: This 36x speedup represents an **exceptional outlier** under optimal conditions:
2650: 
2651: - **Well-scoped task:** MCP server with clear interface boundaries
2652: - **Familiar patterns:** Task management is well-understood domain
2653: - **Mature tooling:** MCP protocol has established conventions
2654: - **Experienced operator:** User proficient in PRP creation and validation
2655: 
2656: **Typical Performance:** Most production features achieve 10-24x speedup. Factors affecting speedup:
2657: 
2658: - Complex integrations: 10-15x (multiple systems, external APIs)
2659: - Greenfield features: 15-20x (new patterns, no legacy constraints)
2660: - Well-scoped additions: 20-30x (clear boundaries, established patterns)
2661: - Exceptional cases: 30-40x (perfect alignment of scope, patterns, tooling)
2662: 
2663: **Cost Savings:** $2,250 per feature (at $150/hr senior developer rate, based on 15 hr manual estimate)
2664: 
2665: ### See Also
2666: 
2667: - [Product Requirements Prompt (PRP) System](../docs/research/01-prp-system.md) - Real case studies, PRP Taskmaster example, and performance data
2668: - [Workflow Patterns](../docs/research/06-workflow-patterns.md) - Detailed timing breakdowns and productivity metrics
2669: 
2670: ---
2671: 
2672: ### 8.2 Success Rates
2673: 
2674: | Metric | Value | Threshold |
2675: |--------|-------|-----------|
2676: | First-pass success rate | 85% | 80% |
2677: | Second-pass success rate | 97% | 95% |
2678: | Self-healing success rate | 92% | 85% |
2679: | Production readiness | 94% | 90% |
2680: 
2681: **Definitions:**
2682: 
2683: - **First-pass:** Code works without validation failures (85% of executions)
2684: - **Second-pass:** Code works after first self-healing iteration
2685: - **Self-healing:** Validation failures fixed automatically (92% fix rate)
2686: - **Production-ready:** Meets all quality gates (10/10 confidence, L1-L4 pass)
2687: 
2688: **Success Rate Calculation:**
2689: 
2690: - First-pass success: 85% complete immediately
2691: - Remaining 15% enter self-healing
2692: - Self-healing fixes 92% of the 15% = 13.8%
2693: - **Overall success rate:** 85% + 13.8% = **98.8%** after first self-healing cycle
2694: - Second-pass success (97%) refers to success after allowing one more iteration beyond self-healing
2695: 
2696: ---
2697: 
2698: ### 8.3 Productivity Impact
2699: 
2700: **Single Developer:**
2701: 
2702: - Features per week (manual): 2-3
2703: - Features per week (PRP-driven): 8-12
2704: - **Productivity increase: 3-4x**
2705: 
2706: **Team of 5:**
2707: 
2708: - Features per week (manual): 10-15
2709: - Features per week (PRP-driven): 40-60
2710: - **Productivity increase: 3-4x**
2711: 
2712: **Quality Consistency:**
2713: 
2714: - Code style: 100% consistent (enforced via CLAUDE.md)
2715: - Test coverage: 100% consistent (enforced via validation gates)
2716: - Documentation: 100% consistent (generated from PRPs)
2717: 
2718: ---
2719: 
2720: ### 8.4 Scalability
2721: 
2722: #### 8.4.1 Codebase Size Impact
2723: 
2724: | Codebase Size | PRP Generation | Execution Time |
2725: |---------------|----------------|----------------|
2726: | Small (< 10k LOC) | Baseline | Baseline |
2727: | Medium (10k-50k LOC) | +20% | +15% |
2728: | Large (50k-200k LOC) | +40% | +25% |
2729: | Very Large (> 200k LOC) | +60% | +35% |
2730: 
2731: **Mitigation:**
2732: 
2733: - Use Serena MCP for efficient navigation
2734: - Cache patterns in `examples/` directory
2735: - Maintain `PRPs/ai_docs/` with key library info
2736: 
2737: ### See Also
2738: 
2739: - [Validation and Testing Framework](../docs/research/08-validation-testing.md) - Performance optimization and validation efficiency
2740: - [Self-Healing Framework](../docs/research/04-self-healing-framework.md) - Self-healing performance metrics and success rate data
2741: 
2742: #### 8.4.2 Quality vs Speed Tradeoff
2743: 
2744: | Priority | Template | Gates | Time | Quality |
2745: |----------|----------|-------|------|---------|
2746: | Speed | KISS | Level 1-2 only | 50% faster | 7-8/10 (L3-L4 skipped) |
2747: | Balanced | KISS | L1-L3 | Standard | 8-9/10 (L4 optional) |
2748: | Quality | Self-healing | L1-L4 + checkpoints | 30% slower | 10/10 (all gates) |
2749: 
2750: ---
2751: 
2752: ## 9. Design Objectives & Performance Targets
2753: 
2754: *Based on 150+ executions across 12 projects (Jan-Oct 2025)*
2755: 
2756: ### 9.1 Reliability Targets
2757: 
2758: 1. **Context Completeness:** PRP contains all information needed for implementation
2759: 2. **Validation Coverage:** Four-level gates (L1-L4) catch 97% of errors and prevent pattern drift
2760: 3. **Self-Healing:** 92% of failures automatically corrected
2761: 4. **Production Readiness:** 94% of executions meet 10/10 confidence threshold (all 4 gates pass)
2762: 
2763: ### 9.2 Performance Targets
2764: 
2765: 1. **Speed:** 10-40x faster than manual development (typically 10-24x)
2766: 2. **Consistency:** 100% adherence to project conventions
2767: 3. **Coverage:** 80%+ test coverage on all implementations
2768: 4. **Documentation:** Complete from PRP specifications
2769: 
2770: ### 9.3 Security Guarantees
2771: 
2772: 1. **No Secret Exposure:** Automated detection of API keys, passwords
2773: 2. **No Manual .env Edits:** Environment variables via templates only
2774: 3. **Validation Before Commit:** All gates must pass
2775: 4. **Checkpoint Recovery:** Restore to last known good state
2776: 
2777: ### See Also
2778: 
2779: - [Validation and Testing Framework](../docs/research/08-validation-testing.md) - Complete validation and testing strategies
2780: - [Self-Healing Framework](../docs/research/04-self-healing-framework.md) - Detailed design objectives and performance targets
2781: 
2782: ---
2783: 
2784: ## 10. Operational Model
2785: 
2786: ### 10.1 Development Modes
2787: 
2788: | Mode | Use Case | Speed | Quality | Human Input |
2789: |------|----------|-------|---------|-------------|
2790: | **Research** | Understanding codebase | Slow | N/A | High |
2791: | **Generation** | Creating PRPs | Medium | High | Medium |
2792: | **Execution** | Implementing features | Fast | High | Low |
2793: | **Validation** | Testing and verification | Fast | Critical | None |
2794: 
2795: ### 10.2 Decision Points
2796: 
2797: ```mermaid
2798: graph TD
2799:     A["Feature Request"] --> B{"Complexity?"}
2800:     B -->|"Simple"| C["KISS Template"]
2801:     B -->|"Complex"| D["Self-Healing Template"]
2802: 
2803:     C --> E["PRP Generation"]
2804:     D --> E
2805: 
2806:     E --> F["Human Validation"]
2807: 
2808:     F --> G{"Approved?"}
2809:     G -->|"No"| H["Revise"]
2810:     H --> E
2811:     G -->|"Yes"| I["/execute-prp"]
2812: 
2813:     I --> J{"First-Pass Success?"}
2814:     J -->|"Yes"| K["Production"]
2815:     J -->|"No"| L{"Auto-Fixable?"}
2816:     L -->|"Yes"| M["Self-Heal"]
2817:     L -->|"No"| N["Manual Debug"]
2818:     M --> J
2819:     N --> I
2820: 
2821:     style A fill:#fff8e1,color:#000
2822:     style B fill:#fff3e0,color:#000
2823:     style C fill:#b2ebf2,color:#000
2824:     style D fill:#ffe0b2,color:#000
2825:     style E fill:#f3e5f5,color:#000
2826:     style F fill:#ff9999,color:#000
2827:     style G fill:#fff3e0,color:#000
2828:     style H fill:#fff9c4,color:#000
2829:     style I fill:#ffe0b2,color:#000
2830:     style J fill:#e1f5fe,color:#000
2831:     style K fill:#c8e6c9,color:#000
2832:     style L fill:#fff3e0,color:#000
2833:     style M fill:#b2ebf2,color:#000
2834:     style N fill:#ffccbc,color:#000
2835: ```
2836: 
2837: ### 10.3 Error Handling Strategy
2838: 
2839: **Level 1 Errors (Syntax):** Auto-fix immediately
2840: **Level 2 Errors (Logic):** Analyze, fix, re-test
2841: **Level 3 Errors (Integration):** Debug systematically
2842: **Persistent Errors:** Escalate after 3 attempts
2843: 
2844: ### See Also
2845: 
2846: - [Command Reference](../docs/research/07-commands-reference.md) - Comprehensive command workflows and operational procedures
2847: - [Claude Code 2.0 Features](../docs/research/11-claude-code-features.md) - Checkpoints, subagents, and hooks integration
2848: 
2849: ---
2850: 
2851: ## 11. Summary
2852: 
2853: ### 11.1 Core Value Proposition
2854: 
2855: Context Engineering Management delivers:
2856: 
2857: - **100x reliability improvement** over prompt engineering
2858: - **10-24x speed improvement** over manual development
2859: - **3-4x productivity increase** for teams
2860: - **Zero hallucinations** through complete context provision
2861: 
2862: ### 11.2 Key Differentiators
2863: 
2864: 1. **Context-as-Compiler:** Systematic context provision eliminates hallucinations
2865: 2. **PRP System:** Structured specifications enable autonomous implementation
2866: 3. **Self-Healing:** Automatic error correction achieves 92% success rate
2867: 4. **Strict Enforcement:** 3 LOC rule, validation gates, no fishy fallbacks
2868: 
2869: ### 11.3 Operational Requirements
2870: 
2871: **Prerequisites:**
2872: 
2873: - CLAUDE.md with project rules
2874: - PRPs/ structure with templates
2875: - MCP integration (Serena, Context7)
2876: - UV package management
2877: - Validation infrastructure
2878: 
2879: **Team Skills:**
2880: 
2881: - PRP writing (INITIAL.md creation)
2882: - Human validation (architecture review)
2883: - Context maintenance (CLAUDE.md updates)
2884: 
2885: ### 11.4 Success Metrics
2886: 
2887: | Metric | Target | Current |
2888: |--------|--------|---------|
2889: | First-pass success | 80% | 85% |
2890: | Confidence score | 10/10 (all 4 gates) | 9.4/10 avg (improving toward 10/10) |
2891: | Test coverage | 80% | 87% avg |
2892: | Speed improvement | 10x | 10-24x |
2893: | Productivity gain | 3x | 3-4x |
2894: 
2895: ### See Also
2896: 
2897: - [Context Engineering Framework: Complete Documentation Suite](../docs/research/00-index.md) - Comprehensive framework overview and documentation index
2898: - [Context Engineering Foundations](../docs/research/02-context-engineering-foundations.md) - Foundational concepts and philosophy
2899: - [Best Practices and Anti-Patterns](../docs/research/09-best-practices-antipatterns.md) - Implementation wisdom and lessons learned
2900: 
2901: ---
2902: 
2903: ---
2904: 
2905: ## References
2906: 
2907: ### Peer-Reviewed Claims
2908: 
2909: 1. **GitHub Copilot Evaluation (2024)**: "AI-Assisted Code Generation Benchmarks"
2910:    - Baseline Pass@1 rates: 35-45% for general code generation tasks
2911:    - Source: GitHub Research
2912:    - Used as: Baseline for Stage 1-2 success rates (Section 2.1)
2913: 
2914: 2. **IBM Research (2024)**: "Context-Aware Code Generation Performance Study"
2915:    - GPT-4.1 performance on HumanEval: 26.7% ‚Üí 43.3% (62% gain, 1.62x improvement)
2916:    - Demonstrates context engineering impact on standardized benchmarks
2917:    - Source: IBM Research Publications
2918:    - Used as: Evidence for context engineering effectiveness
2919: 
2920: 3. **LSP Token Efficiency Research (2023)**: "Semantic Code Navigation for Token Reduction"
2921:    - Typical reduction: 60-90% vs. full file reads through symbol-based queries
2922:    - Source: Language Server Protocol optimization studies
2923:    - Used as: Justification for Serena MCP COMPRESS pillar (Section 3.1.3)
2924: 
2925: ### Internal Observations
2926: 
2927: **Methodology:** Based on 4 documented PRP case studies (PRP-001 through PRP-004) executed between Jan-Oct 2025. These represent internal observations, not peer-reviewed research.
2928: 
2929: **Case Studies:**
2930: 
2931: - PRP-001: JWT Authentication (165 min)
2932: - PRP-002: Stripe Payments (135 min)
2933: - PRP-003: Inventory Management (120 min)
2934: - PRP-004: Order Status Webhooks (in progress)
2935: 
2936: **Metrics Derived from Case Studies:**
2937: 
2938: - 85% first-pass success rate (Section 8.2)
2939: - 92% self-healing success rate (Section 8.2)
2940: - 10-24x typical speedup range (Section 8.3)
2941: - 36x exceptional speedup for PRP Taskmaster (Section 8.1)
2942: 
2943: **Limitations:**
2944: 
2945: - Small sample size (n=4)
2946: - Single operator (experienced with framework)
2947: - Similar domain (web application features)
2948: - Not independently validated
2949: 
2950: **Claims Status:**
2951: 
2952: - ‚úÖ **Research-backed:** 35-45% baseline, 1.5-2x context improvement, 60-90% token reduction
2953: - ‚ö†Ô∏è **Internal observations:** 85% success rate, 10-24x speedup, 92% self-healing rate
2954: - üéØ **Aspirational targets:** 95% success rate, 100x improvement (exceptional cases)
2955: 
2956: ---
2957: 
2958: ## Document Metadata
2959: 
2960: **Version:** 1.0
2961: **Date:** 2025-10-12
2962: **Status:** Active (Model Specification)
2963: **Maintainer:** Context Engineering Team
2964: 
2965: **Related Documents:**
2966: 
2967: - `docs/research/01-prp-system.md` - PRP detailed specification
2968: - `docs/research/02-context-engineering-foundations.md` - Philosophical foundation
2969: - `docs/research/03-mcp-orchestration.md` - MCP integration patterns
2970: - `docs/research/08-validation-testing.md` - Validation framework details
2971: - `docs/research/09-best-practices-antipatterns.md` - Practical implementation guidance
2972: - `PRPs/templates/self-healing.md` - Complex feature template
2973: - `PRPs/templates/kiss.md` - Simple feature template
2974: - `CLAUDE.md` - Project implementation guide
2975: 
2976: **Revision Policy:**
2977: 
2978: - Review quarterly for accuracy
2979: - Update with real-world metrics
2980: - Incorporate lessons learned
2981: - Maintain version history
</file>

<file path="examples/TOOL-USAGE-GUIDE.md">
  1: # Tool Usage Guide - Claude Code Native-First Philosophy
  2: 
  3: **Last Updated**: 2025-10-29
  4: **Status**: Authoritative reference for tool selection
  5: **Replaces**: Obsolete MCP tool documentation
  6: 
  7: ---
  8: 
  9: ## Philosophy
 10: 
 11: ### Native-First Principle
 12: 
 13: Use Claude Code native tools (Read, Write, Edit, Glob, Grep, Bash) over MCP wrappers whenever possible.
 14: 
 15: **Why?**
 16: 
 17: - **Token Efficiency**: 96% reduction in MCP tools context (~46k ‚Üí ~2k tokens)
 18: - **Performance**: Direct tool access, no MCP routing overhead
 19: - **Reliability**: Fewer abstraction layers, clearer error messages
 20: - **Universality**: Native tools work across all codebases without configuration
 21: 
 22: ### When to Use MCP Tools
 23: 
 24: **Only use MCP tools for capabilities not available natively**:
 25: 
 26: - **Serena**: Code symbol navigation, memory management
 27: - **Linear**: Issue tracking integration
 28: - **Context7**: Library documentation fetching
 29: - **Sequential Thinking**: Complex reasoning workflows
 30: - **Syntropy**: System health checks, knowledge search
 31: 
 32: ---
 33: 
 34: ## Decision Tree
 35: 
 36: ```
 37: Need to [action]?
 38: ‚îÇ
 39: ‚îú‚îÄ File Operations?
 40: ‚îÇ  ‚îú‚îÄ Read file ‚Üí Read (native)
 41: ‚îÇ  ‚îú‚îÄ Write new file ‚Üí Write (native)
 42: ‚îÇ  ‚îú‚îÄ Edit existing ‚Üí Edit (native)
 43: ‚îÇ  ‚îî‚îÄ Find files ‚Üí Glob (native)
 44: ‚îÇ
 45: ‚îú‚îÄ Code Search?
 46: ‚îÇ  ‚îú‚îÄ Search content ‚Üí Grep (native)
 47: ‚îÇ  ‚îú‚îÄ Find symbol ‚Üí mcp__syntropy__serena_find_symbol
 48: ‚îÇ  ‚îî‚îÄ Symbol usage ‚Üí mcp__syntropy__serena_find_referencing_symbols
 49: ‚îÇ
 50: ‚îú‚îÄ Version Control?
 51: ‚îÇ  ‚îú‚îÄ Git operations ‚Üí Bash(git:*)
 52: ‚îÇ  ‚îî‚îÄ GitHub API ‚Üí Bash(gh:*)
 53: ‚îÇ
 54: ‚îú‚îÄ External Knowledge?
 55: ‚îÇ  ‚îú‚îÄ Web search ‚Üí WebSearch (native)
 56: ‚îÇ  ‚îú‚îÄ Library docs ‚Üí mcp__syntropy__context7_get_library_docs
 57: ‚îÇ  ‚îî‚îÄ Web content ‚Üí WebFetch (native)
 58: ‚îÇ
 59: ‚îú‚îÄ Project Management?
 60: ‚îÇ  ‚îî‚îÄ Linear issues ‚Üí mcp__syntropy__linear_*
 61: ‚îÇ
 62: ‚îî‚îÄ Complex Reasoning?
 63:    ‚îî‚îÄ Multi-step analysis ‚Üí mcp__syntropy__thinking_sequentialthinking
 64: ```
 65: 
 66: ---
 67: 
 68: ## Common Tasks
 69: 
 70: ### Task 1: Read and Modify Files
 71: 
 72: **‚ùå WRONG (MCP)**:
 73: 
 74: ```python
 75: mcp__syntropy__filesystem_read_file(path="foo.py")
 76: mcp__syntropy__filesystem_edit_file(path="foo.py", edits=[...])
 77: ```
 78: 
 79: **‚úÖ CORRECT (Native)**:
 80: 
 81: ```python
 82: Read(file_path="/absolute/path/foo.py")
 83: Edit(file_path="/absolute/path/foo.py", old_string="...", new_string="...")
 84: ```
 85: 
 86: **Why**: Native tools are direct, support more features (Edit preserves formatting), consume fewer tokens.
 87: 
 88: ---
 89: 
 90: ### Task 2: Search Codebase
 91: 
 92: **‚ùå WRONG (MCP)**:
 93: 
 94: ```python
 95: mcp__syntropy__filesystem_search_files(pattern="*.py")
 96: mcp__syntropy__repomix_pack_codebase(directory=".")
 97: ```
 98: 
 99: **‚úÖ CORRECT (Native + Serena)**:
100: 
101: ```python
102: # Find files by pattern
103: Glob(pattern="**/*.py")
104: 
105: # Search content
106: Grep(pattern="def calculate", type="py", output_mode="content")
107: 
108: # Find specific symbol (when you know the name)
109: mcp__syntropy__serena_find_symbol(name_path="MyClass.calculate")
110: ```
111: 
112: **Why**: Incremental exploration (Glob ‚Üí Grep ‚Üí Read) is more efficient than packing entire codebase. Serena is for symbol-level navigation.
113: 
114: ---
115: 
116: ### Task 3: Git Operations
117: 
118: **‚ùå WRONG (MCP)**:
119: 
120: ```python
121: mcp__syntropy__git_git_status(repo_path="/path")
122: mcp__syntropy__git_git_commit(repo_path="/path", message="Fix bug")
123: ```
124: 
125: **‚úÖ CORRECT (Native Bash)**:
126: 
127: ```bash
128: # Pre-approved: Bash(git:*)
129: git status
130: git diff --staged
131: git add file.py
132: git commit -m "Fix bug"
133: ```
134: 
135: **Why**: Native `git` supports all flags, universally familiar, no MCP routing delay.
136: 
137: ---
138: 
139: ### Task 4: GitHub Operations
140: 
141: **‚ùå WRONG (MCP)**:
142: 
143: ```python
144: mcp__syntropy__github_create_pull_request(owner="...", repo="...", ...)
145: mcp__syntropy__github_list_issues(owner="...", repo="...")
146: ```
147: 
148: **‚úÖ CORRECT (Native gh CLI)**:
149: 
150: ```bash
151: # Pre-approved: Bash(gh:*)
152: gh pr create --title "Fix bug" --body "Description"
153: gh issue list --label bug
154: gh pr view 123
155: ```
156: 
157: **Why**: Official GitHub CLI, more features, better docs, no permission complexity.
158: 
159: ---
160: 
161: ### Task 5: Find Symbol Usages
162: 
163: **‚úÖ CORRECT (Serena - unique capability)**:
164: 
165: ```python
166: # Find where MyClass.calculate is used
167: mcp__syntropy__serena_find_referencing_symbols(name_path="MyClass.calculate")
168: 
169: # Get overview of all symbols in file
170: mcp__syntropy__serena_get_symbols_overview(relative_path="src/utils.py")
171: ```
172: 
173: **Why**: Serena provides AST-level symbol analysis not available via native tools.
174: 
175: ---
176: 
177: ### Task 6: Library Documentation
178: 
179: **‚úÖ CORRECT (Context7 - unique capability)**:
180: 
181: ```python
182: # Resolve library ID
183: mcp__syntropy__context7_resolve_library_id(libraryName="numpy")
184: 
185: # Fetch docs
186: mcp__syntropy__context7_get_library_docs(
187:   context7CompatibleLibraryID="/numpy/doc",
188:   topic="array indexing"
189: )
190: ```
191: 
192: **Why**: Context7 provides curated, AI-optimized library docs not available via WebSearch.
193: 
194: ---
195: 
196: ### Task 7: Project Management
197: 
198: **‚úÖ CORRECT (Linear - unique capability)**:
199: 
200: ```python
201: # List issues
202: mcp__syntropy__linear_list_issues(team_id="TEAM-123")
203: 
204: # Create issue
205: mcp__syntropy__linear_create_issue(
206:   title="Bug: Login fails",
207:   team_id="TEAM-123",
208:   description="..."
209: )
210: ```
211: 
212: **Why**: Direct Linear API integration not available via native tools.
213: 
214: ---
215: 
216: ### Task 8: Complex Reasoning
217: 
218: **‚úÖ CORRECT (Sequential Thinking - unique capability)**:
219: 
220: ```python
221: mcp__syntropy__thinking_sequentialthinking(
222:   thought="Analyzing trade-offs between approach A and B...",
223:   thoughtNumber=1,
224:   totalThoughts=5,
225:   nextThoughtNeeded=True
226: )
227: ```
228: 
229: **Why**: Structured multi-step reasoning process not available natively.
230: 
231: ---
232: 
233: ### Task 9: System Health Check
234: 
235: **‚úÖ CORRECT (Syntropy - unique capability)**:
236: 
237: ```python
238: # Quick health check
239: mcp__syntropy__healthcheck()
240: 
241: # Detailed diagnostics
242: mcp__syntropy__healthcheck(detailed=True, timeout_ms=5000)
243: ```
244: 
245: **Why**: Aggregates health across all MCP servers, not available via native tools.
246: 
247: ---
248: 
249: ## Anti-Patterns
250: 
251: ### Anti-Pattern 1: Using MCP for Simple File Ops
252: 
253: **‚ùå WRONG**:
254: 
255: ```python
256: mcp__syntropy__filesystem_read_file(path="config.json")
257: mcp__syntropy__filesystem_write_file(path="config.json", content="...")
258: ```
259: 
260: **Problem**: Unnecessary MCP overhead, consumes more tokens, slower execution.
261: 
262: **‚úÖ FIX**:
263: 
264: ```python
265: Read(file_path="/absolute/path/config.json")
266: Write(file_path="/absolute/path/config.json", content="...")
267: ```
268: 
269: ---
270: 
271: ### Anti-Pattern 2: Packing Entire Codebase
272: 
273: **‚ùå WRONG**:
274: 
275: ```python
276: mcp__syntropy__repomix_pack_codebase(directory=".")
277: # Then search packed output
278: ```
279: 
280: **Problem**: Monolithic approach, inefficient for incremental work, high token cost.
281: 
282: **‚úÖ FIX**:
283: 
284: ```python
285: # Incremental exploration
286: Glob(pattern="**/auth*.py")  # Find relevant files
287: Grep(pattern="def authenticate", type="py")  # Search specific pattern
288: Read(file_path="/path/to/auth.py")  # Read only what you need
289: ```
290: 
291: ---
292: 
293: ### Anti-Pattern 3: MCP for Git Commands
294: 
295: **‚ùå WRONG**:
296: 
297: ```python
298: mcp__syntropy__git_git_status(repo_path="/path")
299: mcp__syntropy__git_git_diff(repo_path="/path")
300: ```
301: 
302: **Problem**: Limited flag support, unnecessary abstraction.
303: 
304: **‚úÖ FIX**:
305: 
306: ```bash
307: git status
308: git diff --staged
309: git log --oneline -10
310: ```
311: 
312: ---
313: 
314: ### Anti-Pattern 4: Using Playwright for Simple Web Content
315: 
316: **‚ùå WRONG**:
317: 
318: ```python
319: mcp__syntropy__playwright_navigate(url="https://example.com")
320: mcp__syntropy__playwright_get_visible_text()
321: ```
322: 
323: **Problem**: Overkill for static content, slow browser startup.
324: 
325: **‚úÖ FIX**:
326: 
327: ```python
328: # For static content
329: WebFetch(url="https://example.com", prompt="Extract main content")
330: 
331: # For search queries
332: WebSearch(query="Python asyncio best practices")
333: ```
334: 
335: ---
336: 
337: ### Anti-Pattern 5: GitHub MCP Instead of gh CLI
338: 
339: **‚ùå WRONG**:
340: 
341: ```python
342: mcp__syntropy__github_create_pull_request(
343:   owner="user",
344:   repo="project",
345:   title="Fix",
346:   head="fix-branch",
347:   base="main",
348:   body="Description"
349: )
350: ```
351: 
352: **Problem**: Verbose, requires explicit owner/repo, limited features.
353: 
354: **‚úÖ FIX**:
355: 
356: ```bash
357: # Infers owner/repo from current directory
358: gh pr create --title "Fix" --body "Description"
359: ```
360: 
361: ---
362: 
363: ## Tool Quick Reference
364: 
365: ### Native Tools (Always Prefer)
366: 
367: | Tool | Purpose | Example |
368: |------|---------|---------|
369: | **Read** | Read file contents | `Read(file_path="/abs/path/file.py")` |
370: | **Write** | Create new file | `Write(file_path="/abs/path/new.py", content="...")` |
371: | **Edit** | Modify existing file | `Edit(file_path="...", old_string="...", new_string="...")` |
372: | **Glob** | Find files by pattern | `Glob(pattern="**/*.py")` |
373: | **Grep** | Search file contents | `Grep(pattern="def foo", type="py", output_mode="content")` |
374: | **Bash** | Run shell commands | `Bash(command="git status")` |
375: | **WebSearch** | AI-powered search | `WebSearch(query="Python asyncio")` |
376: | **WebFetch** | Fetch web content | `WebFetch(url="...", prompt="Extract...")` |
377: 
378: ### MCP Tools (Use Only When Native Unavailable)
379: 
380: #### Serena (Code Navigation)
381: 
382: | Tool | Purpose | Example |
383: |------|---------|---------|
384: | `serena_find_symbol` | Find symbol definition | `name_path="MyClass.method"` |
385: | `serena_get_symbols_overview` | List all symbols in file | `relative_path="src/utils.py"` |
386: | `serena_find_referencing_symbols` | Find symbol usages | `name_path="MyClass.method"` |
387: | `serena_search_for_pattern` | Regex search | `pattern="def.*async"` |
388: | `serena_write_memory` | Store project context | `memory_type="architecture", content="..."` |
389: | `serena_read_memory` | Retrieve context | `memory_type="architecture"` |
390: 
391: #### Linear (Project Management)
392: 
393: | Tool | Purpose | Example |
394: |------|---------|---------|
395: | `linear_list_issues` | List issues | `team_id="TEAM-123"` |
396: | `linear_create_issue` | Create issue | `title="Bug", team_id="..."` |
397: | `linear_get_issue` | Get issue details | `issue_id="ISSUE-123"` |
398: | `linear_update_issue` | Update issue | `issue_id="...", updates={...}` |
399: 
400: #### Context7 (Library Docs)
401: 
402: | Tool | Purpose | Example |
403: |------|---------|---------|
404: | `context7_resolve_library_id` | Find library ID | `libraryName="numpy"` |
405: | `context7_get_library_docs` | Fetch docs | `context7CompatibleLibraryID="/numpy/doc"` |
406: 
407: #### Thinking (Reasoning)
408: 
409: | Tool | Purpose | Example |
410: |------|---------|---------|
411: | `thinking_sequentialthinking` | Structured reasoning | `thought="...", thoughtNumber=1` |
412: 
413: #### Syntropy (System)
414: 
415: | Tool | Purpose | Example |
416: |------|---------|---------|
417: | `healthcheck` | Check MCP servers | `detailed=True` |
418: | `enable_tools` | Enable/disable tools dynamically | `enable=["tool1"], disable=["tool2"]` |
419: | `list_all_tools` | List all tools with enabled/disabled status | `{}` (no args) |
420: 
421: ---
422: 
423: ## Migration Table: Denied Tools ‚Üí Alternatives
424: 
425: ### Filesystem (8 tools denied)
426: 
427: | Denied Tool | Alternative | Example |
428: |-------------|-------------|---------|
429: | `filesystem_read_file` | **Read** (native) | `Read(file_path="/abs/path/file.py")` |
430: | `filesystem_read_text_file` | **Read** (native) | Same as above |
431: | `filesystem_write_file` | **Write** (native) | `Write(file_path="...", content="...")` |
432: | `filesystem_edit_file` | **Edit** (native) | `Edit(file_path="...", old_string="...", new_string="...")` |
433: | `filesystem_list_directory` | **Bash** (ls) | `Bash(command="ls -la /path")` |
434: | `filesystem_search_files` | **Glob** (native) | `Glob(pattern="**/*.py")` |
435: | `filesystem_directory_tree` | **Bash** (tree) | `Bash(command="tree -L 2")` |
436: | `filesystem_get_file_info` | **Bash** (stat) | `Bash(command="stat file.py")` |
437: 
438: ### Git (5 tools denied)
439: 
440: | Denied Tool | Alternative | Example |
441: |-------------|-------------|---------|
442: | `git_git_status` | **Bash(git)** | `Bash(command="git status")` |
443: | `git_git_diff` | **Bash(git)** | `Bash(command="git diff --staged")` |
444: | `git_git_log` | **Bash(git)** | `Bash(command="git log --oneline -10")` |
445: | `git_git_add` | **Bash(git)** | `Bash(command="git add file.py")` |
446: | `git_git_commit` | **Bash(git)** | `Bash(command='git commit -m "msg"')` |
447: 
448: ### GitHub (26 tools denied)
449: 
450: | Denied Tool | Alternative | Example |
451: |-------------|-------------|---------|
452: | `github_create_or_update_file` | **Bash(gh)** | `gh api repos/owner/repo/contents/path -f content=...` |
453: | `github_search_repositories` | **Bash(gh)** | `gh search repos "keyword"` |
454: | `github_create_repository` | **Bash(gh)** | `gh repo create name --public` |
455: | `github_get_file_contents` | **Bash(gh)** | `gh api repos/owner/repo/contents/path` |
456: | `github_push_files` | **Bash(git)** | `git add . && git commit -m "msg" && git push` |
457: | `github_create_issue` | **Bash(gh)** | `gh issue create --title "Bug" --body "..."` |
458: | `github_create_pull_request` | **Bash(gh)** | `gh pr create --title "Fix" --body "..."` |
459: | `github_fork_repository` | **Bash(gh)** | `gh repo fork owner/repo` |
460: | `github_create_branch` | **Bash(git)** | `git checkout -b branch-name` |
461: | `github_list_commits` | **Bash(gh)** | `gh api repos/owner/repo/commits` |
462: | `github_list_issues` | **Bash(gh)** | `gh issue list --label bug` |
463: | `github_update_issue` | **Bash(gh)** | `gh issue edit 123 --title "New"` |
464: | `github_add_issue_comment` | **Bash(gh)** | `gh issue comment 123 --body "..."` |
465: | `github_search_code` | **Bash(gh)** | `gh search code "query"` |
466: | `github_search_issues` | **Bash(gh)** | `gh search issues "bug"` |
467: | `github_search_users` | **Bash(gh)** | `gh search users "name"` |
468: | `github_get_issue` | **Bash(gh)** | `gh issue view 123` |
469: | `github_get_pull_request` | **Bash(gh)** | `gh pr view 123` |
470: | `github_list_pull_requests` | **Bash(gh)** | `gh pr list --state open` |
471: | `github_create_pull_request_review` | **Bash(gh)** | `gh pr review 123 --approve` |
472: | `github_merge_pull_request` | **Bash(gh)** | `gh pr merge 123 --squash` |
473: | `github_get_pull_request_files` | **Bash(gh)** | `gh pr diff 123` |
474: | `github_get_pull_request_status` | **Bash(gh)** | `gh pr checks 123` |
475: | `github_update_pull_request_branch` | **Bash(git)** | `git checkout branch && git pull origin main` |
476: | `github_get_pull_request_comments` | **Bash(gh)** | `gh pr view 123 --comments` |
477: | `github_get_pull_request_reviews` | **Bash(gh)** | `gh api repos/owner/repo/pulls/123/reviews` |
478: 
479: ### Repomix (4 tools denied)
480: 
481: | Denied Tool | Alternative | Example |
482: |-------------|-------------|---------|
483: | `repomix_pack_codebase` | **Glob + Grep + Read** | Incremental exploration |
484: | `repomix_grep_repomix_output` | **Grep** (native) | `Grep(pattern="...", output_mode="content")` |
485: | `repomix_read_repomix_output` | **Read** (native) | `Read(file_path="...")` |
486: | `repomix_pack_remote_repository` | **Bash(git clone)** + native tools | `git clone <url> && Glob/Grep/Read` |
487: 
488: ### Playwright (6 tools denied)
489: 
490: | Denied Tool | Alternative | Example |
491: |-------------|-------------|---------|
492: | `playwright_navigate` | **WebFetch** (static) or **Bash(playwright CLI)** (dynamic) | `WebFetch(url="...", prompt="...")` |
493: | `playwright_screenshot` | **Bash(playwright CLI)** | `playwright screenshot <url> screenshot.png` |
494: | `playwright_click` | **Bash(playwright CLI)** | Rarely needed for CLI tooling |
495: | `playwright_fill` | **Bash(playwright CLI)** | Rarely needed for CLI tooling |
496: | `playwright_evaluate` | **Bash(playwright CLI)** | Rarely needed for CLI tooling |
497: | `playwright_get_visible_text` | **WebFetch** | `WebFetch(url="...", prompt="Extract text")` |
498: 
499: ### Perplexity (1 tool denied)
500: 
501: | Denied Tool | Alternative | Example |
502: |-------------|-------------|---------|
503: | `perplexity_perplexity_ask` | **WebSearch** (native) | `WebSearch(query="Python asyncio patterns")` |
504: 
505: ### Syntropy System (5 tools denied)
506: 
507: | Denied Tool | Alternative | Example |
508: |-------------|-------------|---------|
509: | `init_project` | **Manual setup** | One-time operation, rarely needed |
510: | `get_system_doc` | **Read** (native) | `Read(file_path=".ce/RULES.md")` |
511: | `get_user_doc` | **Read** (native) | `Read(file_path="PRPs/executed/PRP-1.md")` |
512: | `get_summary` | **Read** + manual analysis | Read REPLKAN, analyze structure |
513: | `denoise` | **Edit** (native) | Manually edit verbose docs |
514: 
515: ---
516: 
517: ## Best Practices
518: 
519: ### 1. Start with Native Tools
520: 
521: Always check if Read/Write/Edit/Glob/Grep/Bash can solve the task before reaching for MCP tools.
522: 
523: ### 2. Use Serena for Symbol Navigation
524: 
525: When you need to find a specific function/class definition or its usages across the codebase.
526: 
527: ### 3. Incremental > Monolithic
528: 
529: Prefer Glob ‚Üí Grep ‚Üí Read over packing entire codebase with Repomix.
530: 
531: ### 4. Bash for System Commands
532: 
533: Git, gh, tree, ls, find, etc. are pre-approved and more flexible than MCP wrappers.
534: 
535: ### 5. MCP for Integration
536: 
537: Use MCP tools when you need external service integration (Linear, Context7) not available via native tools.
538: 
539: ### 6. Validate with Healthcheck
540: 
541: Periodically run `mcp__syntropy__healthcheck(detailed=True)` to ensure all servers are connected.
542: 
543: ---
544: 
545: ## Troubleshooting
546: 
547: ### Issue: "Tool not found" error
548: 
549: **Cause**: Tool is in deny list or MCP server disconnected.
550: 
551: **Fix**:
552: 
553: 1. Check `.claude/settings.local.json` permissions.deny
554: 2. Run `mcp__syntropy__healthcheck(detailed=True)`
555: 3. Reconnect MCP: `/mcp` (in main repo, not worktrees)
556: 
557: ### Issue: "Permission denied" for Bash command
558: 
559: **Cause**: Command not in allow list.
560: 
561: **Fix**:
562: 
563: 1. Check if command matches allow pattern: `Bash(git:*)`, `Bash(uv run:*)`, etc.
564: 2. If needed frequently, add to allow list in settings
565: 3. Temporary: User can approve via prompt
566: 
567: ### Issue: MCP tool slow or timing out
568: 
569: **Cause**: Server connectivity issue or large operation.
570: 
571: **Fix**:
572: 
573: 1. Check server health: `mcp__syntropy__healthcheck()`
574: 2. Increase timeout if supported
575: 3. Consider native alternative (e.g., Grep instead of repomix)
576: 
577: ### Issue: Serena "symbol not found"
578: 
579: **Cause**: Incorrect name_path format or file not indexed.
580: 
581: **Fix**:
582: 
583: 1. Use `serena_get_symbols_overview` to list all symbols in file
584: 2. Ensure format: `ClassName.method_name` or `function_name`
585: 3. Check relative_path is correct from project root
586: 
587: ---
588: 
589: ## See Also
590: 
591: **Code Examples**:
592: 
593: - `tools/ce/examples/syntropy/` - MCP tool usage patterns in Python
594: - `.serena/memories/` - Serena memory management examples and patterns
595: 
596: **Related Documentation**:
597: 
598: - `CLAUDE.md` - Project guide and quick commands
599: - `TOOL-PERMISSION-LOCKDOWN-PLAN.md` - Detailed rationale for tool deny list
600: - `PRPs/executed/PRP-B-tool-usage-guide.md` - PRP that created this guide
601: 
602: ---
603: 
604: **End of Guide**
605: 
606: For questions or suggestions, update this guide via PR following Context Engineering framework.
</file>

<file path="examples/INDEX.md">
  1: # Context Engineering Examples Index
  2: 
  3: Comprehensive catalog of all Context Engineering framework examples, organized by type and category for easy discovery.
  4: 
  5: ## Quick Reference
  6: 
  7: **I want to...**
  8: 
  9: - Initialize CE framework ‚Üí [Framework Initialization](#framework-initialization)
 10: - Learn Syntropy MCP tools ‚Üí [Tool Usage Guide](TOOL-USAGE-GUIDE.md)
 11: - Initialize Serena memories ‚Üí [Serena Memory Templates](#serena-memory-templates) (23 framework memories with YAML headers)
 12: - Run batch PRPs ‚Üí Slash commands: `/batch-gen-prp`, `/batch-exe-prp` (see `.claude/commands/`)
 13: - Clean up my project ‚Üí Slash command: `/vacuum` (see `.claude/commands/vacuum.md`)
 14: - Fix context drift ‚Üí `cd tools && uv run ce context health`
 15: - Configure commands/hooks ‚Üí [Slash Commands](#slash-commands)
 16: - Understand patterns ‚Üí [Patterns](#patterns)
 17: - Migrate existing project ‚Üí [Migration Workflows](#migration-workflows)
 18: 
 19: ## All Examples
 20: 
 21: | Name | Type | Category | IsWorkflow | Description | Path |
 22: |------|------|----------|-----------|-------------|------|
 23: | **FRAMEWORK INITIALIZATION** | | | | | |
 24: | Initialization Guide | Guide | Initialization | Yes | Master CE 1.1 framework initialization (5 phases: buckets, user files, repomix, blending, cleanup). Covers 4 scenarios: Greenfield, Mature Project, CE 1.0 Upgrade, Partial Install | [INITIALIZATION.md](INITIALIZATION.md) |
 25: | **TEMPLATES** | | | | | |
 26: | PRP-0 Template | Template | Initialization | Yes | Document framework installation in meta-PRP (PRP-0-CONTEXT-ENGINEERING.md template) | [templates/PRP-0-CONTEXT-ENGINEERING.md](templates/PRP-0-CONTEXT-ENGINEERING.md) |
 27: | **SLASH COMMANDS** | | | | | |
 28: | Batch PRP Execution | Command | Batch | Yes | Execute PRPs in parallel stages with health monitoring (see `.claude/commands/batch-exe-prp.md`) | Command: `/batch-exe-prp` |
 29: | Batch PRP Generation | Command | Batch | Yes | Generate multiple PRPs from plan with dependency analysis (see `.claude/commands/batch-gen-prp.md`) | Command: `/batch-gen-prp` |
 30: | Context Drift Check | Command | Context | Yes | Fast drift score check without full validation (see `.claude/commands/analyze-context.md`) | Command: `/analyze-context` |
 31: | Denoise Documents | Command | Cleanup | Yes | Compress verbose documentation with AI-powered denoising (see `.claude/commands/denoise.md`) | Command: `/denoise` |
 32: | Vacuum Cleanup | Command | Cleanup | Yes | Identify and remove project noise with confidence-based deletion (see `.claude/commands/vacuum.md`) | Command: `/vacuum` |
 33: | **PATTERNS** | | | | | |
 34: | Dedrifting Lessons | Pattern | Context | Yes | Root cause analysis for context drift with prevention strategies | [patterns/dedrifting-lessons.md](patterns/dedrifting-lessons.md) |
 35: | Example Simple Feature | Pattern | PRP | No | Complete PRP example for adding git status summary command (ctx-eng-plus specific) | [patterns/example-simple-feature.md](patterns/example-simple-feature.md) |
 36: | Git Message Rules | Pattern | Git | No | Git commit message formatting and convention rules (ctx-eng-plus specific) | [patterns/git-message-rules.md](patterns/git-message-rules.md) |
 37: | Mock Marking Pattern | Pattern | Testing | Yes | Mark mocks with FIXME comments for tracking temporary test code | [patterns/mocks-marking.md](patterns/mocks-marking.md) |
 38: | **GUIDES** | | | | | |
 39: | Tool Usage Guide | Guide | Tools | Yes | Complete tool selection guide with native-first philosophy, decision trees and examples | [TOOL-USAGE-GUIDE.md](TOOL-USAGE-GUIDE.md) |
 40: | PRP Decomposition Patterns | Guide | PRP | Yes | Patterns for breaking down large features into manageable PRPs | [prp-decomposition-patterns.md](prp-decomposition-patterns.md) |
 41: | **REFERENCE** | | | | | |
 42: | L4 Validation Example | Reference | Validation | No | Level 4 pattern conformance validation example (ctx-eng-plus specific) | [l4-validation-example.md](l4-validation-example.md) |
 43: | Linear Integration Example | Reference | MCP | Yes | Linear MCP integration example with configuration defaults | [linear-integration-example.md](linear-integration-example.md) |
 44: | Mermaid Color Palette | Reference | Diagrams | Yes | Standard color palette for mermaid diagrams with light/dark themes | [mermaid-color-palette.md](mermaid-color-palette.md) |
 45: | Syntropy Status Hook | Reference | MCP | No | Syntropy MCP health check system (references ctx-eng-plus scripts) | [syntropy-status-hook-system.md](syntropy-status-hook-system.md) |
 46: | Settings Local Example | Reference | Configuration | Yes | Example .claude/settings.local.json with permissions (framework template) | [example.setting.local.md](example.setting.local.md) |
 47: | tmp/ Directory Convention | Reference | Standards | Yes | Conventions for temporary file storage and cleanup | [tmp-directory-convention.md](tmp-directory-convention.md) |
 48: | **MODEL** | | | | | |
 49: | System Model | Model | Architecture | Yes | Complete Context Engineering framework architecture and design | [model/SystemModel.md](model/SystemModel.md) |
 50: 
 51: ## Statistics
 52: 
 53: ### Examples & Documentation
 54: 
 55: - **Total Examples**: 23 files
 56: - **Framework Initialization**: 6 (Main guide + 4 migration workflows + integration summary)
 57: - **Templates**: 1 (PRP-0-CONTEXT-ENGINEERING.md)
 58: - **Slash Commands**: 5 (Reference - actual commands in `.claude/commands/`)
 59: - **Patterns**: 4 (Git, testing, context, PRP)
 60: - **Guides**: 2 (Tools, PRP decomposition)
 61: - **Reference**: 6 (Validation, diagrams, standards, Syntropy overview)
 62: - **Model**: 1 (System architecture)
 63: 
 64: **Note**: Workflows previously referenced in INDEX.md now exist as slash commands (`.claude/commands/`) or CLI tools (`ce` command). Migration guides and initialization documentation are new additions for CE 1.1.
 65: 
 66: ### Serena Memories
 67: 
 68: - **Total Memories**: 23 files (~3,621 lines) with YAML type headers (CE 1.1)
 69: - **Type System**: All framework memories default to `type: regular` (users upgrade to `type: critical` during target project initialization)
 70: - **Categories**: documentation (13), pattern (5), architecture (2), configuration (4), troubleshooting (1)
 71: - **Critical Memory Candidates**: 6 memories (code-style-conventions, suggested-commands, task-completion-checklist, testing-standards, tool-usage-syntropy, use-syntropy-tools-not-bash)
 72: - **Memory Type README**: See `.serena/memories/README.md` for complete type system documentation
 73: - **Storage**: `.serena/memories/` (created automatically by Serena MCP)
 74: 
 75: ## Categories
 76: 
 77: ### Framework Initialization
 78: 
 79: Complete CE 1.1 framework initialization and migration workflows:
 80: 
 81: | Example | Type | Duration | Description |
 82: |---------|------|----------|-------------|
 83: | [Initialization Guide](INITIALIZATION.md) | Guide | Variable | Master CE 1.1 framework initialization guide (5 phases: buckets, user files, repomix, blending, cleanup). Covers 4 scenarios: Greenfield (10 min), Mature Project (45 min), CE 1.0 Upgrade (40 min), Partial Install (15 min) |
 84: | [PRP-0 Template](templates/PRP-0-CONTEXT-ENGINEERING.md) | Template | - | Document framework installation in meta-PRP |
 85: 
 86: **Total**: 2 files (1 master guide + 1 template)
 87: 
 88: **Key Features**:
 89: - 5-phase initialization (bucket collection, user files, repomix, blending, cleanup)
 90: - /system/ organization for framework files (separation from user files)
 91: - YAML header system for memories and PRPs (type: regular/critical/user)
 92: - Zero noise guarantee (legacy files cleaned up after migration)
 93: - PRP-0 convention (document installation in meta-PRP)
 94: 
 95: ### Serena Memory Templates
 96: 
 97: #### Recommended Memory Types for New Projects
 98: 
 99: Recommended initial knowledge base for Serena memory initialization in new projects:
100: 
101: | Memory Type | Purpose | IsWorkflow | When to Use | Example Topics |
102: |-------------|---------|-----------|-------------|-----------------|
103: | `architecture` | Document architectural decisions and design rationale | Yes | Record why certain patterns/structures were chosen | Validation approach, error handling strategy, module organization |
104: | `pattern` | Build reusable solution library | Yes | Store recurring solution patterns discovered during development | Retry strategies, error recovery, async patterns, testing approaches |
105: | `troubleshooting` | Capture issue resolution steps for recurring problems | Yes | Document root causes and fixes for common issues | MCP connection errors, git conflicts, validation failures |
106: | `configuration` | Setup notes and configuration guidelines | Yes | Record framework setup decisions and best practices | Serena project activation, hook configuration, path conventions |
107: | `documentation` | Cache frequently-accessed library documentation | Yes | Store Context7-fetched docs for quick offline access | Next.js routing, React patterns, Python asyncio guides |
108: | `note` | Record session insights, handoffs, and observations | Conditional | Preserve context between sessions; project-specific when filled | Session end state, discovered gotchas, optimization insights |
109: 
110: **Initialization Strategy**: When activating Serena for a new CE project, create template memories for architecture, pattern, troubleshooting, and configuration types with framework-level guidance. Let projects accumulate documentation and note types organically during development.
111: 
112: #### Existing Project Memories
113: 
114: Current knowledge base in `.serena/memories/` (23 files, ~3,719 lines):
115: 
116: **Universal Memories (IsWorkflow = Yes)** - Suitable for copying to new projects:
117: 
118: | Memory | Type | Purpose | Lines |
119: |--------|------|---------|-------|
120: | [code-style-conventions.md](.serena/memories/code-style-conventions.md) | pattern | Coding principles: KISS, no fishy fallbacks, mock marking, function/file size limits | 129 |
121: | [suggested-commands.md](.serena/memories/suggested-commands.md) | documentation | Common commands reference (UV, pytest, CE tools, Darwin) | 98 |
122: | [task-completion-checklist.md](.serena/memories/task-completion-checklist.md) | documentation | Pre-commit verification checklist with all quality gates | 80 |
123: | [testing-standards.md](.serena/memories/testing-standards.md) | pattern | Testing philosophy: real functionality, no mocks, TDD approach | 87 |
124: | [tool-usage-syntropy.md](.serena/memories/tool-usage-syntropy.md) | documentation | Comprehensive Syntropy tool selection guide with decision trees | 425 |
125: | [use-syntropy-tools-not-bash.md](.serena/memories/use-syntropy-tools-not-bash.md) | pattern | Core principle & migration patterns: prefer Syntropy over bash | 200 |
126: 
127: **Project-Specific Memories (IsWorkflow = No)** - Ctx-eng-plus custom knowledge:
128: 
129: | Memory | Type | Purpose | Lines |
130: |--------|------|---------|-------|
131: | [codebase-structure.md](.serena/memories/codebase-structure.md) | architecture | Complete directory layout and module organization | 196 |
132: | [cwe78-prp22-newline-escape-issue.md](.serena/memories/cwe78-prp22-newline-escape-issue.md) | troubleshooting | Security issue with Serena regex replacement and workaround | 100 |
133: | [l4-validation-usage.md](.serena/memories/l4-validation-usage.md) | pattern | L4 validation system usage, modules, and drift thresholds | 150 |
134: | [linear-issue-creation-pattern.md](.serena/memories/linear-issue-creation-pattern.md) | pattern | Working example for Linear issue creation with PRP metadata | 69 |
135: | [linear-issue-tracking-integration.md](.serena/memories/linear-issue-tracking-integration.md) | pattern | Bi-directional Linear/PRP integration workflow | 213 |
136: | [linear-mcp-integration-example.md](.serena/memories/linear-mcp-integration-example.md) | pattern | Linear MCP integration with configuration defaults | 101 |
137: | [linear-mcp-integration.md](.serena/memories/linear-mcp-integration.md) | documentation | Complete Linear MCP tool reference (20+ tools) | 114 |
138: | [project-overview.md](.serena/memories/project-overview.md) | documentation | Master project documentation with tech stack & features | 188 |
139: | [PRP-15-remediation-workflow-implementation.md](.serena/memories/PRP-15-remediation-workflow-implementation.md) | documentation | Implementation record for PRP-15 remediation workflow | 206 |
140: | [prp-2-implementation-patterns.md](.serena/memories/prp-2-implementation-patterns.md) | pattern | State management patterns and atomic write practices | 330 |
141: | [prp-backlog-system.md](.serena/memories/prp-backlog-system.md) | configuration | PRP backlog directory system and workflow | 106 |
142: | [prp-structure-initialized.md](.serena/memories/prp-structure-initialized.md) | documentation | PRP structure initialization completion record | 80 |
143: | [serena-implementation-verification-pattern.md](.serena/memories/serena-implementation-verification-pattern.md) | pattern | Pattern for verifying PRP implementations with Serena symbol lookup | 139 |
144: | [serena-mcp-tool-restrictions.md](.serena/memories/serena-mcp-tool-restrictions.md) | configuration | Current tool restrictions, allowed tools, and workarounds | 236 |
145: | [syntropy-status-hook-pattern.md](.serena/memories/syntropy-status-hook-pattern.md) | pattern | Cache-based architecture for SessionStart hook MCP access | 177 |
146: | [system-model-specification.md](.serena/memories/system-model-specification.md) | documentation | Formal specification of Context Engineering target architecture | 157 |
147: | [tool-config-optimization-completed.md](.serena/memories/tool-config-optimization-completed.md) | documentation | Completion record for tool config optimization (7 violations resolved) | 63 |
148: 
149: **Summary**: 23 framework memories with YAML type headers (CE 1.1)
150: - 6 critical memory candidates (type: regular by default, upgrade to type: critical during initialization)
151: - 17 project-specific memories (ctx-eng-plus custom knowledge)
152: - See `.serena/memories/README.md` for complete memory type system documentation
153: 
154: **Storage**: `.serena/memories/` (created automatically by Serena MCP)
155: 
156: **Related Documentation**:
157: - [Tool Usage Guide](TOOL-USAGE-GUIDE.md) - Native-first tool selection philosophy
158: - [Initialization Guide](INITIALIZATION.md) - Framework initialization and memory setup
159: 
160: ### Slash Commands & CLI Tools
161: 
162: Workflow automation via slash commands and CLI tools:
163: 
164: | Command | Type | Description |
165: |---------|------|-------------|
166: | `/batch-gen-prp` | Slash Command | Generate multiple PRPs from plan with dependency analysis (see `.claude/commands/batch-gen-prp.md`) |
167: | `/batch-exe-prp` | Slash Command | Execute PRPs in parallel stages with health monitoring (see `.claude/commands/batch-exe-prp.md`) |
168: | `/vacuum` | Slash Command | Identify and remove project noise with confidence-based deletion (see `.claude/commands/vacuum.md`) |
169: | `/denoise` | Slash Command | Compress verbose documentation with AI-powered denoising (see `.claude/commands/denoise.md`) |
170: | `/analyze-context` | Slash Command | Fast drift score check without full validation (see `.claude/commands/analyze-context.md`) |
171: | `ce context health` | CLI Tool | Context health check with drift analysis (see `tools/ce/context.py`) |
172: | `ce validate --level 4` | CLI Tool | Full validation suite with L1-L4 checks (see `tools/ce/validate.py`) |
173: | `ce vacuum` | CLI Tool | Vacuum cleanup with execute/auto modes (see `tools/ce/` CLI) |
174: 
175: **Total**: 5 slash commands + 3 CLI tools
176: 
177: **Documentation**: All slash commands documented in `.claude/commands/`, CLI tools documented in `tools/README.md`
178: 
179: ### Configuration
180: 
181: Commands and hooks:
182: 
183: | Example | Lines | Focus |
184: |---------|-------|-------|
185: | [Hook Configuration](config/hook-configuration.md) | 649 | Lifecycle hooks (pre-commit, session-start) |
186: | [Slash Command Template](config/slash-command-template.md) | 622 | Custom command creation |
187: 
188: **Total**: 2 examples, 1,271 lines
189: 
190: ### Patterns
191: 
192: Reusable patterns and practices:
193: 
194: | Example | Lines | Focus |
195: |---------|-------|-------|
196: | [Dedrifting Lessons](patterns/dedrifting-lessons.md) | 241 | Context drift prevention |
197: | [Git Message Rules](patterns/git-message-rules.md) | 205 | Commit message conventions |
198: | [Example Simple Feature](patterns/example-simple-feature.md) | 182 | Complete PRP example |
199: | [Mock Marking](patterns/mocks-marking.md) | 96 | Test mock tracking |
200: 
201: **Total**: 4 examples, 724 lines
202: 
203: ### Guides
204: 
205: Comprehensive guides:
206: 
207: | Example | Lines | Focus |
208: |---------|-------|-------|
209: | [Tool Usage Guide](TOOL-USAGE-GUIDE.md) | 606 | Native-first tool selection philosophy |
210: | [PRP Decomposition Patterns](prp-decomposition-patterns.md) | 357 | Breaking down large features |
211: 
212: **Total**: 2 examples, 963 lines
213: 
214: ### Reference
215: 
216: Quick reference materials:
217: 
218: | Example | Lines | Focus |
219: |---------|-------|-------|
220: | [Mermaid Color Palette](mermaid-color-palette.md) | 313 | Diagram color standards |
221: | [L4 Validation Example](l4-validation-example.md) | 290 | Pattern conformance validation |
222: | [Linear Integration Example](linear-integration-example.md) | 204 | Legacy Linear example |
223: | [Syntropy Status Hook](syntropy-status-hook-system.md) | 149 | MCP health check |
224: | [tmp/ Convention](tmp-directory-convention.md) | 130 | Temp file standards |
225: | [Settings Local Example](example.setting.local.md) | 17 | Configuration example |
226: 
227: **Total**: 6 examples, 1,103 lines
228: 
229: ### Model
230: 
231: System architecture:
232: 
233: | Example | Lines | Focus |
234: |---------|-------|-------|
235: | [System Model](model/SystemModel.md) | 2,981 | Complete framework architecture |
236: 
237: **Total**: 1 example, 2,981 lines
238: 
239: ## IsWorkflow Distribution
240: 
241: ### Examples
242: 
243: - **Yes** (Universal/Framework): 21 examples (84%)
244: - **No** (Project-Specific): 4 examples (16%)
245: 
246: ### Serena Memories
247: 
248: - **Yes** (Universal/Framework): 6 memories (1,013 lines, 28%) - Suitable for all CE projects
249: - **No** (Project-Specific): 17 memories (2,608 lines, 72%) - Ctx-eng-plus custom knowledge
250: 
251: ### Classification Legend
252: 
253: **IsWorkflow = Yes**: Universal CE framework documentation that should be copied to any target project during initialization. Includes MCP patterns, generic workflows, framework config templates, reusable practices, and essential coding/testing standards.
254: 
255: **IsWorkflow = No**: Project-specific documentation tied to ctx-eng-plus codebase, conventions, or implementation details. Not suitable for general distribution to other projects.
256: 
257: ### Project-Specific Examples (No)
258: 
259: 1. **Example Simple Feature** (patterns/) - Demonstrates adding git status summary command specific to ctx-eng-plus
260: 2. **Git Message Rules** (patterns/) - Commit message conventions specific to this project
261: 3. **L4 Validation Example** (reference/) - Validation patterns specific to ctx-eng-plus infrastructure
262: 4. **Syntropy Status Hook** (reference/) - References ctx-eng-plus-specific scripts (scripts/session-startup.sh)
263: 
264: ### Universal Serena Memories to Copy to New Projects
265: 
266: 1. **code-style-conventions** (pattern) - Coding principles and standards
267: 2. **suggested-commands** (documentation) - Common command reference
268: 3. **task-completion-checklist** (documentation) - Quality gates verification
269: 4. **testing-standards** (pattern) - Testing philosophy and practices
270: 5. **tool-usage-syntropy** (documentation) - Syntropy tool selection guide
271: 6. **use-syntropy-tools-not-bash** (pattern) - Migration patterns and principles
272: 
273: ## Syntropy Integration
274: 
275: **Examples using Syntropy MCP**: 9/25 (36%)
276: 
277: - **Heavy usage** (20+ references): Serena Symbol Search (58), Linear Integration (30), Context7 Docs (29), Tool Usage Guide (34), Memory Management (34), Syntropy README (navigation hub)
278: - **Moderate usage** (5-20 references): Thinking Sequential (17), System Model (2)
279: - **Light usage** (1-5 references): Syntropy Status Hook (1), Slash Command Template (1)
280: 
281: ## Usage Patterns
282: 
283: ### By Use Case
284: 
285: **Starting with Context Engineering**:
286: 
287: 1. [System Model](model/SystemModel.md) - Understand framework architecture
288: 2. [Tool Usage Guide](TOOL-USAGE-GUIDE.md) - Learn tool selection
289: 3. [Example Simple Feature](patterns/example-simple-feature.md) - See complete PRP
290: 4. [Execute PRP workflow](workflows/batch-prp-execution.md) - Implement PRPs
291: 
292: **Learning Syntropy MCP**:
293: 
294: 1. [Syntropy README](syntropy/README.md) - Master overview, decision matrix, tool naming
295: 2. [Serena Symbol Search](syntropy/serena-symbol-search.md) - Code navigation and refactoring
296: 3. [Context7 Docs Fetch](syntropy/context7-docs-fetch.md) - Library documentation fetching
297: 4. [Linear Integration](syntropy/linear-integration.md) - Issue tracking and project management
298: 
299: **Maintaining Project Health**:
300: 
301: 1. [Context Drift Remediation](workflows/context-drift-remediation.md) - Sync PRPs
302: 2. [Vacuum Cleanup](workflows/vacuum-cleanup.md) - Remove noise
303: 3. [Denoise Documents](workflows/denoise-documents.md) - Compress docs
304: 4. [Dedrifting Lessons](patterns/dedrifting-lessons.md) - Prevention strategies
305: 
306: **Batch Operations**:
307: 
308: 1. [Batch PRP Generation](workflows/batch-prp-generation.md) - Generate from plan
309: 2. [Batch PRP Execution](workflows/batch-prp-execution.md) - Execute in parallel
310: 3. [PRP Decomposition Patterns](prp-decomposition-patterns.md) - Break down features
311: 
312: **Configuration**:
313: 
314: 1. [Slash Command Template](config/slash-command-template.md) - Create commands
315: 2. [Hook Configuration](config/hook-configuration.md) - Lifecycle hooks
316: 3. [Settings Local Example](example.setting.local.md) - Configuration format
317: 
318: ## Maintenance
319: 
320: **Updating this index**:
321: 
322: When adding new examples:
323: 
324: 1. Create example file following content template (150-300 lines)
325: 2. Add entry to appropriate category section above
326: 3. Update statistics
327: 4. Commit: `git add examples/ && git commit -m "Examples: Added [name]"`
328: 
329: **Content template**:
330: 
331: - **Purpose**: What this example demonstrates, when to use
332: - **Prerequisites**: Required setup
333: - **Examples**: 3-4 concrete examples with input/output
334: - **Common Patterns**: 3-5 patterns
335: - **Anti-Patterns**: 2-3 things not to do
336: - **Related**: Links to related examples
337: 
338: ## Related Documentation
339: 
340: - [CLAUDE.md](../CLAUDE.md) - Project guide and quick commands
341: - [PRPs/](../PRPs/) - Executed and feature request PRPs
342: - [.claude/commands/](../.claude/commands/) - Slash commands (11 framework commands including peer-review)
343: 
344: ## Contributing
345: 
346: To add new examples:
347: 
348: 1. Follow [content template](syntropy/README.md#content-template) structure
349: 2. Add to appropriate directory (syntropy/, workflows/, config/, patterns/)
350: 3. Update INDEX.md with new entry
351: 4. Cross-link with related examples
352: 5. Run validation: `cd tools && uv run ce validate --level 4`
</file>

<file path="examples/INITIALIZATION.md">
   1: # CE 1.1 Framework Initialization Guide
   2: 
   3: **Purpose**: Complete guide for installing and configuring the Context Engineering (CE) 1.1 framework across all project scenarios
   4: 
   5: **Version**: 1.1
   6: 
   7: **Last Updated**: 2025-11-04
   8: 
   9: **NOTE (2025-11-04)**: Historical references to `.ce/examples/system/` directory in this guide refer to a planned structure that was consolidated. All framework examples now reside in `examples/` directory. See PRP-32.2.1 for details on the consolidation.
  10: 
  11: ---
  12: 
  13: ## Overview
  14: 
  15: This guide covers the complete process of installing the Context Engineering framework into target projects using a unified 5-phase workflow. The process adapts to your specific scenario while maintaining consistent structure and validation.
  16: 
  17: ### What is CE 1.1?
  18: 
  19: Context Engineering is a framework for managing project context, documentation, and workflows through:
  20: 
  21: - **Structured knowledge base** (Serena memories)
  22: - **Automated workflows** (slash commands)
  23: - **PRP-based development** (Plan-Review-Produce pattern)
  24: - **Tool integration** (Syntropy MCP, Linear, UV)
  25: - **System/user separation** (framework vs project docs)
  26: 
  27: ### Key Benefits
  28: 
  29: - **Zero noise**: Clean separation of framework and project files
  30: - **Consistent validation**: Multi-level validation gates
  31: - **Automated workflows**: 11 framework commands for common tasks
  32: - **Knowledge persistence**: 23 framework memories + your project memories
  33: - **Easy upgrades**: System docs updated independently
  34: 
  35: ---
  36: 
  37: ## Quick Start: Choose Your Scenario
  38: 
  39: Use this decision tree to identify your installation scenario:
  40: 
  41: ```
  42: START: What's your project's current state?
  43: ‚îÇ
  44: ‚îú‚îÄ NO CE components exist
  45: ‚îÇ  ‚îÇ
  46: ‚îÇ  ‚îú‚îÄ New project (empty or minimal code)
  47: ‚îÇ  ‚îÇ  ‚îî‚îÄ‚Üí SCENARIO 1: Greenfield (~10 min)
  48: ‚îÇ  ‚îÇ
  49: ‚îÇ  ‚îî‚îÄ Existing codebase with working code
  50: ‚îÇ     ‚îî‚îÄ‚Üí SCENARIO 2: Mature Project (~45 min)
  51: ‚îÇ
  52: ‚îî‚îÄ Has CE components
  53:    ‚îÇ
  54:    ‚îú‚îÄ Has .ce/ directory (CE 1.1)
  55:    ‚îÇ  ‚îî‚îÄ‚Üí SCENARIO 4: Partial Install (~15 min)
  56:    ‚îÇ
  57:    ‚îî‚îÄ No .ce/ directory (CE 1.0 or legacy)
  58:       ‚îî‚îÄ‚Üí SCENARIO 3: CE 1.0 Upgrade (~40 min)
  59: ```
  60: 
  61: ### Scenario Descriptions
  62: 
  63: | Scenario | When to Use | Phases | Time |
  64: |----------|-------------|--------|------|
  65: | **Greenfield** | New project, no CE components | 1, 3, 4 (skip 2, 5) | 10 min |
  66: | **Mature Project** | Existing code, no CE | 1, 2, 3, 4 (skip 5) | 45 min |
  67: | **CE 1.0 Upgrade** | Legacy CE installation | 1, 2, 3, 4, 5 (all) | 40 min |
  68: | **Partial Install** | Missing CE components | 1, 3, 4 (selective) | 15 min |
  69: 
  70: ---
  71: 
  72: ## Prerequisites
  73: 
  74: ### Required for All Scenarios
  75: 
  76: - **Repomix CLI**: `npm install -g repomix`
  77: - **CE framework packages**:
  78:   - `ce-infrastructure.xml` (complete framework)
  79:   - `ce-workflow-docs.xml` (reference documentation)
  80: - **Git repository**: Project initialized with git
  81: - **Project directory**: Write access to target directory
  82: 
  83: ### Optional (Recommended)
  84: 
  85: - **Backup branch**: `git checkout -b pre-ce-backup`
  86: - **Linear account**: For issue tracking integration
  87: - **Syntropy MCP**: For tool integration
  88: - **UV package manager**: For CE CLI tools
  89: 
  90: ### Before You Begin
  91: 
  92: ```bash
  93: # Verify prerequisites
  94: which repomix && echo "‚úì Repomix installed"
  95: which git && echo "‚úì Git installed"
  96: test -f ce-infrastructure.xml && echo "‚úì Framework package available"
  97: 
  98: # Create backup (recommended)
  99: git checkout -b pre-ce-backup
 100: git push origin pre-ce-backup
 101: git checkout main
 102: ```
 103: 
 104: ---
 105: 
 106: ## The 5-Phase Workflow
 107: 
 108: ### Phase Overview
 109: 
 110: 1. **Bucket Collection** (5-10 min) - Stage files for validation
 111: 2. **User Files Copy** (0-15 min) - Migrate project-specific files
 112: 3. **Repomix Package Handling** (5 min) - Extract framework packages
 113: 4. **CLAUDE.md Blending** (10 min) - Merge framework + project guide
 114: 5. **Legacy Cleanup** (0-5 min) - Remove duplicate legacy files
 115: 
 116: **Note**: Not all scenarios execute all phases. See scenario-specific instructions below.
 117: 
 118: ---
 119: 
 120: ## Phase 1: Bucket Collection (Universal)
 121: 
 122: **Duration**: 5-10 minutes
 123: **Applies to**: All scenarios
 124: 
 125: ### Purpose
 126: 
 127: Create a staging area to organize and validate files before copying to CE 1.1 destinations.
 128: 
 129: ### Step 1.1: Create Staging Area
 130: 
 131: ```bash
 132: # Create bucket directories
 133: mkdir -p tmp/syntropy-initialization/{serena,examples,prps,claude-md,claude-dir}
 134: 
 135: # Verify structure
 136: ls -d tmp/syntropy-initialization/*/
 137: # Expected:
 138: # tmp/syntropy-initialization/serena/
 139: # tmp/syntropy-initialization/examples/
 140: # tmp/syntropy-initialization/prps/
 141: # tmp/syntropy-initialization/claude-md/
 142: # tmp/syntropy-initialization/claude-dir/
 143: ```
 144: 
 145: ### Step 1.2: Copy Files to Buckets
 146: 
 147: **Bucket 1: Serena Memories**
 148: 
 149: ```bash
 150: # Copy existing Serena memories (if any)
 151: if [ -d .serena/memories ]; then
 152:   cp -R .serena/memories/*.md tmp/syntropy-initialization/serena/ 2>/dev/null || true
 153:   echo "Serena files: $(ls tmp/syntropy-initialization/serena/*.md 2>/dev/null | wc -l)"
 154: fi
 155: ```
 156: 
 157: **Bucket 2: Examples**
 158: 
 159: ```bash
 160: # Copy existing examples (if any)
 161: if [ -d examples ]; then
 162:   find examples -name "*.md" -exec cp {} tmp/syntropy-initialization/examples/ \; 2>/dev/null || true
 163:   echo "Example files: $(ls tmp/syntropy-initialization/examples/*.md 2>/dev/null | wc -l)"
 164: fi
 165: ```
 166: 
 167: **Bucket 3: PRPs**
 168: 
 169: ```bash
 170: # Copy existing PRPs (if any)
 171: if [ -d PRPs ]; then
 172:   find PRPs -name "*.md" -exec cp {} tmp/syntropy-initialization/prps/ \; 2>/dev/null || true
 173:   echo "PRP files: $(ls tmp/syntropy-initialization/prps/*.md 2>/dev/null | wc -l)"
 174: fi
 175: ```
 176: 
 177: **Bucket 4: CLAUDE.md**
 178: 
 179: ```bash
 180: # Copy existing CLAUDE.md (if any)
 181: if [ -f CLAUDE.md ]; then
 182:   cp CLAUDE.md tmp/syntropy-initialization/claude-md/
 183:   echo "‚úì CLAUDE.md copied"
 184: fi
 185: ```
 186: 
 187: **Bucket 5: Claude Directory**
 188: 
 189: ```bash
 190: # Copy existing .claude directory (if any)
 191: if [ -d .claude ]; then
 192:   cp -R .claude/* tmp/syntropy-initialization/claude-dir/ 2>/dev/null || true
 193:   echo "Claude files: $(ls tmp/syntropy-initialization/claude-dir/ 2>/dev/null | wc -l)"
 194: fi
 195: ```
 196: 
 197: ### Step 1.3: Validate Bucket Contents
 198: 
 199: Review files in each bucket to verify they match bucket characteristics:
 200: 
 201: **Serena Bucket Validation**
 202: 
 203: ```bash
 204: cd tmp/syntropy-initialization/serena/
 205: 
 206: for file in *.md 2>/dev/null; do
 207:   # Check for memory-like content
 208:   if ! grep -qi "memory\|pattern\|guide" "$file" 2>/dev/null; then
 209:     mv "$file" "$file.fake"
 210:     echo "‚ö† Marked $file as fake (not a memory)"
 211:   fi
 212: done
 213: ```
 214: 
 215: **Examples Bucket Validation**
 216: 
 217: ```bash
 218: cd tmp/syntropy-initialization/examples/
 219: 
 220: for file in *.md 2>/dev/null; do
 221:   # Check for example/pattern structure
 222:   if ! grep -qi "example\|pattern\|workflow\|guide" "$file" 2>/dev/null; then
 223:     mv "$file" "$file.fake"
 224:     echo "‚ö† Marked $file as fake (not an example)"
 225:   fi
 226: done
 227: ```
 228: 
 229: **PRPs Bucket Validation**
 230: 
 231: ```bash
 232: cd tmp/syntropy-initialization/prps/
 233: 
 234: for file in *.md 2>/dev/null; do
 235:   # Check for PRP structure (YAML header or PRP-ID in filename)
 236:   if ! grep -q "^---" "$file" 2>/dev/null && ! echo "$file" | grep -qi "prp-"; then
 237:     mv "$file" "$file.fake"
 238:     echo "‚ö† Marked $file as fake (not a PRP)"
 239:   fi
 240: done
 241: ```
 242: 
 243: ### Step 1.4: Bucket Summary
 244: 
 245: ```bash
 246: # Return to project root
 247: cd /path/to/your/project
 248: 
 249: # Generate bucket report
 250: cat > tmp/syntropy-initialization/bucket-report.txt << 'EOF'
 251: # Bucket Collection Report
 252: 
 253: ## Serena Bucket
 254: Valid: $(ls tmp/syntropy-initialization/serena/*.md 2>/dev/null | grep -v ".fake" | wc -l)
 255: Fake: $(ls tmp/syntropy-initialization/serena/*.fake 2>/dev/null | wc -l)
 256: 
 257: ## Examples Bucket
 258: Valid: $(ls tmp/syntropy-initialization/examples/*.md 2>/dev/null | grep -v ".fake" | wc -l)
 259: Fake: $(ls tmp/syntropy-initialization/examples/*.fake 2>/dev/null | wc -l)
 260: 
 261: ## PRPs Bucket
 262: Valid: $(ls tmp/syntropy-initialization/prps/*.md 2>/dev/null | grep -v ".fake" | wc -l)
 263: Fake: $(ls tmp/syntropy-initialization/prps/*.fake 2>/dev/null | wc -l)
 264: 
 265: ## CLAUDE.md Bucket
 266: Valid: $(ls tmp/syntropy-initialization/claude-md/CLAUDE.md 2>/dev/null | wc -l)
 267: 
 268: ## Claude Dir Bucket
 269: Files: $(ls tmp/syntropy-initialization/claude-dir/ 2>/dev/null | wc -l)
 270: EOF
 271: 
 272: # Display report
 273: cat tmp/syntropy-initialization/bucket-report.txt
 274: ```
 275: 
 276: **Phase 1 Complete**: Files staged and validated. Proceed to Phase 2 (or skip if Greenfield).
 277: 
 278: ---
 279: 
 280: ## Phase 2: User Files Copy
 281: 
 282: **Duration**: 0-15 minutes
 283: **Applies to**: Mature Project, CE 1.0 Upgrade, Partial Install
 284: **Skip for**: Greenfield
 285: 
 286: ### Scenario Variations
 287: 
 288: **Skip this phase if**:
 289: - **Greenfield**: No user files exist yet
 290: 
 291: **Full migration if**:
 292: - **Mature Project**: Copy all validated files from buckets
 293: - **CE 1.0 Upgrade**: Copy all validated files + classify existing files
 294: 
 295: **Selective migration if**:
 296: - **Partial Install**: Copy only missing components
 297: 
 298: ### Step 2.1: User Memory Migration
 299: 
 300: **For Mature Project and CE 1.0 Upgrade**:
 301: 
 302: ```bash
 303: # Copy validated user memories (non-.fake files)
 304: find tmp/syntropy-initialization/serena -name "*.md" ! -name "*.fake" -exec cp {} .serena/memories/ \; 2>/dev/null || true
 305: 
 306: # Add YAML headers to memories without them
 307: cd .serena/memories/
 308: 
 309: for memory in *.md 2>/dev/null; do
 310:   # Skip if already has YAML header
 311:   if head -n 1 "$memory" | grep -q "^---"; then
 312:     continue
 313:   fi
 314: 
 315:   # Determine type (heuristic based on content)
 316:   if grep -qi "architecture\|security\|core principle\|critical" "$memory"; then
 317:     TYPE="critical"
 318:   else
 319:     TYPE="regular"
 320:   fi
 321: 
 322:   # Add YAML header for user memory
 323:   cat > "${memory}.tmp" << EOF
 324: ---
 325: type: user
 326: source: target-project
 327: created: "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
 328: updated: "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
 329: ---
 330: 
 331: $(cat "$memory")
 332: EOF
 333:   mv "${memory}.tmp" "$memory"
 334:   echo "‚úì Added YAML header to $memory (type: $TYPE)"
 335: done
 336: 
 337: cd ../..
 338: ```
 339: 
 340: ### Step 2.2: User PRP Migration
 341: 
 342: **For Mature Project and CE 1.0 Upgrade**:
 343: 
 344: ```bash
 345: # Create PRP directories if needed
 346: mkdir -p .ce/PRPs/{executed,feature-requests,archived}
 347: 
 348: # Copy validated user PRPs (non-.fake files)
 349: find tmp/syntropy-initialization/prps -name "*.md" ! -name "*.fake" -exec sh -c '
 350:   for prp; do
 351:     # Determine destination based on filename or content
 352:     if echo "$prp" | grep -qi "executed"; then
 353:       cp "$prp" .ce/PRPs/executed/
 354:     elif echo "$prp" | grep -qi "feature\|request"; then
 355:       cp "$prp" .ce/PRPs/feature-requests/
 356:     else
 357:       cp "$prp" .ce/PRPs/executed/
 358:     fi
 359:   done
 360: ' sh {} +
 361: 
 362: # Add YAML headers to user PRPs (if missing)
 363: cd .ce/PRPs/executed/
 364: 
 365: for prp in *.md 2>/dev/null; do
 366:   # Skip if already has YAML header
 367:   if head -n 1 "$prp" | grep -q "^---"; then
 368:     continue
 369:   fi
 370: 
 371:   # Extract PRP ID from filename (e.g., USER-001 from USER-001-feature.md)
 372:   PRP_ID=$(echo "$prp" | sed 's/\.md$//' | cut -d'-' -f1-2)
 373:   TITLE=$(echo "$prp" | sed 's/\.md$//' | sed 's/^[^-]*-[^-]*-//' | tr '-' ' ')
 374: 
 375:   # Add YAML header for user PRP
 376:   cat > "${prp}.tmp" << EOF
 377: ---
 378: prp_id: $PRP_ID
 379: title: $TITLE
 380: status: completed
 381: created: "$(date -u +%Y-%m-%d)"
 382: source: target-project
 383: type: user
 384: ---
 385: 
 386: $(cat "$prp")
 387: EOF
 388:   mv "${prp}.tmp" "$prp"
 389:   echo "‚úì Added YAML header to $prp"
 390: done
 391: 
 392: cd ../../..
 393: echo "‚úì User PRPs migrated to .ce/PRPs/"
 394: ```
 395: 
 396: **User PRP YAML Header Format**:
 397: 
 398: ```yaml
 399: ---
 400: prp_id: USER-001
 401: title: User Feature Implementation
 402: status: completed
 403: created: "2025-11-04"
 404: source: target-project
 405: type: user
 406: ---
 407: ```
 408: 
 409: **Notes**:
 410: - `type: user` distinguishes user PRPs from framework PRPs
 411: - `source: target-project` indicates origin (vs. framework source: ctx-eng-plus)
 412: - Framework PRPs use `type: regular` or `type: critical`
 413: 
 414: ### Step 2.3: User Examples Migration
 415: 
 416: **For Mature Project and CE 1.0 Upgrade**:
 417: 
 418: ```bash
 419: # Create examples directory if needed
 420: mkdir -p .ce/examples
 421: 
 422: # Copy validated user examples (non-.fake files)
 423: find tmp/syntropy-initialization/examples -name "*.md" ! -name "*.fake" -exec cp {} .ce/examples/ \; 2>/dev/null || true
 424: 
 425: echo "‚úì User examples migrated to .ce/examples/"
 426: ```
 427: 
 428: ### Step 2.4: User Commands/Settings Migration
 429: 
 430: **For all scenarios with existing .claude/ content**:
 431: 
 432: ```bash
 433: # Copy custom commands (preserve existing)
 434: if [ -d tmp/syntropy-initialization/claude-dir/commands ]; then
 435:   mkdir -p .claude/commands
 436:   cp -n tmp/syntropy-initialization/claude-dir/commands/*.md .claude/commands/ 2>/dev/null || true
 437:   echo "‚úì User commands preserved"
 438: fi
 439: 
 440: # Backup existing settings (will be merged in Phase 3)
 441: if [ -f tmp/syntropy-initialization/claude-dir/settings.local.json ]; then
 442:   mkdir -p .claude
 443:   cp tmp/syntropy-initialization/claude-dir/settings.local.json .claude/settings.pre-ce.json
 444:   echo "‚úì Existing settings backed up"
 445: fi
 446: ```
 447: 
 448: ### Step 2.5: Migration Summary
 449: 
 450: ```bash
 451: # Generate migration report
 452: cat > tmp/syntropy-initialization/phase2-report.txt << EOF
 453: # Phase 2: User Files Migration Report
 454: 
 455: ## Memories Migrated
 456: User memories: $(find .serena/memories -maxdepth 1 -name "*.md" 2>/dev/null | wc -l)
 457: Headers added (type: user): $(grep -l "^type: user" .serena/memories/*.md 2>/dev/null | wc -l)
 458: 
 459: ## PRPs Migrated
 460: Executed: $(ls .ce/PRPs/executed/*.md 2>/dev/null | wc -l)
 461: Feature requests: $(ls .ce/PRPs/feature-requests/*.md 2>/dev/null | wc -l)
 462: Headers added (type: user): $(grep -l "^type: user" .ce/PRPs/executed/*.md 2>/dev/null | wc -l)
 463: 
 464: ## Examples Migrated
 465: User examples: $(ls .ce/examples/*.md 2>/dev/null | wc -l)
 466: 
 467: ## Commands/Settings
 468: Custom commands: $(ls .claude/commands/*.md 2>/dev/null | wc -l)
 469: Settings backed up: $(test -f .claude/settings.pre-ce.json && echo "yes" || echo "no")
 470: 
 471: ## YAML Header Summary
 472: - User memories: type: user, source: target-project
 473: - User PRPs: type: user, source: target-project, prp_id, title, status
 474: - Framework memories: type: regular (default) or type: critical (upgraded manually)
 475: - Framework PRPs: Standard PRP YAML with batch_id, stage, order
 476: EOF
 477: 
 478: cat tmp/syntropy-initialization/phase2-report.txt
 479: ```
 480: 
 481: **Phase 2 Complete**: User files migrated with YAML headers (`type: user`). Framework files use `type: regular` or `type: critical`. Proceed to Phase 3.
 482: 
 483: ---
 484: 
 485: ## Phase 3: Repomix Package Handling (Universal)
 486: 
 487: **Duration**: 5 minutes
 488: **Applies to**: All scenarios
 489: 
 490: ### Purpose
 491: 
 492: Extract framework packages to install system documentation, memories, examples, commands, and tools.
 493: 
 494: ### Step 3.1: Copy Workflow Package
 495: 
 496: ```bash
 497: # Create system directory
 498: mkdir -p .ce/examples/system/
 499: 
 500: # Copy workflow documentation package (reference only, not extracted)
 501: cp ce-workflow-docs.xml .ce/examples/system/
 502: 
 503: echo "‚úì Workflow package copied to .ce/examples/system/ce-workflow-docs.xml"
 504: ```
 505: 
 506: **Note**: `ce-workflow-docs.xml` is stored as-is for reference and redistribution. The actual framework files come from `ce-infrastructure.xml` extraction below.
 507: 
 508: ### Step 3.2: Extract Infrastructure Package
 509: 
 510: ```bash
 511: # Extract complete framework infrastructure
 512: # This creates /system/ subdirectories automatically
 513: repomix --unpack ce-infrastructure.xml --target ./
 514: 
 515: # Verify extraction
 516: echo "Framework files extracted:"
 517: echo "  System memories: $(ls .serena/memories/system/*.md 2>/dev/null | wc -l)"
 518: echo "  System examples: $(ls .ce/examples/system/*.md 2>/dev/null | wc -l)"
 519: echo "  Framework commands: $(ls .claude/commands/*.md 2>/dev/null | wc -l)"
 520: echo "  Tool files: $(find tools -name "*.py" 2>/dev/null | wc -l)"
 521: ```
 522: 
 523: **What gets extracted**:
 524: 
 525: ```
 526: .ce/examples/system/          # 21 framework example files
 527: .serena/memories/system/      # 23 framework memories (6 critical + 17 regular)
 528: .claude/commands/             # 11 framework commands
 529: .claude/settings.local.json   # Framework settings (merged with existing)
 530: tools/                        # 33 tool source files
 531: CLAUDE.md                     # Framework sections (merged with existing)
 532: ```
 533: 
 534: ### Step 3.3: Validate Framework Installation
 535: 
 536: ```bash
 537: # Check system memories (expected: 23)
 538: SYSTEM_MEMORIES=$(ls .serena/memories/system/*.md 2>/dev/null | wc -l)
 539: test $SYSTEM_MEMORIES -eq 23 && echo "‚úì All 23 system memories installed" || echo "‚ö† Only $SYSTEM_MEMORIES system memories found"
 540: 
 541: # Check system examples (expected: 21)
 542: SYSTEM_EXAMPLES=$(ls .ce/examples/system/*.md 2>/dev/null | wc -l)
 543: test $SYSTEM_EXAMPLES -eq 21 && echo "‚úì All 21 system examples installed" || echo "‚ö† Only $SYSTEM_EXAMPLES system examples found"
 544: 
 545: # Check framework commands (expected: 11)
 546: FRAMEWORK_COMMANDS=$(ls .claude/commands/*.md 2>/dev/null | wc -l)
 547: test $FRAMEWORK_COMMANDS -ge 11 && echo "‚úì All 11 framework commands installed" || echo "‚ö† Only $FRAMEWORK_COMMANDS commands found"
 548: 
 549: # Check tool files (expected: 33)
 550: TOOL_FILES=$(find tools -name "*.py" 2>/dev/null | wc -l)
 551: test $TOOL_FILES -ge 33 && echo "‚úì Tool source files installed" || echo "‚ö† Only $TOOL_FILES tool files found"
 552: 
 553: # Check settings merged
 554: test -f .claude/settings.local.json && jq empty .claude/settings.local.json && echo "‚úì Settings valid JSON" || echo "‚ö† Settings invalid"
 555: ```
 556: 
 557: ### Step 3.4: Initialize CE Tools
 558: 
 559: ```bash
 560: # Install CE CLI tools
 561: cd tools
 562: ./bootstrap.sh
 563: 
 564: # Verify installation
 565: uv run ce --version
 566: # Expected: ce version 1.1.0
 567: 
 568: # Run basic validation
 569: uv run ce validate --level 1
 570: # Expected: Structure validation passes
 571: 
 572: cd ..
 573: ```
 574: 
 575: **Phase 3 Complete**: Framework installed with /system/ organization. Proceed to Phase 4.
 576: 
 577: ---
 578: 
 579: ## Phase 4: CLAUDE.md Blending (Universal)
 580: 
 581: **Duration**: 10 minutes
 582: **Applies to**: All scenarios
 583: 
 584: ### Purpose
 585: 
 586: Merge framework CLAUDE.md sections with project-specific sections, creating a single unified project guide.
 587: 
 588: ### Step 4.1: Backup Existing CLAUDE.md
 589: 
 590: ```bash
 591: # Backup user's CLAUDE.md (if exists)
 592: if [ -f CLAUDE.md ]; then
 593:   cp CLAUDE.md "CLAUDE.md.backup-$(date +%Y%m%d-%H%M%S)"
 594:   echo "‚úì CLAUDE.md backed up"
 595: else
 596:   echo "‚Ñπ No existing CLAUDE.md (fresh installation)"
 597: fi
 598: ```
 599: 
 600: ### Step 4.2: Identify Framework vs Project Sections
 601: 
 602: Framework sections (from ce-infrastructure.xml):
 603: - Communication
 604: - Core Principles
 605: - UV Package Management
 606: - Ad-Hoc Code Policy
 607: - Quick Commands
 608: - Tool Naming Convention
 609: - Allowed Tools Summary
 610: - Command Permissions
 611: - Quick Tool Selection
 612: - Project Structure
 613: - Testing Standards
 614: - Code Quality
 615: - Context Commands
 616: - Syntropy MCP Tool Sync
 617: - Linear Integration
 618: - Batch PRP Generation
 619: - PRP Sizing
 620: - Testing Patterns
 621: - Documentation Standards
 622: - Efficient Doc Review
 623: - Resources
 624: - Keyboard Shortcuts
 625: - Git Worktree
 626: - Troubleshooting
 627: 
 628: Project sections (user-defined) are any sections not in framework list.
 629: 
 630: ### Step 4.3: Blend Sections
 631: 
 632: **Manual Blending** (recommended for first installation):
 633: 
 634: ```bash
 635: # Edit CLAUDE.md to mark sections
 636: vim CLAUDE.md
 637: 
 638: # Add [FRAMEWORK] or [PROJECT] markers to section headers:
 639: # ## [FRAMEWORK] Communication
 640: # ## [PROJECT] Project-Specific Communication
 641: # ## [FRAMEWORK] Core Principles
 642: # ## [PROJECT] Team Conventions
 643: ```
 644: 
 645: **Automated Blending** (if framework provides blending tool):
 646: 
 647: ```bash
 648: # Use denoise command to merge sections
 649: /denoise CLAUDE.md
 650: 
 651: # Review merged output
 652: less CLAUDE.md
 653: ```
 654: 
 655: ### Step 4.4: Validate Blended CLAUDE.md
 656: 
 657: ```bash
 658: # Check for framework markers
 659: grep -c "\[FRAMEWORK\]" CLAUDE.md
 660: # Expected: Multiple framework sections marked
 661: 
 662: # Check for project markers (if any)
 663: grep -c "\[PROJECT\]" CLAUDE.md
 664: # Expected: 0+ (depending on scenario)
 665: 
 666: # Verify key framework sections present
 667: for section in "Communication" "Core Principles" "Quick Commands" "Tool Naming Convention"; do
 668:   grep -q "## .*$section" CLAUDE.md && echo "‚úì $section section present" || echo "‚ö† $section section missing"
 669: done
 670: ```
 671: 
 672: ### Step 4.5: Add Project-Specific Sections
 673: 
 674: **For Mature Project and CE 1.0 Upgrade**:
 675: 
 676: Add project-specific sections to CLAUDE.md:
 677: 
 678: ```bash
 679: cat >> CLAUDE.md << 'EOF'
 680: 
 681: ---
 682: 
 683: ## [PROJECT] Project-Specific Information
 684: 
 685: ### Project Structure
 686: 
 687: **Architecture**: [Your architecture description]
 688: 
 689: **Key Components**:
 690: - Component 1: [Description]
 691: - Component 2: [Description]
 692: 
 693: ### Development Workflow
 694: 
 695: **Branch Strategy**: [Your branching model]
 696: 
 697: **Code Review Process**: [Your review process]
 698: 
 699: ### Testing Standards
 700: 
 701: **Test Coverage**: [Your coverage requirements]
 702: 
 703: **Test Frameworks**: [Your test tools]
 704: 
 705: ### Deployment Process
 706: 
 707: **CI/CD Pipeline**: [Your pipeline description]
 708: 
 709: **Deployment Stages**: [Your stages]
 710: 
 711: ---
 712: 
 713: EOF
 714: ```
 715: 
 716: **Phase 4 Complete**: CLAUDE.md blended with framework + project sections. Proceed to Phase 5 (if applicable).
 717: 
 718: ---
 719: 
 720: ## Phase 5: Legacy Cleanup
 721: 
 722: **Duration**: 0-5 minutes
 723: **Applies to**: CE 1.0 Upgrade only
 724: **Skip for**: Greenfield, Mature Project, Partial Install
 725: 
 726: ### Scenario Variations
 727: 
 728: **Skip this phase if**:
 729: - **Greenfield**: No legacy files (new project)
 730: - **Mature Project**: No legacy CE files (first CE installation)
 731: - **Partial Install**: Selective cleanup only
 732: 
 733: **Full cleanup if**:
 734: - **CE 1.0 Upgrade**: Aggressive cleanup of legacy CE 1.0 structure
 735: 
 736: ### Step 5.1: Verify Migration Completed
 737: 
 738: ```bash
 739: # Verify all files migrated to CE 1.1 structure
 740: test -d .ce/PRPs/system && echo "‚úì System PRPs migrated"
 741: test -d .ce/examples/system && echo "‚úì System examples migrated"
 742: test -d .serena/memories/system && echo "‚úì System memories migrated"
 743: 
 744: # Check for errors in migration
 745: if [ -f tmp/syntropy-initialization/phase2-report.txt ]; then
 746:   grep -i error tmp/syntropy-initialization/phase2-report.txt
 747:   # Expected: No errors
 748: fi
 749: ```
 750: 
 751: ### Step 5.2: Archive Legacy Organization
 752: 
 753: ```bash
 754: # Create archive of legacy files before deletion (safety backup)
 755: mkdir -p tmp/syntropy-initialization/legacy-backup/
 756: 
 757: # Archive legacy directories
 758: tar -czf "tmp/syntropy-initialization/legacy-backup/pre-ce-1.1-$(date +%Y%m%d-%H%M%S).tar.gz" \
 759:   PRPs/ \
 760:   examples/ \
 761:   .serena/memories/*.md \
 762:   2>/dev/null || true
 763: 
 764: echo "‚úì Legacy files archived"
 765: 
 766: # Verify archive created
 767: ARCHIVE_FILE=$(ls -t tmp/syntropy-initialization/legacy-backup/*.tar.gz | head -n 1)
 768: test -f "$ARCHIVE_FILE" && echo "‚úì Archive: $ARCHIVE_FILE" || echo "‚ö† Archive not created"
 769: ```
 770: 
 771: ### Step 5.3: Delete Legacy Organization Files
 772: 
 773: **Delete legacy PRPs directory** (now in .ce/PRPs/):
 774: 
 775: ```bash
 776: if [ -d PRPs/ ]; then
 777:   # Count files before deletion
 778:   LEGACY_PRPS=$(find PRPs -name "*.md" | wc -l)
 779: 
 780:   # Delete directory
 781:   rm -rf PRPs/
 782: 
 783:   echo "‚úì Deleted legacy PRPs/ ($LEGACY_PRPS files migrated to .ce/PRPs/)"
 784: fi
 785: ```
 786: 
 787: **Delete legacy examples directory** (now in .ce/examples/):
 788: 
 789: ```bash
 790: if [ -d examples/ ]; then
 791:   # Count files before deletion
 792:   LEGACY_EXAMPLES=$(find examples -name "*.md" | wc -l)
 793: 
 794:   # Delete directory
 795:   rm -rf examples/
 796: 
 797:   echo "‚úì Deleted legacy examples/ ($LEGACY_EXAMPLES files migrated to .ce/examples/)"
 798: fi
 799: ```
 800: 
 801: **Delete legacy memories** (now in .serena/memories/system/):
 802: 
 803: ```bash
 804: # Delete only memories that were migrated to /system/
 805: # Preserve user memories (not in system/)
 806: if [ -d .serena/memories/ ]; then
 807:   find .serena/memories/ -maxdepth 1 -name "*.md" -type f | while read file; do
 808:     basename=$(basename "$file")
 809:     if [ -f .serena/memories/system/"$basename" ]; then
 810:       rm -f "$file"
 811:       echo "‚úì Deleted legacy .serena/memories/$basename (migrated to system/)"
 812:     fi
 813:   done
 814: fi
 815: ```
 816: 
 817: ### Step 5.4: Log Cleanup Summary
 818: 
 819: ```bash
 820: # Log cleanup actions to initialization report
 821: cat > tmp/syntropy-initialization/phase5-report.txt << EOF
 822: # Phase 5: Legacy Organization Cleanup Report
 823: 
 824: ## Deleted Legacy Files
 825: 
 826: **PRPs Directory**: $(test ! -d PRPs && echo "Deleted" || echo "Still exists")
 827: **Examples Directory**: $(test ! -d examples && echo "Deleted" || echo "Still exists")
 828: **Legacy Memories**: $(find .serena/memories -maxdepth 1 -name "*.md" 2>/dev/null | wc -l) remaining at root level
 829: 
 830: ## Backup
 831: 
 832: **Archive Created**: $(ls tmp/syntropy-initialization/legacy-backup/*.tar.gz | head -n 1)
 833: **Archive Size**: $(du -h tmp/syntropy-initialization/legacy-backup/*.tar.gz | head -n 1 | cut -f1)
 834: 
 835: ## Verification
 836: 
 837: **CE 1.1 Structure Active**: $(test -d .ce/PRPs/system && test -d .ce/examples/system && test -d .serena/memories/system && echo "Yes" || echo "No")
 838: **Zero Noise**: $(test ! -d PRPs && test ! -d examples && echo "Yes - Clean project" || echo "No - Legacy files remain")
 839: 
 840: EOF
 841: 
 842: cat tmp/syntropy-initialization/phase5-report.txt
 843: ```
 844: 
 845: ### Step 5.5: Zero Noise Verification
 846: 
 847: ```bash
 848: # Final verification: No legacy noise
 849: echo ""
 850: echo "=== Zero Noise Verification ==="
 851: 
 852: # Check legacy directories deleted
 853: ! test -d PRPs && echo "‚úÖ PRPs/ removed" || echo "‚ùå PRPs/ still exists"
 854: ! test -d examples && echo "‚úÖ examples/ removed" || echo "‚ùå examples/ still exists"
 855: 
 856: # Check no duplicate system memories
 857: DUPLICATE_SYSTEM_MEMORIES=$(find .serena/memories/ -maxdepth 1 -name "*.md" -type f | while read f; do
 858:   basename=$(basename "$f")
 859:   test -f .serena/memories/system/"$basename" && echo "$f"
 860: done | wc -l)
 861: 
 862: test "$DUPLICATE_SYSTEM_MEMORIES" -eq 0 && echo "‚úÖ No duplicate system memories" || echo "‚ùå $DUPLICATE_SYSTEM_MEMORIES duplicate system memories found"
 863: 
 864: # Final status
 865: if [ ! -d PRPs ] && [ ! -d examples ] && [ "$DUPLICATE_SYSTEM_MEMORIES" -eq 0 ]; then
 866:   echo ""
 867:   echo "‚úÖ PROJECT IS CLEAN - Zero noise achieved"
 868: else
 869:   echo ""
 870:   echo "‚ö† PROJECT HAS LEGACY NOISE - Manual cleanup required"
 871: fi
 872: ```
 873: 
 874: **Phase 5 Complete**: Legacy files removed, CE 1.1 structure clean. Installation complete.
 875: 
 876: ---
 877: 
 878: ## Scenario-Specific Workflows
 879: 
 880: ### Scenario 1: Greenfield Project
 881: 
 882: **Use when**: New project with no existing CE components
 883: 
 884: **Phases**: 1, 3, 4 (skip 2, 5)
 885: 
 886: **Duration**: ~10 minutes
 887: 
 888: #### Quick Steps
 889: 
 890: ```bash
 891: # Phase 1: Bucket Collection (will be empty)
 892: mkdir -p tmp/syntropy-initialization/{serena,examples,prps,claude-md,claude-dir}
 893: echo "‚úì Buckets created (empty for greenfield)"
 894: 
 895: # Phase 2: SKIP (no user files)
 896: echo "‚è≠ Skipping Phase 2 (no user files)"
 897: 
 898: # Phase 3: Repomix Package Handling
 899: repomix --unpack ce-infrastructure.xml --target ./
 900: cd tools && ./bootstrap.sh && cd ..
 901: echo "‚úì Framework installed"
 902: 
 903: # Phase 4: CLAUDE.md Blending (framework only)
 904: grep -q "## Communication" CLAUDE.md && echo "‚úì Framework CLAUDE.md installed"
 905: 
 906: # Phase 5: SKIP (no legacy files)
 907: echo "‚è≠ Skipping Phase 5 (no legacy files)"
 908: 
 909: # Validate
 910: cd tools && uv run ce validate --level 4 && cd ..
 911: echo "‚úÖ Greenfield installation complete"
 912: ```
 913: 
 914: ---
 915: 
 916: ### Scenario 2: Mature Project (No CE)
 917: 
 918: **Use when**: Existing codebase with no CE components
 919: 
 920: **Phases**: 1, 2, 3, 4 (skip 5)
 921: 
 922: **Duration**: ~45 minutes
 923: 
 924: ---
 925: 
 926: ### Scenario 3: CE 1.0 Upgrade
 927: 
 928: **Use when**: Existing CE installation, no .ce/ directory (legacy structure)
 929: 
 930: **Phases**: 1, 2, 3, 4, 5 (all phases)
 931: 
 932: **Duration**: ~40 minutes
 933: 
 934: ---
 935: 
 936: ### Scenario 4: Partial Install (Completion)
 937: 
 938: **Use when**: Project has some CE components but missing others
 939: 
 940: **Phases**: 1, 3, 4 (selective)
 941: 
 942: **Duration**: ~15 minutes
 943: 
 944: ---
 945: 
 946: ## Validation Checklist
 947: 
 948: ### Structure Validation
 949: 
 950: ```bash
 951: # Check CE 1.1 directory structure
 952: test -d .ce/examples/system && echo "‚úÖ .ce/examples/system/"
 953: test -d .ce/PRPs/system && echo "‚úÖ .ce/PRPs/system/"
 954: test -d .serena/memories/system && echo "‚úÖ .serena/memories/system/"
 955: test -d .claude/commands && echo "‚úÖ .claude/commands/"
 956: test -f CLAUDE.md && echo "‚úÖ CLAUDE.md"
 957: ```
 958: 
 959: ### Component Counts
 960: 
 961: ```bash
 962: # Expected file counts
 963: echo "System memories: $(ls .serena/memories/system/*.md 2>/dev/null | wc -l) (expected: 23)"
 964: echo "System examples: $(ls .ce/examples/system/*.md 2>/dev/null | wc -l) (expected: 21)"
 965: echo "Framework commands: $(ls .claude/commands/*.md 2>/dev/null | wc -l) (expected: 11+)"
 966: ```
 967: 
 968: ---
 969: 
 970: ## Troubleshooting
 971: 
 972: ### Issue: Repomix command not found
 973: 
 974: **Solution**:
 975: 
 976: ```bash
 977: # Install repomix globally
 978: npm install -g repomix
 979: 
 980: # Or use npx
 981: npx repomix --unpack ce-infrastructure.xml --target ./
 982: ```
 983: 
 984: ### Issue: Bootstrap script fails
 985: 
 986: **Solution**:
 987: 
 988: ```bash
 989: cd tools
 990: 
 991: # Install UV manually
 992: curl -LsSf https://astral.sh/uv/install.sh | sh
 993: 
 994: # Retry bootstrap
 995: ./bootstrap.sh
 996: 
 997: # Or install dependencies directly
 998: uv sync
 999: ```
1000: 
1001: ---
1002: 
1003: ## Success Criteria
1004: 
1005: Your installation is complete when:
1006: 
1007: - ‚úÖ All CE 1.1 directories created (`.ce/`, `.serena/`, `.claude/`)
1008: - ‚úÖ System files installed (23 memories, 21 examples, 11 commands)
1009: - ‚úÖ CLAUDE.md present with framework sections
1010: - ‚úÖ Settings JSON valid and merged
1011: - ‚úÖ CE tools installed (`ce --version` works)
1012: - ‚úÖ Validation level 4 passes
1013: - ‚úÖ Context drift <5%
1014: - ‚úÖ Zero noise (no legacy directories for CE 1.0 upgrades)
1015: - ‚úÖ Serena memories loaded
1016: - ‚úÖ Linear configured (if using)
1017: - ‚úÖ First PRP created successfully
1018: 
1019: ---
1020: 
1021: ## Related Documentation
1022: 
1023: - **Framework Rules**: `.ce/RULES.md`
1024: - **Tool Usage Guide**: `.ce/examples/system/TOOL-USAGE-GUIDE.md`
1025: - **PRP-0 Template**: `.ce/examples/system/templates/PRP-0-CONTEXT-ENGINEERING.md`
1026: - **Validation Levels**: `.serena/memories/system/validation-levels.md`
1027: - **Testing Standards**: `.serena/memories/system/testing-standards.md`
1028: 
1029: ---
1030: 
1031: **Installation Guide Version**: 1.1
1032: **Last Updated**: 2025-11-04
1033: **Framework Version**: CE 1.1
</file>

<file path="CLAUDE.md">
  1: # Context Engineering Tools - Project Guide
  2: 
  3: **Project**: CLI tooling for Context Engineering framework operations
  4: 
  5: ## Communication
  6: 
  7: Direct, token-efficient. No fluff. Call out problems directly.
  8: 
  9: ## Core Principles
 10: 
 11: ### Syntropy MCP First
 12: - Use `mcp__syntropy__<server>_<tool>` format
 13: - Prefer Syntropy tools over bash/cmdline
 14: 
 15: ### No Fishy Fallbacks
 16: - Fast failure: Let exceptions bubble up
 17: - Actionable errors: Include üîß troubleshooting
 18: - No silent corruption
 19: 
 20: ### KISS
 21: - Simple solutions first
 22: - Clear code over clever code
 23: - Minimal dependencies (stdlib only)
 24: - Single responsibility per function
 25: 
 26: ### UV Package Management - STRICT
 27: ```bash
 28: uv add package-name              # Production
 29: uv add --dev package-name        # Development
 30: uv sync                          # Install
 31: 
 32: # ‚ùå FORBIDDEN: Manual pyproject.toml editing
 33: ```
 34: 
 35: ### Ad-Hoc Code Policy
 36: - Max 3 LOC inline
 37: - Longer code ‚Üí tmp/ file and execute
 38: - Must execute via run_py
 39: 
 40: ## Quick Commands
 41: 
 42: ```bash
 43: cd tools
 44: 
 45: # Validation & health
 46: uv run ce validate --level all
 47: uv run ce context health
 48: uv run ce git status
 49: 
 50: # Cleanup
 51: uv run ce vacuum                  # Dry-run (report only)
 52: uv run ce vacuum --execute        # Delete temp files only
 53: uv run ce vacuum --auto           # Delete temp files + obsolete docs/dead links
 54: 
 55: # Testing
 56: uv run pytest tests/ -v
 57: 
 58: # Run Python (3 LOC max ad-hoc)
 59: uv run ce run_py "print('hello')"
 60: uv run ce run_py ../tmp/script.py
 61: ```
 62: 
 63: ## Framework Initialization
 64: 
 65: **First-time setup**: See [examples/INITIALIZATION.md](examples/INITIALIZATION.md) for complete CE 1.1 initialization guide.
 66: 
 67: **Key Steps** (5-phase workflow):
 68: 1. **Bucket Collection**: Extract existing Serena memories, examples, PRPs, CLAUDE.md, .claude directory
 69: 2. **User Files Migration**: Copy validated user files with `type: user` YAML headers
 70: 3. **Repomix Package Handling**: Extract ce-infrastructure.xml to /system/ subfolders
 71: 4. **Blending**: Merge framework + user files (CLAUDE.md sections, settings.local.json, commands)
 72: 5. **Cleanup**: Remove initialization artifacts, verify structure
 73: 
 74: **Repomix Usage** (manual context loading):
 75: 
 76: ```bash
 77: # Load workflow docs (commands, validation, PRP patterns)
 78: # Reference package - stored in .ce/, not extracted during initialization
 79: cat .ce/ce-workflow-docs.xml
 80: 
 81: # Load infrastructure docs (memories, rules, system architecture)
 82: # Extracted to /system/ subfolders during Phase 3 of initialization
 83: npx repomix --unpack .ce/ce-infrastructure.xml --target tmp/extraction/
 84: ```
 85: 
 86: **Repomix Package Structure** (CE 1.1):
 87: - **ce-workflow-docs.xml**: <60KB (reference package, not extracted)
 88: - **ce-infrastructure.xml**: <150KB (all framework files with /system/ organization)
 89: - **Combined**: <210KB total
 90: 
 91: **Migration Scenarios**:
 92: 
 93: All scenarios documented in [INITIALIZATION.md](examples/INITIALIZATION.md) with scenario-specific variations within each phase:
 94: - **Greenfield**: New project setup (10 min)
 95: - **Mature Project**: Add CE to existing codebase (45 min)
 96: - **CE 1.0 Upgrade**: Upgrade CE 1.0 ‚Üí CE 1.1 (40 min)
 97: - **Partial Install**: Complete partial CE installation (15 min)
 98: 
 99: **Memory Type System** (CE 1.1):
100: 
101: Framework memories (23 files) use `type: regular` by default:
102: ```yaml
103: ---
104: type: regular
105: category: documentation
106: tags: [tag1, tag2, tag3]
107: created: "2025-11-04T17:30:00Z"
108: updated: "2025-11-04T17:30:00Z"
109: ---
110: ```
111: 
112: **Critical Memory Candidates** (upgrade during initialization):
113: - code-style-conventions.md
114: - suggested-commands.md
115: - task-completion-checklist.md
116: - testing-standards.md
117: - tool-usage-syntropy.md
118: - use-syntropy-tools-not-bash.md
119: 
120: **User File Headers** (added during Phase 2 of initialization):
121: 
122: User memories:
123: ```yaml
124: ---
125: type: user
126: source: target-project
127: created: "2025-11-04T00:00:00Z"
128: updated: "2025-11-04T00:00:00Z"
129: ---
130: ```
131: 
132: User PRPs:
133: ```yaml
134: ---
135: prp_id: USER-001
136: title: User Feature Implementation
137: status: completed
138: created: "2025-11-04"
139: source: target-project
140: type: user
141: ---
142: ```
143: 
144: **See Also**:
145: - [examples/INITIALIZATION.md](examples/INITIALIZATION.md) - Complete initialization guide
146: - [.serena/memories/README.md](.serena/memories/README.md) - Memory type system documentation
147: - [examples/templates/PRP-0-CONTEXT-ENGINEERING.md](examples/templates/PRP-0-CONTEXT-ENGINEERING.md) - Document framework installation
148: 
149: ## Working Directory
150: 
151: **Default**: `/Users/bprzybysz/nc-src/ctx-eng-plus`
152: 
153: **For tools/ commands**: Use `cd tools &&` or `uv run -C tools`
154: 
155: ## Hooks
156: 
157: **Pre-Commit**: Runs `ce validate --level 4` before commit (skip: `--no-verify`)
158: 
159: **Session Start**: Auto drift score check
160: 
161: **Shell Functions** (optional): Source `.ce/shell-functions.sh` for `cet` alias
162: 
163: ## Tool Naming Convention
164: 
165: Format: `mcp__syntropy__<server>_<tool>`
166: - `mcp__` - MCP prefix (double underscore)
167: - `syntropy__` - Syntropy server (double underscore)
168: - `<server>_` - Server name + single underscore
169: - `<tool>` - Tool name
170: 
171: Example: `mcp__syntropy__serena_find_symbol`
172: 
173: ## Allowed Tools Summary
174: 
175: **Post-Lockdown State** (after PRP-A & PRP-D):
176: - **Before**: 87 MCP tools (via Syntropy aggregator)
177: - **After**: 32 MCP tools (55 denied for native tool preference)
178: - **Token reduction**: ~44k tokens (96% reduction from 46k‚Üí2k)
179: 
180: ### Kept Tools by Category
181: 
182: **Serena** (11 tools): Code symbol navigation
183: - find_symbol, get_symbols_overview, search_for_pattern
184: - find_referencing_symbols, write_memory, read_memory, list_memories
185: - create_text_file, read_file, list_dir, delete_memory
186: 
187: **Linear** (9 tools): Project management integration
188: - create_issue, get_issue, list_issues, update_issue
189: - list_projects, list_teams, list_users, get_team, create_project
190: 
191: **Context7** (2 tools): Library documentation
192: - resolve_library_id, get_library_docs
193: 
194: **Thinking** (1 tool): Complex reasoning
195: - sequentialthinking
196: 
197: **Syntropy System** (2 tools): System utilities
198: - healthcheck (MCP diagnostics)
199: - knowledge_search (semantic search across PRPs, memories)
200: 
201: **Bash Commands** (~50 patterns): See "Command Permissions" section below
202: **Native Tools**: Read, Write, Edit, Glob, Grep, WebSearch, WebFetch
203: 
204: ### Denied Tools (55 total)
205: 
206: **Rationale**: Native Claude Code tools provide equivalent or better functionality
207: 
208: **Categories**:
209: - Filesystem (8): Use Read, Write, Edit, Glob instead
210: - Git (5): Use Bash(git:*) instead
211: - GitHub (26): Use Bash(gh:*) instead
212: - Repomix (4): Use incremental Glob/Grep/Read instead
213: - Playwright (6): Use WebFetch or Bash(playwright CLI) instead
214: - Perplexity (1): Use WebSearch instead
215: - Syntropy (5): Use Read for docs, rare-use tools
216: 
217: **Full details**: See [TOOL-USAGE-GUIDE.md](TOOL-USAGE-GUIDE.md)
218: 
219: ## Command Permissions
220: 
221: **Permission Model**: Auto-allow safe commands, ask-first for potentially destructive operations.
222: 
223: ### Auto-Allow Patterns (~35 bash patterns)
224: 
225: Commands that never prompt:
226: 
227: **File Inspection**:
228: - `ls`, `cat`, `head`, `tail`, `less`, `more`, `file`, `stat`
229: 
230: **Navigation**:
231: - `cd`, `pwd`, `which`, `whereis`
232: 
233: **Search**:
234: - `find`, `grep`, `rg`, `tree`
235: 
236: **Text Processing**:
237: - `sed`, `awk`, `sort`, `uniq`, `cut`, `diff`, `comm`, `wc`
238: 
239: **Environment**:
240: - `env`, `ps`, `echo`
241: 
242: **Development**:
243: - `git` (all operations), `gh` (GitHub CLI)
244: - `uv`, `uvx`, `pytest`
245: - `python`, `python3`
246: 
247: **Special Cases**:
248: - `rm -rf ~/.mcp-auth` (MCP troubleshooting)
249: 
250: **Full list**: See `.claude/settings.local.json` "allow" array
251: 
252: ### Ask-First Patterns (15 patterns)
253: 
254: Commands that require confirmation:
255: 
256: **File Operations** (potentially destructive):
257: - `rm`, `mv`, `cp`
258: 
259: **Network Operations**:
260: - `curl`, `wget`, `nc`, `telnet`, `ssh`, `scp`, `rsync`
261: 
262: **Package Management**:
263: - `brew install`, `npm install`, `pip install`, `gem install`
264: 
265: **System Operations**:
266: - `sudo` (any sudo command)
267: 
268: **Rationale**: Safety gate for operations that modify files, access network, or require elevated privileges.
269: 
270: **Full list**: See `.claude/settings.local.json` "ask" array
271: 
272: ### Permission Behavior
273: 
274: **Unlisted commands**: Prompt by default (ask before execution)
275: **Workaround**: Add to allow list in `.claude/settings.local.json` if frequently used
276: 
277: ## Quick Tool Selection
278: 
279: **üîó Comprehensive Guide**: See [examples/TOOL-USAGE-GUIDE.md](examples/TOOL-USAGE-GUIDE.md) for:
280: - Decision tree (flowchart for tool selection)
281: - Common tasks with right/wrong examples
282: - Anti-patterns to avoid
283: - Migration table (55 denied tools ‚Üí alternatives)
284: 
285: **Quick Reference**:
286: 
287: **Analyze code**:
288: - Know symbol ‚Üí `serena_find_symbol`
289: - Explore file ‚Üí `serena_get_symbols_overview`
290: - Search patterns ‚Üí `Grep` (native, not serena_search_for_pattern)
291: - Find usages ‚Üí `serena_find_referencing_symbols`
292: 
293: **Modify files**:
294: - New ‚Üí `Write` (native)
295: - Existing (surgical) ‚Üí `Edit` (native)
296: - Config/text ‚Üí `Read` (native)
297: 
298: **Version control**:
299: - Use `Bash(git:*)` (native git commands)
300: - NOT `mcp__syntropy__git_git_status` (denied)
301: 
302: **GitHub operations**:
303: - Use `Bash(gh:*)` (native gh CLI)
304: - NOT `mcp__syntropy__github_*` (denied)
305: 
306: **External knowledge**:
307: - Documentation ‚Üí `context7_get_library_docs`
308: - Web search ‚Üí `WebSearch` (native)
309: - Web content ‚Üí `WebFetch` (native)
310: 
311: **Complex reasoning**: `sequentialthinking`
312: 
313: **Project management**: Linear tools (all 9 kept)
314: 
315: **System health**: `healthcheck` (detailed diagnostics with `detailed=true`)
316: 
317: ## Project Structure
318: 
319: ```
320: tools/
321: ‚îú‚îÄ‚îÄ ce/                 # Source code
322: ‚îÇ   ‚îú‚îÄ‚îÄ core.py         # File, git, shell ops
323: ‚îÇ   ‚îú‚îÄ‚îÄ validate.py     # 3-level validation
324: ‚îÇ   ‚îî‚îÄ‚îÄ context.py      # Context management
325: ‚îú‚îÄ‚îÄ tests/              # Test suite
326: ‚îú‚îÄ‚îÄ pyproject.toml      # UV config (don't edit!)
327: ‚îî‚îÄ‚îÄ bootstrap.sh        # Setup script
328: ```
329: 
330: ## Testing Standards
331: 
332: **TDD**: Test first ‚Üí fail ‚Üí implement ‚Üí refactor
333: 
334: **Real functionality**: No fake results, no mocks in tests
335: 
336: **Test before critical changes** (tool naming, API changes, refactoring)
337: 
338: ## Code Quality
339: 
340: - Functions: 50 lines (single responsibility)
341: - Files: 300-500 lines (logical modules)
342: - Classes: 100 lines (single concept)
343: - Mark mocks with FIXME in production code
344: 
345: ## Context Commands
346: 
347: ```bash
348: # Sync all PRPs with codebase
349: cd tools && uv run ce update-context
350: 
351: # Sync specific PRP
352: cd tools && uv run ce update-context --prp PRPs/executed/PRP-6.md
353: 
354: # Fast drift check (2-3s vs 10-15s)
355: cd tools && uv run ce analyze-context
356: 
357: # Force re-analysis
358: cd tools && uv run ce analyze-context --force
359: ```
360: 
361: **Drift Exit Codes**:
362: - 0: <5% (healthy)
363: - 1: 5-15% (warning)
364: - 2: ‚â•15% (critical)
365: 
366: ## Syntropy MCP Tool Sync
367: 
368: **Dynamic tool management** - Enable/disable tools at runtime without restart
369: 
370: ```bash
371: # Sync settings with Syntropy MCP tool state
372: /sync-with-syntropy
373: 
374: # Workflow example:
375: # 1. Enable/disable tools via Syntropy
376: mcp__syntropy__enable_tools(
377:   enable=["serena_find_symbol", "context7_get_library_docs"],
378:   disable=["filesystem_read_file", "git_git_status"]
379: )
380: 
381: # 2. Sync settings to .claude/settings.local.json
382: /sync-with-syntropy
383: 
384: # 3. Verify changes
385: cat .claude/settings.local.json
386: ```
387: 
388: **How it works**:
389: 1. Call `mcp__syntropy__list_all_tools` to get current tool states
390: 2. Update `.claude/settings.local.json` to match
391: 3. Backup original settings to `.claude/settings.local.json.backup`
392: 4. Output clear summary of changes made
393: 
394: **Benefits**:
395: - Real-time tool control (no MCP restart needed)
396: - Persistent state across sessions (`~/.syntropy/tool-state.json`)
397: - Context-aware tool sets (enable 10 tools for quick tasks, all 87 for deep analysis)
398: 
399: ## Linear Integration
400: 
401: **Config**: `.ce/linear-defaults.yml`
402: - Project: "Context Engineering"
403: - Assignee: "blazej.przybyszewski@gmail.com"
404: - Team: "Blaise78"
405: 
406: **Auto-create issues**: `/generate-prp` uses defaults
407: 
408: **Join existing issue**: `/generate-prp --join-prp 12`
409: 
410: **Troubleshooting**: `rm -rf ~/.mcp-auth` (pre-approved)
411: 
412: ## Batch PRP Generation
413: 
414: **Decompose large plans into staged, parallelizable PRPs with automatic dependency analysis**
415: 
416: ```bash
417: # Create plan document
418: vim FEATURE-PLAN.md
419: 
420: # Generate all PRPs with parallel subagents
421: /batch-gen-prp FEATURE-PLAN.md
422: 
423: # Output: Multiple PRPs with format PRP-X.Y.Z
424: #   X = Batch ID (next free number)
425: #   Y = Stage number
426: #   Z = Order within stage
427: ```
428: 
429: **Plan Format**:
430: ```markdown
431: # Plan Title
432: 
433: ## Phases
434: 
435: ### Phase 1: Name
436: 
437: **Goal**: One-sentence objective
438: **Estimated Hours**: 0.5
439: **Complexity**: low
440: **Files Modified**: path/to/file
441: **Dependencies**: None
442: **Implementation Steps**: [steps]
443: **Validation Gates**: [gates]
444: ```
445: 
446: **What It Does**:
447: 1. Parses plan document ‚Üí Extracts phases
448: 2. Builds dependency graph ‚Üí Analyzes deps + file conflicts
449: 3. Assigns stages ‚Üí Groups independent PRPs for parallel execution
450: 4. Spawns Sonnet subagents ‚Üí Parallel generation per stage
451: 5. Monitors via heartbeat files ‚Üí 30s polling, kills after 2 failed polls
452: 6. Creates Linear issues ‚Üí One per PRP
453: 7. Outputs summary ‚Üí All generated PRPs grouped by stage
454: 
455: **Example Output**:
456: ```
457: Batch 43:
458:   Stage 1: PRP-43.1.1
459:   Stage 2: PRP-43.2.1, PRP-43.2.2, PRP-43.2.3 (parallel)
460:   Stage 3: PRP-43.3.1
461: ```
462: 
463: **Integration with Execution**:
464: ```bash
465: # Generate PRPs from plan
466: /batch-gen-prp BIG-FEATURE-PLAN.md
467: 
468: # Execute entire batch
469: /batch-exe-prp --batch 43
470: 
471: # Or stage-by-stage
472: /batch-exe-prp --batch 43 --stage 1
473: /batch-exe-prp --batch 43 --stage 2
474: ```
475: 
476: **Time Savings**: 8 PRPs sequential (30 min) ‚Üí parallel (10-12 min) = **60% faster**
477: 
478: **See**: `.claude/commands/batch-gen-prp.md` for complete documentation
479: 
480: ## PRP Sizing
481: 
482: ```bash
483: cd tools && uv run ce prp analyze <path-to-prp.md>
484: ```
485: 
486: **Size Categories**:
487: - GREEN: ‚â§700 lines, ‚â§8h, LOW-MEDIUM risk
488: - YELLOW: 700-1000 lines, 8-12h, MEDIUM risk
489: - RED: >1000 lines, >12h, HIGH risk
490: 
491: **Exit Codes**: 0 (GREEN), 1 (YELLOW), 2 (RED)
492: 
493: ## Testing Patterns
494: 
495: **Strategy pattern** for composable testing:
496: - **Unit**: Test single strategy in isolation
497: - **Integration**: Test subgraph with real + mock
498: - **E2E**: Full pipeline, all external deps mocked
499: 
500: **Mock Strategies**: MockSerenaStrategy, MockContext7Strategy, MockLLMStrategy
501: 
502: **Real Strategies**: RealParserStrategy, RealCommandStrategy
503: 
504: ## Documentation Standards
505: 
506: **Mermaid Diagrams**: Always specify text color
507: - Light backgrounds ‚Üí `color:#000`
508: - Dark backgrounds ‚Üí `color:#fff`
509: - Format: `style X fill:#bgcolor,color:#textcolor`
510: 
511: ## Efficient Doc Review
512: 
513: **Grep-first validation** (90% token reduction):
514: 1. Structural validation (Grep patterns, 1-2k tokens)
515: 2. Code quality checks (Grep anti-patterns, 500 tokens)
516: 3. Targeted reads (2-3 files only, 3-5k tokens)
517: 
518: **Total**: ~5-7k tokens vs 200k+ for read-all
519: 
520: ## Resources
521: 
522: - `.ce/` - System boilerplate (don't modify)
523: - `.ce/RULES.md` - Framework rules
524: - `PRPs/[executed,feature-requests]` - Feature requests
525: - `examples/` - Framework patterns and user code
526: 
527: ## Keyboard Shortcuts
528: 
529: ### Image Pasting (macOS)
530: 
531: **cmd+v**: Paste screenshot images into Claude Code
532: - Requires Karabiner-Elements (configured via PRP-30)
533: - Remaps cmd+v ‚Üí ctrl+v in terminals only
534: - Config: `~/.config/karabiner/assets/complex_modifications/claude-code-cmd-v.json`
535: - Toggle: Karabiner-Elements ‚Üí Complex Modifications
536: 
537: **Setup** (one-time):
538: ```bash
539: brew install --cask karabiner-elements
540: # Enable rule in Karabiner-Elements UI ‚Üí Complex Modifications
541: ```
542: 
543: ## Git Worktree - Parallel PRP Development
544: 
545: **Native git solution for working on multiple PRPs simultaneously**
546: 
547: ### Quick Start
548: 
549: ```bash
550: # Create worktree for PRP-A (creates ../ctx-eng-plus-prp-a)
551: git worktree add ../ctx-eng-plus-prp-a -b prp-a-feature
552: 
553: # Work in worktree
554: cd ../ctx-eng-plus-prp-a
555: # Make changes...
556: git add .
557: git commit -m "Implement feature"
558: 
559: # List all worktrees
560: git worktree list
561: 
562: # Remove worktree after merging
563: git worktree remove ../ctx-eng-plus-prp-a
564: ```
565: 
566: ### Commands
567: 
568: **Create**:
569: ```bash
570: git worktree add <path> -b <branch-name>
571: # Example: git worktree add ../ctx-eng-plus-prp-12 -b prp-12-validation
572: ```
573: 
574: **List**:
575: ```bash
576: git worktree list
577: # Shows: path, commit hash, branch name
578: ```
579: 
580: **Remove**:
581: ```bash
582: git worktree remove <path>
583: # or: git worktree remove --force <path>  # if uncommitted changes
584: ```
585: 
586: **Prune** (clean stale references):
587: ```bash
588: git worktree prune
589: ```
590: 
591: ### Workflow for Parallel PRPs
592: 
593: **Stage 1: Create Worktrees**
594: ```bash
595: # From main repo: /Users/bprzybysz/nc-src/ctx-eng-plus
596: git worktree add ../ctx-eng-plus-prp-a -b prp-a-tool-deny
597: git worktree add ../ctx-eng-plus-prp-b -b prp-b-usage-guide
598: git worktree add ../ctx-eng-plus-prp-c -b prp-c-worktree-docs
599: ```
600: 
601: **Stage 2: Execute in Parallel**
602: ```bash
603: # Terminal 1
604: cd ../ctx-eng-plus-prp-a
605: # Edit .claude/settings.local.json
606: git add .
607: git commit -m "PRP-A: Add tools to deny list"
608: 
609: # Terminal 2
610: cd ../ctx-eng-plus-prp-b
611: # Create TOOL-USAGE-GUIDE.md
612: git add .
613: git commit -m "PRP-B: Create tool usage guide"
614: 
615: # Terminal 3
616: cd ../ctx-eng-plus-prp-c
617: # Update CLAUDE.md
618: git add .
619: git commit -m "PRP-C: Migrate to worktree docs"
620: ```
621: 
622: **Stage 3: Merge in Order**
623: ```bash
624: cd /Users/bprzybysz/nc-src/ctx-eng-plus
625: git checkout main
626: 
627: # Merge PRP-A first
628: git merge prp-a-tool-deny --no-ff
629: git push origin main
630: 
631: # Merge PRP-B
632: git merge prp-b-usage-guide --no-ff
633: git push origin main
634: 
635: # Merge PRP-C (may conflict with PRP-A on settings.local.json)
636: git merge prp-c-worktree-docs --no-ff
637: # If conflicts, resolve manually (see Conflict Resolution below)
638: git push origin main
639: ```
640: 
641: **Stage 4: Cleanup**
642: ```bash
643: git worktree remove ../ctx-eng-plus-prp-a
644: git worktree remove ../ctx-eng-plus-prp-b
645: git worktree remove ../ctx-eng-plus-prp-c
646: git worktree prune
647: ```
648: 
649: ### Critical Constraints
650: 
651: **‚ö†Ô∏è Same Branch Limitation**
652: 
653: **CANNOT** check out the same branch in multiple worktrees simultaneously.
654: 
655: **Example of ERROR**:
656: ```bash
657: # Main repo on `main` branch
658: cd /Users/bprzybysz/nc-src/ctx-eng-plus
659: git branch
660: # * main
661: 
662: # Try to create worktree on `main`
663: git worktree add ../ctx-eng-plus-test -b main
664: # ERROR: fatal: 'main' is already checked out at '/Users/bprzybysz/nc-src/ctx-eng-plus'
665: ```
666: 
667: **Solution**: Each worktree must use a **unique branch**.
668: 
669: ```bash
670: # Main repo stays on gitbutler/workspace or main
671: # Each PRP worktree uses dedicated branch
672: git worktree add ../ctx-eng-plus-prp-a -b prp-a-unique  # ‚úì
673: git worktree add ../ctx-eng-plus-prp-b -b prp-b-unique  # ‚úì
674: ```
675: 
676: ### Conflict Resolution
677: 
678: When merging parallel PRPs, conflicts may occur if they modify the same file sections.
679: 
680: **Scenario 1: No Conflicts** (PRP-A + PRP-B)
681: ```bash
682: git merge prp-a-tool-deny --no-ff  # ‚úì Success
683: git merge prp-b-usage-guide --no-ff  # ‚úì Success (different files)
684: ```
685: 
686: **Scenario 2: Merge Conflict** (PRP-A + PRP-D both edit settings.local.json)
687: 
688: **Step 1: Attempt Merge**
689: ```bash
690: git merge prp-d-command-perms --no-ff
691: # Auto-merging .claude/settings.local.json
692: # CONFLICT (content): Merge conflict in .claude/settings.local.json
693: # Automatic merge failed; fix conflicts and then commit the result.
694: ```
695: 
696: **Step 2: Check Conflict Markers**
697: ```bash
698: git status
699: # Unmerged paths:
700: #   both modified:   .claude/settings.local.json
701: ```
702: 
703: **Step 3: Read File to See Conflicts**
704: ```python
705: Read(file_path="/Users/bprzybysz/nc-src/ctx-eng-plus/.claude/settings.local.json")
706: # Look for:
707: # <<<<<<< HEAD
708: # ... current branch content ...
709: # =======
710: # ... incoming branch content ...
711: # >>>>>>> prp-d-command-perms
712: ```
713: 
714: **Step 4: Resolve with Edit Tool**
715: ```python
716: # Remove conflict markers, keep desired changes from both branches
717: Edit(
718:   file_path="/Users/bprzybysz/nc-src/ctx-eng-plus/.claude/settings.local.json",
719:   old_string="""<<<<<<< HEAD
720:   "deny": [existing tools...]
721: =======
722:   "deny": [incoming tools...]
723: >>>>>>> prp-d-command-perms""",
724:   new_string="""  "deny": [merged tools from both branches...]"""
725: )
726: ```
727: 
728: **Step 5: Stage and Commit**
729: ```bash
730: git add .claude/settings.local.json
731: git commit -m "Merge prp-d-command-perms: Resolve settings conflict"
732: ```
733: 
734: **Scenario 3: Conflicting Logic** (PRP-A denies tool, PRP-D allows same tool)
735: 
736: **Resolution**: Apply **last-merged wins** or **manual decision**.
737: 
738: ```json
739: // PRP-A (merged first): Denies "mcp__syntropy__git_git_status"
740: "deny": ["mcp__syntropy__git_git_status"]
741: 
742: // PRP-D (merging now): Allows "git" commands implicitly
743: "allow": ["Bash(git:*)"]
744: 
745: // Decision: Keep Bash(git:*) in allow, keep git_git_status in deny
746: // Rationale: Native bash git preferred over MCP wrapper
747: ```
748: 
749: ### Comparison: GitButler vs Worktree
750: 
751: | Feature | GitButler | Git Worktree |
752: |---------|-----------|--------------|
753: | **Parallel Development** | ‚úì Virtual branches | ‚úì Physical worktrees |
754: | **Branch Switching** | ‚úó Not needed | ‚úó Not needed |
755: | **Conflict Detection** | ‚úì Real-time üîí icon | ‚ö†Ô∏è At merge time |
756: | **Native Git** | ‚úó Proprietary layer | ‚úì Built-in since Git 2.5 |
757: | **Learning Curve** | Medium (new concepts) | Low (standard git) |
758: | **Merge Strategy** | UI-based | CLI-based (standard) |
759: | **Same Branch Limit** | ‚úì Can work on same "virtual" branch | ‚úó Must use unique branches |
760: | **Tool Requirement** | Requires GitButler app + CLI | ‚úì Native git (no install) |
761: | **Workspace Branch** | Auto-merges to `gitbutler/workspace` | Manual merge to `main` |
762: 
763: ### Benefits of Worktree Approach
764: 
765: 1. **Native Git**: No external dependencies, works everywhere
766: 2. **Explicit Branches**: Clear separation, standard git workflow
767: 3. **Merge Control**: Full control over merge order and conflict resolution
768: 4. **Universal**: Works on any git version ‚â•2.5 (2015)
769: 5. **Simple Cleanup**: `git worktree remove` + `git worktree prune`
770: 
771: ### Example: 3-PRP Parallel Execution
772: 
773: ```bash
774: # Stage 1: Create worktrees (30 seconds)
775: git worktree add ../ctx-eng-plus-prp-a -b prp-a-tool-deny
776: git worktree add ../ctx-eng-plus-prp-b -b prp-b-usage-guide
777: git worktree add ../ctx-eng-plus-prp-c -b prp-c-worktree-docs
778: 
779: # Stage 2: Execute in parallel (15 minutes total, vs 45 sequential)
780: # Each PRP executes independently in its worktree
781: 
782: # Stage 3: Merge in dependency order (5 minutes)
783: git merge prp-a-tool-deny --no-ff     # Merge order: 1
784: git merge prp-b-usage-guide --no-ff   # Merge order: 2
785: git merge prp-c-worktree-docs --no-ff # Merge order: 3
786: 
787: # Stage 4: Cleanup (30 seconds)
788: git worktree remove ../ctx-eng-plus-prp-a
789: git worktree remove ../ctx-eng-plus-prp-b
790: git worktree remove ../ctx-eng-plus-prp-c
791: git worktree prune
792: ```
793: 
794: **Time Savings**: 45 min sequential ‚Üí 20 min parallel (55% reduction)
795: 
796: ---
797: 
798: ## Troubleshooting
799: 
800: ```bash
801: # Tool not found
802: cd tools && uv pip install -e .
803: 
804: # Tests failing
805: uv sync
806: uv run pytest tests/ -v
807: 
808: # Linear "Not connected"
809: rm -rf ~/.mcp-auth
810: 
811: # Check PRP's Linear issue ID
812: grep "^issue:" PRPs/executed/PRP-12-feature.md
813: ```
814: 
815: **New Issues** (added after lockdown):
816: 
817: ### Issue: "Permission prompt for safe command"
818: 
819: **Symptom**: Commands like `ls` or `cat` prompt for permission
820: 
821: **Cause**: Command not in auto-allow list
822: 
823: **Solution**:
824: 1. Check if command matches pattern: `grep 'Bash(ls' .claude/settings.local.json`
825: 2. If missing, add pattern to allow list
826: 3. Or approve once (permission remembered for session)
827: 
828: ### Issue: "Command denied" or "tool not found"
829: 
830: **Symptom**: MCP tool like `mcp__syntropy__filesystem_read_file` fails
831: 
832: **Cause**: Tool in deny list (post-lockdown)
833: 
834: **Solution**:
835: 1. Check TOOL-USAGE-GUIDE.md for alternative
836: 2. Example: `filesystem_read_file` ‚Üí Use `Read` (native) instead
837: 3. If tool should be allowed, remove from deny list (rare)
838: 
839: ### Issue: "MCP tools context too large"
840: 
841: **Symptom**: Token usage warning for MCP tools
842: 
843: **Cause**: Deny list not applied (MCP not reconnected)
844: 
845: **Solution**:
846: ```bash
847: # Reconnect MCP servers
848: /mcp
849: 
850: # Verify token reduction
851: # Expected: ~2k tokens for MCP tools (was ~46k)
852: ```
853: 
854: ## Permissions
855: 
856: **‚ùå NEVER** replace all permissions with one entry in `.claude/settings.local.json`
857: 
858: **‚úÖ ALLOWED**: Surgical edits to individual permissions
859: 
860: ## Special Notes
861: 
862: - Linear MCP context: "linear( mcp)" = linear-server mcp
863: - Compact conversation: Use claude-3-haiku-20240307
864: - Activate Serena: Use project's root full path
865: - Ad-hoc code strict: 3 LOC max, no exceptions
</file>

</files>
